#  Retain only occurrences which are identified to genus or species level#
RawData <- filter(RawData, !is.na(genus))
nrow(RawData)
?filter
#  Retain only occurrences which are identified to genus or species level#
RawData <- dplyr::filter(RawData, !is.na(genus))
nrow(RawData)
?paste0
?browseURL
?gsub
?install.packages
?dplyr::filter
RawData[, "genus"]
#  Retain only occurrences which are identified to genus or species level#
RawData <- dplyr::filter(RawData, nchar(genus) == 0)
nrow(RawData)
# ...and then use the read.csv function to read the data into R:#
RawData <- utils::read.csv(URL, header = TRUE, stringsAsFactors = FALSE)#
#
# This is a lot of data!:#
nrow(RawData)#
#
# So best to just look at part of it to begin with:#
head(RawData)#
#
# Importantly, you should never take a raw data query like this and use it#
# without some kind of scrutiny. But first we will simply trim away some of#
# the database fields (columns) we don't really need:#
RawData <- RawData[, c("occurrence_no", "collection_no", "phylum", "class",#
  "order", "family", "genus", "accepted_name", "early_interval",#
  "late_interval", "max_ma", "min_ma", "lng", "lat", "paleolng",#
  "paleolat", "identified_rank")]#
#
# We have already excluded egg and trace fossils ("form taxa" in the language#
# of the PBDB), but we also have a bunch of fossils that are only assignable#
# to some higher-level group:#
unique(RawData[, "identified_rank"])#
#
# There are clever ways some of these can be used to set some minimum level#
# of species diversity where no lower-level taxa are known, but for now we#
# will simply remove anything above genus-level:#
#  Retain only occurrences which are identified to genus or species level#
RawData <- dplyr::filter(RawData, nchar(genus) > 0)
nrow(RawData)
unique(RawData[, "identified_rank"])
nrow(Rawdata)
# We can see ths has shrunk the data, but not by much:#
nrow(RawData)
?distinct
RawData <- dplyr::distinct(RawData, accepted_name, collection_no,#
  .keep_all = TRUE)
nrow(RawData)
StageNames <- c("Capitanian", "Wuchiapingian", "Changhsingian", "Induan",#
  "Olenekian", "Anisian")
# Next we will consider occurrences not assigned to the stage(s) we want to#
# use as out time bins, but first we need to explicitly state what these are:#
StageNames <- c("Capitanian", "Wuchiapingian", "Changhsingian", "Induan",#
  "Olenekian", "Anisian")#
#
# Whilst we are at it we will also create a vector of stage midpoints we can#
# use later for (e.g.) plots:#
StageMidpoints <- c(263.1, 257, 253.2, 251.7, 249.2, 244.6)#
#  Retain occurences which are dated to a single stage#
#  [Note: doing this in a simple, automated fashion loses lots of occurrences unnecessarily, such as#
#  those dated to a single substage or regional biozone, but is done here for ease]#
RawData <- dplyr::filter(RawData, is.na(late_interval)) %>% filter(early_interval %in% StageNames)
nrow(RawData)
StageNames
RawData
late_interval
#################################################################################
#                                                                              ##
#                SCRIPT I - SETUP AND GETTING PBDB DATA INTO R                 ##
#                                                                              ##
#################################################################################
#
# SCRIPT AIMS:#
##
# 1. Install and load the packages required for the workshop.#
# 2. Introduce the PBDB and its' API.#
# 3. Get some example data into R for use in the later scripts.#
#
# First up we need to install the packages we will want to use (note this may#
# take a while and you might be prompted to install additional packages):#
PackageBundle <- c("devtools", "earth", "iNEXT", "nlme", "paleoTS", "plotrix",#
  "praise", "tidyverse", "velociraptr")#
utils::install.packages(PackageBundle, dependencies = TRUE)#
devtools::install_github("graemetlloyd/metatree")#
#
# And load these into memory:#
for(pkg in c(PackageBundle, "metatree")) try(library(pkg,#
  character.only = TRUE), silent = TRUE)#
#
# If you are familiar with R then you will know the hardest part in using a#
# package or script is to get your data into R in the format required by the#
# functions you want to use. Here we are going to take advantage of the#
# Paleobiology Database's "API" (short for Application Programming Interface),#
# which lets us "download" data directly into R. We are also going to use as#
# an example data set Permo-Triassic brachiopods.#
##
# We can begin by setting up some variables:#
Taxa <- "Brachiopoda" # Set "Taxa" as the taxonomic group of interest#
StartInterval <- "Capitanian" # Set start interval for sampling window#
StopInterval <- "Anisian" # Set stop interval for sampling window#
#
# In case you want to alter these to your own purposes then you should also#
# run the following lines which will ensure things get fromatted properly#
# for use with the API:#
Taxa <- paste(Taxa, collapse = ",")#
StartInterval <- gsub(" ", "%20", StartInterval)#
StopInterval <- gsub(" ", "%20", StopInterval)#
#
# We are now ready to use the API, but to do we have to produce a formatted#
# URL (Uniform Resource Locator; i.e., a web address).#
##
# These will always begin with:#
"https://paleobiodb.org/data1.2"#
#
# This is simply the top-level of the database with data1.2 indicating we#
# are using version 1.2 (the latest version) of the API. Next we want the#
# type of query, here we want some fossil occurrences (which is what most#
# queries are going to be). Here we are going to ask for them as a CSV#
# (comma-separated values):#
"https://paleobiodb.org/data1.2/occs/list.csv"#
#
# It is important to note that this means R will assume any comma it finds#
# in the output represents a division between columns of data. This means#
# if any of the data fields we want output contain a comma things are going#
# to break and hence why other formats (e.g., JSON) are also available).#
# Here we should be fine though.#
##
# Next we need to tell the database what taxon we actually want data for, so#
# we can use our Taxa variable from above with:#
paste0("https://paleobiodb.org/data1.2/occs/list.csv?base_name=", Taxa)#
#
# It is worth pointing out that, again, things can go wrong this way if#
# names are duplicated in the database. An example is the genus "Glyptolepis"#
# which is both a plant (type of conifer)...:#
utils::browseURL("https://paleobiodb.org/classic/basicTaxonInfo?taxon_no=291933")#
#
# ...and a fish (lobe-fin):#
utils::browseURL("https://paleobiodb.org/classic/basicTaxonInfo?taxon_no=34920")#
#
# Thus if we ask the database for Glyptolepis the response from the database#
# might not be what you expect. Let's skip ahead and ask for this data to#
# see what happens:#
utils::read.csv("https://paleobiodb.org/data1.2/occs/list.csv?base_name=Glyptolepis&show=coords,paleoloc,class&limit=all", header = T, na.strings = "")#
#
# Instead of an error message (there are two Glyptotlepises!) the API just#
# goes with one of them (the plant). Note this is not happening because#
# there are no occurrences of the fish in the database. We can check that#
# this is true by asking for the "right" Glyptolepis (at least if you are a#
# fish person) with:#
utils::read.csv("https://paleobiodb.org/data1.2/occs/list.csv?taxon_id=34920&show=coords,paleoloc,class&limit=all",#
  header = T, na.strings = "")#
#
# Thus if you *really* want to be sure you are getting the data you want you#
# should use taxon_id= and the taxon number, and not base_name= and the taxon#
# name. Again, with nrachiopods we are OK, but remember that the ICZN and#
# ICBN are separate entities so there is nothing to stop someone naming a#
# group of plants Brachiopoda!#
##
# Now we have stated what taxon we want the next thing to do is add any#
# additional options we want to add to our query. The obvious one here is the#
# sampling window. We can do this with the interval= option and as this is an#
# addition to the query we proceed it with an ampersand (&):#
paste0("https://paleobiodb.org/data1.2/occs/list.csv?base_name=", Taxa,#
  "&interval=", StartInterval, ",", StopInterval)#
#
# Note that the start and end of the interval have to be separated by a comma.#
##
# We can now add some additional options for what we want the output to include#
# with show=. If you want multiple things, agaian, these must be seoarated by#
# commas. Here we will ask for coordinate data (coords), palaeo-locality data#
# (paleoloc) and taxonomic hierarchy data (class):#
paste0("https://paleobiodb.org/data1.2/occs/list.csv?base_name=", Taxa,#
  "&interval=", StartInterval, ",", StopInterval,#
  "&show=coords,paleoloc,class")#
#
# One final tip is to make sure you only get "regular" taxa and not something#
# from a parataxonomy (like egg or footprint "species") with the pres= option#
# and the value "regular":#
paste0("https://paleobiodb.org/data1.2/occs/list.csv?base_name=", Taxa,#
  "&interval=", StartInterval, ",", StopInterval,#
  "&show=coords,paleoloc,class&pres=regular")#
#
# Now we have a complete URL we can store it in a variable...:#
URL <- paste0("https://paleobiodb.org/data1.2/occs/list.csv?base_name=",#
  Taxa, "&interval=", StartInterval, ",", StopInterval,#
  "&show=coords,paleoloc,class&pres=regular")#
#
# ...and then use the read.csv function to read the data into R:#
RawData <- utils::read.csv(URL, header = TRUE, stringsAsFactors = FALSE)#
#
# This is a lot of data!:#
nrow(RawData)#
#
# So best to just look at part of it to begin with:#
head(RawData)#
#
# Importantly, you should never take a raw data query like this and use it#
# without some kind of scrutiny. But first we will simply trim away some of#
# the database fields (columns) we don't really need:#
RawData <- RawData[, c("occurrence_no", "collection_no", "phylum", "class",#
  "order", "family", "genus", "accepted_name", "early_interval",#
  "late_interval", "max_ma", "min_ma", "lng", "lat", "paleolng",#
  "paleolat", "identified_rank")]#
#
# We have already excluded egg and trace fossils ("form taxa" in the language#
# of the PBDB), but we also have a bunch of fossils that are only assignable#
# to some higher-level group:#
unique(RawData[, "identified_rank"])#
#
# There are clever ways some of these can be used to set some minimum level#
# of species diversity where no lower-level taxa are known, but for now we#
# will simply remove anything above genus-level (the level of analysis we#
# will use here):#
RawData <- dplyr::filter(RawData, nchar(genus) > 0)#
#
# We can see this has shrunk the data, but not by much:#
nrow(RawData)#
#
# Anotehr important issue to consider is that synonymisation of taxa in the#
# PBDB can lead to separate entries with the same name (as junior synonyms are#
# replaced with their senior counterparts. If you want to know about richness#
# this is an issue, as it articifially inflates your estimate.#
##
#  We can stop this from happening by stripping out combinations of the same#
# collection no. AND accepted name.#
RawData <- dplyr::distinct(RawData, accepted_name, collection_no,#
  .keep_all = TRUE)#
#
# This has shrunk our data a little more:#
nrow(RawData)#
#
# Next we will consider occurrences not assigned to the stage(s) we want to#
# use as out time bins, but first we need to explicitly state what these are:#
StageNames <- c("Capitanian", "Wuchiapingian", "Changhsingian", "Induan",#
  "Olenekian", "Anisian")#
#
# Whilst we are at it we will also create a vector of stage midpoints we can#
# use later for (e.g.) plots:#
StageMidpoints <- c(263.1, 257, 253.2, 251.7, 249.2, 244.6)#
#  Retain occurences which are dated to a single stage#
#  [Note: doing this in a simple, automated fashion loses lots of occurrences unnecessarily, such as#
#  those dated to a single substage or regional biozone, but is done here for ease]#
RawData <- dplyr::filter(RawData, is.na(StopInterval)) %>% filter(StartInterval %in% StageNames)
nrow(RawData)
colnames(RawData)
#################################################################################
#                                                                              ##
#                SCRIPT I - SETUP AND GETTING PBDB DATA INTO R                 ##
#                                                                              ##
#################################################################################
#
# SCRIPT AIMS:#
##
# 1. Install and load the packages required for the workshop.#
# 2. Introduce the PBDB and its' API.#
# 3. Get some example data into R for use in the later scripts.#
#
# First up we need to install the packages we will want to use (note this may#
# take a while and you might be prompted to install additional packages):#
PackageBundle <- c("devtools", "earth", "iNEXT", "nlme", "paleoTS", "plotrix",#
  "praise", "tidyverse", "velociraptr")#
utils::install.packages(PackageBundle, dependencies = TRUE)#
devtools::install_github("graemetlloyd/metatree")#
#
# And load these into memory:#
for(pkg in c(PackageBundle, "metatree")) try(library(pkg,#
  character.only = TRUE), silent = TRUE)#
#
# If you are familiar with R then you will know the hardest part in using a#
# package or script is to get your data into R in the format required by the#
# functions you want to use. Here we are going to take advantage of the#
# Paleobiology Database's "API" (short for Application Programming Interface),#
# which lets us "download" data directly into R. We are also going to use as#
# an example data set Permo-Triassic brachiopods.#
##
# We can begin by setting up some variables:#
Taxa <- "Brachiopoda" # Set "Taxa" as the taxonomic group of interest#
StartInterval <- "Capitanian" # Set start interval for sampling window#
StopInterval <- "Anisian" # Set stop interval for sampling window#
#
# In case you want to alter these to your own purposes then you should also#
# run the following lines which will ensure things get fromatted properly#
# for use with the API:#
Taxa <- paste(Taxa, collapse = ",")#
StartInterval <- gsub(" ", "%20", StartInterval)#
StopInterval <- gsub(" ", "%20", StopInterval)#
#
# We are now ready to use the API, but to do we have to produce a formatted#
# URL (Uniform Resource Locator; i.e., a web address).#
##
# These will always begin with:#
"https://paleobiodb.org/data1.2"#
#
# This is simply the top-level of the database with data1.2 indicating we#
# are using version 1.2 (the latest version) of the API. Next we want the#
# type of query, here we want some fossil occurrences (which is what most#
# queries are going to be). Here we are going to ask for them as a CSV#
# (comma-separated values):#
"https://paleobiodb.org/data1.2/occs/list.csv"#
#
# It is important to note that this means R will assume any comma it finds#
# in the output represents a division between columns of data. This means#
# if any of the data fields we want output contain a comma things are going#
# to break and hence why other formats (e.g., JSON) are also available).#
# Here we should be fine though.#
##
# Next we need to tell the database what taxon we actually want data for, so#
# we can use our Taxa variable from above with:#
paste0("https://paleobiodb.org/data1.2/occs/list.csv?base_name=", Taxa)#
#
# It is worth pointing out that, again, things can go wrong this way if#
# names are duplicated in the database. An example is the genus "Glyptolepis"#
# which is both a plant (type of conifer)...:#
utils::browseURL("https://paleobiodb.org/classic/basicTaxonInfo?taxon_no=291933")#
#
# ...and a fish (lobe-fin):#
utils::browseURL("https://paleobiodb.org/classic/basicTaxonInfo?taxon_no=34920")#
#
# Thus if we ask the database for Glyptolepis the response from the database#
# might not be what you expect. Let's skip ahead and ask for this data to#
# see what happens:#
utils::read.csv("https://paleobiodb.org/data1.2/occs/list.csv?base_name=Glyptolepis&show=coords,paleoloc,class&limit=all", header = T, na.strings = "")#
#
# Instead of an error message (there are two Glyptotlepises!) the API just#
# goes with one of them (the plant). Note this is not happening because#
# there are no occurrences of the fish in the database. We can check that#
# this is true by asking for the "right" Glyptolepis (at least if you are a#
# fish person) with:#
utils::read.csv("https://paleobiodb.org/data1.2/occs/list.csv?taxon_id=34920&show=coords,paleoloc,class&limit=all",#
  header = T, na.strings = "")#
#
# Thus if you *really* want to be sure you are getting the data you want you#
# should use taxon_id= and the taxon number, and not base_name= and the taxon#
# name. Again, with nrachiopods we are OK, but remember that the ICZN and#
# ICBN are separate entities so there is nothing to stop someone naming a#
# group of plants Brachiopoda!#
##
# Now we have stated what taxon we want the next thing to do is add any#
# additional options we want to add to our query. The obvious one here is the#
# sampling window. We can do this with the interval= option and as this is an#
# addition to the query we proceed it with an ampersand (&):#
paste0("https://paleobiodb.org/data1.2/occs/list.csv?base_name=", Taxa,#
  "&interval=", StartInterval, ",", StopInterval)#
#
# Note that the start and end of the interval have to be separated by a comma.#
##
# We can now add some additional options for what we want the output to include#
# with show=. If you want multiple things, agaian, these must be seoarated by#
# commas. Here we will ask for coordinate data (coords), palaeo-locality data#
# (paleoloc) and taxonomic hierarchy data (class):#
paste0("https://paleobiodb.org/data1.2/occs/list.csv?base_name=", Taxa,#
  "&interval=", StartInterval, ",", StopInterval,#
  "&show=coords,paleoloc,class")#
#
# One final tip is to make sure you only get "regular" taxa and not something#
# from a parataxonomy (like egg or footprint "species") with the pres= option#
# and the value "regular":#
paste0("https://paleobiodb.org/data1.2/occs/list.csv?base_name=", Taxa,#
  "&interval=", StartInterval, ",", StopInterval,#
  "&show=coords,paleoloc,class&pres=regular")#
#
# Now we have a complete URL we can store it in a variable...:#
URL <- paste0("https://paleobiodb.org/data1.2/occs/list.csv?base_name=",#
  Taxa, "&interval=", StartInterval, ",", StopInterval,#
  "&show=coords,paleoloc,class&pres=regular")#
#
# ...and then use the read.csv function to read the data into R:#
RawData <- utils::read.csv(URL, header = TRUE, stringsAsFactors = FALSE)#
#
# This is a lot of data!:#
nrow(RawData)#
#
# So best to just look at part of it to begin with:#
head(RawData)#
#
# Importantly, you should never take a raw data query like this and use it#
# without some kind of scrutiny. But first we will simply trim away some of#
# the database fields (columns) we don't really need:#
RawData <- RawData[, c("occurrence_no", "collection_no", "phylum", "class",#
  "order", "family", "genus", "accepted_name", "early_interval",#
  "late_interval", "max_ma", "min_ma", "lng", "lat", "paleolng",#
  "paleolat", "identified_rank")]#
#
# We have already excluded egg and trace fossils ("form taxa" in the language#
# of the PBDB), but we also have a bunch of fossils that are only assignable#
# to some higher-level group:#
unique(RawData[, "identified_rank"])#
#
# There are clever ways some of these can be used to set some minimum level#
# of species diversity where no lower-level taxa are known, but for now we#
# will simply remove anything above genus-level (the level of analysis we#
# will use here):#
RawData <- dplyr::filter(RawData, nchar(genus) > 0)#
#
# We can see this has shrunk the data, but not by much:#
nrow(RawData)#
#
# Anotehr important issue to consider is that synonymisation of taxa in the#
# PBDB can lead to separate entries with the same name (as junior synonyms are#
# replaced with their senior counterparts. If you want to know about richness#
# this is an issue, as it articifially inflates your estimate.#
##
#  We can stop this from happening by stripping out combinations of the same#
# collection no. AND accepted name.#
RawData <- dplyr::distinct(RawData, accepted_name, collection_no,#
  .keep_all = TRUE)#
#
# This has shrunk our data a little more:#
nrow(RawData)#
#
# Next we will consider occurrences not assigned to the stage(s) we want to#
# use as out time bins, but first we need to explicitly state what these are:#
StageNames <- c("Capitanian", "Wuchiapingian", "Changhsingian", "Induan",#
  "Olenekian", "Anisian")#
#
# Whilst we are at it we will also create a vector of stage midpoints we can#
# use later for (e.g.) plots:#
StageMidpoints <- c(263.1, 257, 253.2, 251.7, 249.2, 244.6)
nrow(RawData)
unique(RawData[, "late_interval"])
unique(RawData[, "early_interval"])
nrow(RawData)
RawData <- dplyr::filter(RawData, nchar(late_interval) == 0) %>% dplyr::filter(early_interval %in% StageNames)
nrow(RawData)
RawData <- dplyr::filter(RawData, nchar(late_interval) == 0) %>%#
  dplyr::filter(early_interval %in% StageNames)
VRData <- velociraptr::downloadPBDB(Taxa = Taxa, StartInterval = StartInterval, StopInterval = StopInterval)#
MTData <- metatree::PaleobiologyDBOccurrenceQuerier(unlist(lapply(apply(#
  metatree::PaleobiologyDBChildFinder("1", Taxa, interval = c(StartInterval,#
  StopInterval), returnrank = "3"), 1, list), function(x) {x <- unlist(x)#
  [c("OriginalTaxonNo", "ResolvedTaxonNo")]; gsub("txn:|var:", "", unname(x[!is.na(x)][1]))})))
MTData <- metatree::PaleobiologyDBOccurrenceQuerier(unlist(lapply(apply(#
  metatree::PaleobiologyDBChildFinder("1", Taxa, interval = c(StartInterval,#
  StopInterval), returnrank = "3"), 1, list), function(x) {x <-#
  unlist(x)[c("OriginalTaxonNo", "ResolvedTaxonNo")]; gsub("txn:|var:",#
  "", unname(x[!is.na(x)][1]))})))
MTData <- metatree::PaleobiologyDBOccurrenceQuerier(unlist(lapply(apply(metatree::PaleobiologyDBChildFinder("1", Taxa, interval = c(StartInterval, StopInterval), returnrank = "3"), 1, list), function(x) {x <- unlist(x)[c("OriginalTaxonNo", "ResolvedTaxonNo")]; gsub("txn:|var:", "", unname(x[!is.na(x)][1]))})))
MTData <- metatree::PaleobiologyDBOccurrenceQuerier(unlist(lapply(apply(#
  metatree::PaleobiologyDBChildFinder("1", Taxa, interval = c(StartInterval,#
  StopInterval), returnrank = "3"), 1, list), function(x) {x <-#
  unlist(x)[c("OriginalTaxonNo", "ResolvedTaxonNo")]; gsub("txn:|var:",#
  "", unname(x[!is.na(x)][1]))})))
head(MTData)
head(RawData)
nrow(RawData)
unique(RawData[, "genus"])
lapply(as.list(StageNames), function(x) {unique(RawData[RawData[, "early_interval"] == x, "genus"])})
54t  lapply(as.list(StageNames), function(x) {unlist(lapply(strsplit(RawData[RawData[, "early_interval"] == x, "genus"], split = " "), function(y) y[1]))})
lapply(as.list(StageNames), function(x) {unlist(lapply(strsplit(RawData[RawData[, "early_interval"] == x, "genus"], split = " "), function(y) y[1]))})
CleanData <- lapply(as.list(StageNames), function(x)#
  {unlist(lapply(strsplit(RawData[RawData[, "early_interval"] == x,#
  "genus"], split = " "), function(y) y[1]))})
# And add the stage names for each one:#
names(CleanData) <- StageNames
CleanData[["Induan"]]
lapply(CleanData, function(x) length(unique(x)))
unlist(lapply(CleanData, function(x) length(unique(x))))
plot(x = StageMidpoints, y = unlist(lapply(CleanData, function(x) length(unique(x))), xlab = "Time (Ma)", ylab = "Richness (N genera)")
)
plot(x = StageMidpoints, y = unlist(lapply(CleanData, function(x) length(unique(x))), xlab = "Time (Ma)", ylab = "Richness (N genera)")
plot(x = StageMidpoints, y = unlist(lapply(CleanData, function(x) length(unique(x)), xlab = "Time (Ma)", ylab = "Richness (N genera)")
unlist(lapply(CleanData, function(x) length(unique(x))
)
plot(x = StageMidpoints, y = unlist(lapply(CleanData, function(x) length(unique(x)))), xlab = "Time (Ma)", ylab = "Richness (N genera)")
plot(x = StageMidpoints, y = unlist(lapply(CleanData, function(x) length(unique(x)))), xlab = "Time (Ma)", ylab = "Richness (N genera)", type = "l")
plot(x = StageMidpoints, y = unlist(lapply(CleanData, function(x) length(unique(x)))), xlab = "Time (Ma)", ylab = "Richness (N genera)", type = "l", xlim = c(max(StageMidpoints), min(StageMidpoints)))
plot(x = StageMidpoints, y = unlist(lapply(CleanData, function(x)#
  length(unique(x)))), xlab = "Time (Ma)", ylab = "Richness (N genera)",#
  type = "l", xlim = c(max(StageMidpoints), min(StageMidpoints)))
#################################################################################
#                                                                              ##
#                   SCRIPT II - RAREFACTION AND BOOTSTRAPPING                  ##
#                                                                              ##
#################################################################################
#
# SCRIPT AIMS:#
##
# 1. Install and load the packages required for the workshop.#
# 2. Introduce the PBDB and its' API.#
# 3. Get some example data into R for use in the later scripts.#
#
# Make sure the packages are loaded into memory...:#
PackageBundle <- c("devtools", "earth", "iNEXT", "metatree", "nlme", "paleoTS",#
  "plotrix", "praise", "tidyverse", "velociraptr")#
for(pkg in c(PackageBundle, "metatree")) try(library(pkg,#
  character.only = TRUE), silent = TRUE)#
#
# ...alongside the data the data into R:#
RawData <- utils::read.csv("https://paleobiodb.org/data1.2/occs/list.csv?base_name=Brachiopoda&interval=Capitanian,Anisian&show=coords,paleoloc,class",#
  header = TRUE, stringsAsFactors = FALSE)#
RawData <- RawData[, c("occurrence_no", "collection_no", "phylum", "class",#
  "order", "family", "genus", "accepted_name", "early_interval",#
  "late_interval", "max_ma", "min_ma", "lng", "lat", "paleolng",#
  "paleolat", "identified_rank")]#
RawData <- dplyr:: n|(RawData, nchar(genus) > 0)#
RawData <- dplyr::distinct(RawData, accepted_name, collection_no,#
  .keep_all = TRUE)#
StageNames <- c("Capitanian", "Wuchiapingian", "Changhsingian", "Induan",#
  "Olenekian", "Anisian")#
StageMidpoints <- c(263.1, 257, 253.2, 251.7, 249.2, 244.6)#
RawData <- dplyr::filter(RawData, nchar(late_interval) == 0) %>%#
  dplyr::filter(early_interval %in% StageNames)#
CleanData <- lapply(as.list(StageNames), function(x)#
  {unlist(lapply(strsplit(RawData[RawData[, "early_interval"] == x,#
  "genus"], split = " "), function(y) y[1]))})#
names(CleanData) <- StageNames
CleanData[[4]]
#################################################################################
#                                                                              ##
#                   SCRIPT II - RAREFACTION AND BOOTSTRAPPING                  ##
#                                                                              ##
#################################################################################
#
# SCRIPT AIMS:#
##
# 1. Introduce basics of resampling.#
# 2. Learn hot to rarefy and bootstrap data in R.#
# 3. Generate rarefied and bootstrapped richness estimates.#
#
# Make sure the packages are loaded into memory...:#
PackageBundle <- c("devtools", "earth", "iNEXT", "metatree", "nlme", "paleoTS",#
  "plotrix", "praise", "tidyverse", "velociraptr")#
for(pkg in c(PackageBundle, "metatree")) try(library(pkg,#
  character.only = TRUE), silent = TRUE)#
#
# ...alongside the data the data into R:#
RawData <- utils::read.csv("https://paleobiodb.org/data1.2/occs/list.csv?base_name=Brachiopoda&interval=Capitanian,Anisian&show=coords,paleoloc,class",#
  header = TRUE, stringsAsFactors = FALSE)#
RawData <- RawData[, c("occurrence_no", "collection_no", "phylum", "class",#
  "order", "family", "genus", "accepted_name", "early_interval",#
  "late_interval", "max_ma", "min_ma", "lng", "lat", "paleolng",#
  "paleolat", "identified_rank")]#
RawData <- dplyr::filter(RawData, nchar(genus) > 0)#
RawData <- dplyr::distinct(RawData, accepted_name, collection_no,#
  .keep_all = TRUE)#
StageNames <- c("Capitanian", "Wuchiapingian", "Changhsingian", "Induan",#
  "Olenekian", "Anisian")#
StageMidpoints <- c(263.1, 257, 253.2, 251.7, 249.2, 244.6)#
RawData <- dplyr::filter(RawData, nchar(late_interval) == 0) %>%#
  dplyr::filter(early_interval %in% StageNames)#
CleanData <- lapply(as.list(StageNames), function(x)#
  {unlist(lapply(strsplit(RawData[RawData[, "early_interval"] == x,#
  "genus"], split = " "), function(y) y[1]))})#
names(CleanData) <- StageNames
CleanData[[4]]
CleanData[["Induan"]]
?sample
base::sample(1:10)
CleanData[["Induan"]]
sample(CleanData[["Induan"]])
sample(CleanData[["Induan"]])[1]
ReSample[1:2]
ReSample <- sample(CleanData[["Induan"]])#
ReSample[1]#
#
# Whereas for the next value it will be two (fossils/occurrences), but#
# possibly either one (if our genus from before is sampled again) or two if#
# we now sample a different genus:#
ReSample[1:2]
ReSampler <- function(NamesVector) {ShuffledSample <- sample(NamesVector);#
  lapply(as.list(1:length(ShuffledSample)), function(x) unique(ShuffledSample[1:x]))}#
ReSampler(CleanData[["Induan"]])
ReSampler <- function(NamesVector) {ShuffledSample <- sample(NamesVector);#
  unlist(lapply(as.list(1:length(ShuffledSample)), function(x) length(unique(ShuffledSample[1:x]))))}#
ReSampler(CleanData[["Induan"]])
ReSampler <- function(NamesVector) {ShuffledSample <- sample(NamesVector);#
  matrix(c(1:length(ShuffledSample), unlist(lapply(as.list(1:length(ShuffledSample)), function(x) length(unique(ShuffledSample[1:x]))))), nrow = 2)}#
ReSampler(CleanData[["Induan"]])
ReSampler <- function(NamesVector) {ShuffledSample <- sample(NamesVector);#
  matrix(c(1:length(ShuffledSample), unlist(lapply(as.list(1:length(ShuffledSample)), function(x) length(unique(ShuffledSample[1:x]))))), nrow = 2, byrow = TRUE)}#
ReSampler(CleanData[["Induan"]])
ReSampler <- function(NamesVector) {ShuffledSample <- sample(NamesVector);#
  matrix(c(1:length(ShuffledSample), unlist(lapply(as.list(1:length(ShuffledSample)), function(x) length(unique(ShuffledSample[1:x]))))), nrow = 2, byrow = TRUE, dimnames = list(c("SampleSize", "NUnique"), c())}#
ReSampler(CleanData[["Induan"]])
ReSampler <- function(NamesVector) {ShuffledSample <- sample(NamesVector);#
  matrix(c(1:length(ShuffledSample), unlist(lapply(as.list(1:length(ShuffledSample)), function(x) length(unique(ShuffledSample[1:x]))))), nrow = 2, byrow = TRUE, dimnames = list(c("SampleSize", "NUnique"), c()))}#
ReSampler(CleanData[["Induan"]])
ReSampler <- function(NamesVector) {ShuffledSample <- sample(NamesVector);#
  matrix(c(1:length(ShuffledSample),#
  unlist(lapply(as.list(1:length(ShuffledSample)),#
  function(x) length(unique(ShuffledSample[1:x]))))), nrow = 2, byrow = TRUE,#
  dimnames = list(c("SampleSize", "NUnique"), c()))}#
ReSampler(CleanData[["Induan"]])
# And apply it to the Induan brachiopods:#
ReSampler(CleanData[["Induan"]])
ReSampler(CleanData[["Induan"]])#
ReSampler(CleanData[["Induan"]])#
ReSampler(CleanData[["Induan"]])#
ReSampler(CleanData[["Induan"]])#
ReSampler(CleanData[["Induan"]])
# It would be tedious to continue in this way manually, so let's write a#
# little function to do this job for us (including counting the unique#
# names in each size sample)...:#
ReSampler <- function(NamesVector) {ShuffledSample <- sample(NamesVector);#
  matrix(c(1:length(ShuffledSample),#
  unlist(lapply(as.list(1:length(ShuffledSample)),#
  function(x) length(unique(ShuffledSample[1:x]))))), nrow = 2, byrow = TRUE,#
  dimnames = list(c("SampleSize", "NUnique"), c()))}#
#
# ...and apply it to the Induan brachiopods:#
ReSampler(CleanData[["Induan"]])
NReplicates <- 10#
NamesVector <- CleanData[["Induan"]]#
#
MultiReSampler <- function(NamesVector, NReplicates) {#
  lapply(as.list(1:NReplicates), function(x) ReSampler(NamesVector)[NUnique, ])#
}#
MultiReSampler(NamesVector, NReplicates)
NReplicates <- 10#
NamesVector <- CleanData[["Induan"]]#
#
MultiReSampler <- function(NamesVector, NReplicates) {#
  lapply(as.list(1:NReplicates), function(x) ReSampler(NamesVector)["NUnique", ])#
}#
MultiReSampler(NamesVector, NReplicates)
NReplicates <- 10#
NamesVector <- CleanData[["Induan"]]#
#
MultiReSampler <- function(NamesVector, NReplicates) {#
  do.call(rbind, lapply(as.list(1:NReplicates), function(x) ReSampler(NamesVector)["NUnique", ]))#
}#
MultiReSampler(NamesVector, NReplicates)
NReplicates <- 10#
NamesVector <- CleanData[["Induan"]]#
#
MultiReSampler <- function(NamesVector, NReplicates) {#
  apply(do.call(rbind, lapply(as.list(1:NReplicates), function(x) ReSampler(NamesVector)["NUnique", ])), 2, mean)#
}#
MultiReSampler(NamesVector, NReplicates)
MultiReSampler <- function(NamesVector, NReplicates) apply(do.call(rbind,#
  lapply(as.list(1:NReplicates),#
  function(x) ReSampler(NamesVector)["NUnique", ])), 2, mean)#
#
# ...and test it out 100 times:#
MultiReSampler(NamesVector = CleanData[["Induan"]], NReplicates = 100)
MultiReSamples <- MultiReSampler(NamesVector = CleanData[["Induan"]],#
  NReplicates = 100)#
MultiReSamples
plot(x = 1:length(MultiReSamples), y = MultiReSamples, xlab = "N Occurrences",#
  ylab = "Genus richness (N unique genera)", type = "l")
MultiReSamples <- MultiReSampler(NamesVector = CleanData[["Induan"]],#
  NReplicates = 1000)#
MultiReSamples#
#
# These results are best understood graphically:#
plot(x = 1:length(MultiReSamples), y = MultiReSamples, xlab = "N Occurrences",#
  ylab = "Genus richness (N unique genera)", type = "l")
MultiReSamples <- MultiReSampler(NamesVector = CleanData[["Anisian"]],#
  NReplicates = 100)#
plot(x = 1:length(MultiReSamples), y = MultiReSamples, xlab = "N Occurrences",#
  ylab = "Genus richness (N unique genera)", type = "l")
MultiReSamples <- lapply(as.list(StageNames), function(x) MultiReSampler(NamesVector = CleanData[[x]], NReplicates = 100))
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), log = "xy")
unlist(lapply(MultiReSamples, max))
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), y = max(unlist(lapply(MultiReSamples, max))), log = "xy")
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), y = seq(from = 1, to = max(unlist(lapply(MultiReSamples, max))), length.out = max(unlist(lapply(MultiReSamples, length)))), log = "xy")
?plot
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), y = seq(from = 1, to = max(unlist(lapply(MultiReSamples, max))), length.out = max(unlist(lapply(MultiReSamples, length)))), log = "xy", plot=FALSE)
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), y = seq(from = 1, to = max(unlist(lapply(MultiReSamples, max))), length.out = max(unlist(lapply(MultiReSamples, length)))), log = "xy", type = "n")
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), y = seq(from = 1, to = max(unlist(lapply(MultiReSamples, max))), length.out = max(unlist(lapply(MultiReSamples, length)))), log = "xy", type = "n")#
for(i in StageNames) points(x = 1:length(MultiReSamples[[i]]), y = MultiReSamples[[i]], type = "l")
MultiReSamples[[i]]
i
names(MultiReSamples) <- StageNames
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), y = seq(from = 1, to = max(unlist(lapply(MultiReSamples, max))), length.out = max(unlist(lapply(MultiReSamples, length)))), log = "xy", type = "n")#
for(i in StageNames) points(x = 1:length(MultiReSamples[[i]]), y = MultiReSamples[[i]], type = "l")
?rainbow
StageNames == i
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), y = seq(from = 1, to = max(unlist(lapply(MultiReSamples, max))), length.out = max(unlist(lapply(MultiReSamples, length)))), log = "xy", type = "n")#
for(i in StageNames) points(x = 1:length(MultiReSamples[[i]]), y = MultiReSamples[[i]], type = "l", col = rainbow(length(StageNames))[StageNames == i])
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), y = seq(from = 1,#
  to = max(unlist(lapply(MultiReSamples, max))),#
  length.out = max(unlist(lapply(MultiReSamples, length)))), log = "xy",#
  type = "n", xlab = "N Occurrences", ylab = "Genus richness")#
for(i in StageNames) points(x = 1:length(MultiReSamples[[i]]), y = MultiReSamples[[i]], type = "l", col = rainbow(length(StageNames))[StageNames == i])
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), y = seq(from = 1,#
  to = max(unlist(lapply(MultiReSamples, max))),#
  length.out = max(unlist(lapply(MultiReSamples, length)))), log = "xy",#
  type = "n", xlab = "N Occurrences", ylab = "Genus richness")#
for(i in StageNames) points(x = 1:length(MultiReSamples[[i]]), y = MultiReSamples[[i]], type = "l", col = rainbow(length(StageNames))[StageNames == i])#
#
legend("topleft", legend = StageNames, col = rainbow(length(StageNames)), lwd=2, bty = "n", cex = 0.7)
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), y = seq(from = 1,#
  to = max(unlist(lapply(MultiReSamples, max))),#
  length.out = max(unlist(lapply(MultiReSamples, length)))), log = "xy",#
  type = "n", xlab = "N Occurrences", ylab = "Genus richness")#
for(i in StageNames) points(x = 1:length(MultiReSamples[[i]]),#
  y = MultiReSamples[[i]], type = "l",#
  col = rainbow(length(StageNames))[StageNames == i], lwd = 2)#
legend("topleft", legend = StageNames, col = rainbow(length(StageNames)),#
  lwd = 2, bty = "n", cex = 0.7)
library(viridis)
viridis::plasma(6)
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), y = seq(from = 1,#
  to = max(unlist(lapply(MultiReSamples, max))),#
  length.out = max(unlist(lapply(MultiReSamples, length)))), log = "xy",#
  type = "n", xlab = "N Occurrences", ylab = "Genus richness")#
for(i in StageNames) points(x = 1:length(MultiReSamples[[i]]),#
  y = MultiReSamples[[i]], type = "l",#
  col = viridis::plasma(length(StageNames))[StageNames == i], lwd = 2)#
legend("topleft", legend = StageNames, col = viridis::plasma(length(StageNames)),#
  lwd = 2, bty = "n", cex = 0.7)#
(6)
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), y = seq(from = 1,#
  to = max(unlist(lapply(MultiReSamples, max))),#
  length.out = max(unlist(lapply(MultiReSamples, length)))), log = "xy",#
  type = "n", xlab = "N Occurrences", ylab = "Genus richness")#
for(i in StageNames) points(x = 1:length(MultiReSamples[[i]]),#
  y = MultiReSamples[[i]], type = "l",#
  col = viridis::magma(length(StageNames))[StageNames == i], lwd = 2)#
legend("topleft", legend = StageNames, col = viridis::magma(length(StageNames)),#
  lwd = 2, bty = "n", cex = 0.7)
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), y = seq(from = 1,#
  to = max(unlist(lapply(MultiReSamples, max))),#
  length.out = max(unlist(lapply(MultiReSamples, length)))), log = "xy",#
  type = "n", xlab = "N Occurrences", ylab = "Genus richness")#
for(i in StageNames) points(x = 1:length(MultiReSamples[[i]]),#
  y = MultiReSamples[[i]], type = "l",#
  col = viridis::magma(length(StageNames))[StageNames == i], lwd = 2)#
legend("topleft", legend = StageNames, col = viridis::magma(length(StageNames)),#
  lwd = 2, bty = "n", cex = 1)
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), y = seq(from = 1,#
  to = max(unlist(lapply(MultiReSamples, max))),#
  length.out = max(unlist(lapply(MultiReSamples, length)))), log = "xy",#
  type = "n", xlab = "N Occurrences", ylab = "Genus richness")#
for(i in StageNames) points(x = 1:length(MultiReSamples[[i]]),#
  y = MultiReSamples[[i]], type = "l",#
  col = viridis::viridis(length(StageNames))[StageNames == i], lwd = 2)#
legend("topleft", legend = StageNames, col = viridis::viridis(length(StageNames)),#
  lwd = 2, bty = "n", cex = 1)
#################################################################################
#                                                                              ##
#                   SCRIPT II - RAREFACTION AND BOOTSTRAPPING                  ##
#                                                                              ##
#################################################################################
#
# SCRIPT AIMS:#
##
# 1. Introduce basics of resampling.#
# 2. Learn hot to rarefy and bootstrap data in R.#
# 3. Generate rarefied and bootstrapped richness estimates.#
#
# Make sure the packages are loaded into memory...:#
PackageBundle <- c("devtools", "earth", "iNEXT", "metatree", "nlme", "paleoTS",#
  "plotrix", "praise", "tidyverse", "velociraptr", "viridis")#
for(pkg in c(PackageBundle, "metatree")) try(library(pkg,#
  character.only = TRUE), silent = TRUE)#
#
# ...alongside the data the data into R:#
RawData <- utils::read.csv("https://paleobiodb.org/data1.2/occs/list.csv?base_name=Tetrapoda&interval=Capitanian,Anisian&show=coords,paleoloc,class",#
  header = TRUE, stringsAsFactors = FALSE)#
RawData <- RawData[, c("occurrence_no", "collection_no", "phylum", "class",#
  "order", "family", "genus", "accepted_name", "early_interval",#
  "late_interval", "max_ma", "min_ma", "lng", "lat", "paleolng",#
  "paleolat", "identified_rank")]#
RawData <- dplyr::filter(RawData, nchar(genus) > 0)#
RawData <- dplyr::distinct(RawData, accepted_name, collection_no,#
  .keep_all = TRUE)#
StageNames <- c("Capitanian", "Wuchiapingian", "Changhsingian", "Induan",#
  "Olenekian", "Anisian")#
StageMidpoints <- c(263.1, 257, 253.2, 251.7, 249.2, 244.6)#
RawData <- dplyr::filter(RawData, nchar(late_interval) == 0) %>%#
  dplyr::filter(early_interval %in% StageNames)#
CleanData <- lapply(as.list(StageNames), function(x)#
  {unlist(lapply(strsplit(RawData[RawData[, "early_interval"] == x,#
  "genus"], split = " "), function(y) y[1]))})#
names(CleanData) <- StageNames#
#
# One way to deal with sampling bias is to artifically resample the data. This#
# allows us to, for example, quantify and plot the relationship between sampling#
# and the thing we are measuring (here genus richness) as well as set an equal#
# sampling level to use across a range of samples (here six geologic stages#
# spanning the Permian-Traissic extinction). A great many packages include#
# functions to perform the two resamling methods we will use here (rarefaction#
# and bootstrapping), but we will just write our own code as the process is#
# simple enough and it should aid understanding and avoid "black boxes".#
##
# Both resampling processes can be coded in R using a simple base R function#
# called "sample". We can see what this does if just give it the numbers 1:10:#
base::sample(1:10)#
#
# You shoudl see it basically "shuffles" them. try running it a few times to#
# confirm that the answer will vary:#
base::sample(1:10)#
base::sample(1:10)#
base::sample(1:10)#
base::sample(1:10)#
base::sample(1:10)#
#
# We can imagine each number represents a fossil and we are artifically#
# creating an order in which they could have been discovered. However, here#
# we want to know not the number of the fossil but the taxon to which it is#
# assigned. Let's use our real data (brachiopods from the Induan stage)#
# instead of numbers:#
sample(CleanData[["Induan"]])#
#
# Again, if we try it a few times we should see that it varies:#
sample(CleanData[["Induan"]])#
sample(CleanData[["Induan"]])#
sample(CleanData[["Induan"]])#
sample(CleanData[["Induan"]])#
sample(CleanData[["Induan"]])#
#
# Note that it might *appear* to change quite often as some names are#
# duplicated, but remember that "underneath" it we could be sampling fossil 1#
# of genus A followed by fossil two of genus A one time and fossil 2 followed#
# by fossil 1 another time and we would just see genus A twice in a row both#
# ways.#
##
# Now, to really mimic sampling verus richness what we want to record across#
# our resample (from left to right) are two things: 1) the sample size and 2)#
# the number of unique genera sampled. Thus for the first value this is going#
# to be one (fossil/occurrence) and one (genus):#
ReSample <- sample(CleanData[["Induan"]])#
ReSample[1]#
#
# Whereas for the next value it will be two (fossils/occurrences), but#
# possibly either one (if our genus from before is sampled again) or two if#
# we now sample a different genus:#
ReSample[1:2]#
#
# It would be tedious to continue in this way manually, so let's write a#
# little function to do this job for us (including counting the unique#
# names in each size sample)...:#
ReSampler <- function(NamesVector) {ShuffledSample <- sample(NamesVector);#
  matrix(c(1:length(ShuffledSample),#
  unlist(lapply(as.list(1:length(ShuffledSample)),#
  function(x) length(unique(ShuffledSample[1:x]))))), nrow = 2, byrow = TRUE,#
  dimnames = list(c("SampleSize", "NUnique"), c()))}#
#
# ...and apply it to the Induan brachiopods:#
ReSampler(CleanData[["Induan"]])#
#
# Note that sample size will always increment up by one on the top row, but the#
# bottom row can vary each time:#
ReSampler(CleanData[["Induan"]])#
ReSampler(CleanData[["Induan"]])#
ReSampler(CleanData[["Induan"]])#
ReSampler(CleanData[["Induan"]])#
ReSampler(CleanData[["Induan"]])#
#
# Thus we really want to repeat this process multiple times so we can get (for#
# example) a mean expectation for number of genera based on a given number of#
# fossil occurrences. Again, manually doing this would be tedious, so lets's#
# write some code to do it...:#
MultiReSampler <- function(NamesVector, NReplicates) apply(do.call(rbind,#
  lapply(as.list(1:NReplicates),#
  function(x) ReSampler(NamesVector)["NUnique", ])), 2, mean)#
#
# ...and test it out 100 times:#
MultiReSamples <- MultiReSampler(NamesVector = CleanData[["Induan"]],#
  NReplicates = 100)#
MultiReSamples#
#
# These results are best understood graphically:#
plot(x = 1:length(MultiReSamples), y = MultiReSamples, xlab = "N Occurrences",#
  ylab = "Genus richness (N unique genera)", type = "l")#
#
# What we have here is a rarefaction curve. It clearly shows that as we add#
# samples (go from left to right) we also add divesrity (genus richness).#
# Let's try this again, but with a different stage, the Anisian:#
MultiReSamples <- MultiReSampler(NamesVector = CleanData[["Anisian"]],#
  NReplicates = 100)#
plot(x = 1:length(MultiReSamples), y = MultiReSamples, xlab = "N Occurrences",#
  ylab = "Genus richness (N unique genera)", type = "l")#
#
# You should se this is a much larger sample (x-axis extends to much higher#
# values). But also that the shape of the curve is now much clearer and appears#
# to be asymptoting (i.e. it gets less steep fom left to right). Now let's#
# produce a plot where we use all our stages so we can see the various#
# rarefaction curves simultaneously (this might take a while to run):#
MultiReSamples <- lapply(as.list(StageNames), function(x)#
  MultiReSampler(NamesVector = CleanData[[x]], NReplicates = 100))#
names(MultiReSamples) <- StageNames#
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), y = seq(from = 1,#
  to = max(unlist(lapply(MultiReSamples, max))),#
  length.out = max(unlist(lapply(MultiReSamples, length)))), log = "xy",#
  type = "n", xlab = "N Occurrences", ylab = "Genus richness")#
for(i in StageNames) points(x = 1:length(MultiReSamples[[i]]),#
  y = MultiReSamples[[i]], type = "l",#
  col = viridis::viridis(length(StageNames))[StageNames == i], lwd = 2)#
legend("topleft", legend = StageNames, col = viridis::viridis(length(StageNames)),#
  lwd = 2, bty = "n", cex = 1)
#################################################################################
#                                                                              ##
#                   SCRIPT II - RAREFACTION AND BOOTSTRAPPING                  ##
#                                                                              ##
#################################################################################
#
# SCRIPT AIMS:#
##
# 1. Introduce basics of resampling.#
# 2. Learn hot to rarefy and bootstrap data in R.#
# 3. Generate rarefied and bootstrapped richness estimates.#
#
# Make sure the packages are loaded into memory...:#
PackageBundle <- c("devtools", "earth", "iNEXT", "metatree", "nlme", "paleoTS",#
  "plotrix", "praise", "tidyverse", "velociraptr", "viridis")#
for(pkg in c(PackageBundle, "metatree")) try(library(pkg,#
  character.only = TRUE), silent = TRUE)#
#
# ...alongside the data the data into R:#
RawData <- utils::read.csv("https://paleobiodb.org/data1.2/occs/list.csv?base_name=Tetrapoda&interval=Capitanian,Norian&show=coords,paleoloc,class",#
  header = TRUE, stringsAsFactors = FALSE)#
RawData <- RawData[, c("occurrence_no", "collection_no", "phylum", "class",#
  "order", "family", "genus", "accepted_name", "early_interval",#
  "late_interval", "max_ma", "min_ma", "lng", "lat", "paleolng",#
  "paleolat", "identified_rank")]#
RawData <- dplyr::filter(RawData, nchar(genus) > 0)#
RawData <- dplyr::distinct(RawData, accepted_name, collection_no,#
  .keep_all = TRUE)#
StageNames <- c("Capitanian", "Wuchiapingian", "Changhsingian", "Induan",#
  "Olenekian", "Anisian", "Ladinian", "Carnian", "Norian")#
StageMidpoints <- c(263.1, 257, 253.2, 251.7, 249.2, 244.6, 239.5, 232, 217.75)#
RawData <- dplyr::filter(RawData, nchar(late_interval) == 0) %>%#
  dplyr::filter(early_interval %in% StageNames)#
CleanData <- lapply(as.list(StageNames), function(x)#
  {unlist(lapply(strsplit(RawData[RawData[, "early_interval"] == x,#
  "genus"], split = " "), function(y) y[1]))})#
names(CleanData) <- StageNames#
#
# One way to deal with sampling bias is to artifically resample the data. This#
# allows us to, for example, quantify and plot the relationship between sampling#
# and the thing we are measuring (here genus richness) as well as set an equal#
# sampling level to use across a range of samples (here six geologic stages#
# spanning the Permian-Traissic extinction). A great many packages include#
# functions to perform the two resamling methods we will use here (rarefaction#
# and bootstrapping), but we will just write our own code as the process is#
# simple enough and it should aid understanding and avoid "black boxes".#
##
# Both resampling processes can be coded in R using a simple base R function#
# called "sample". We can see what this does if just give it the numbers 1:10:#
base::sample(1:10)#
#
# You shoudl see it basically "shuffles" them. try running it a few times to#
# confirm that the answer will vary:#
base::sample(1:10)#
base::sample(1:10)#
base::sample(1:10)#
base::sample(1:10)#
base::sample(1:10)#
#
# We can imagine each number represents a fossil and we are artifically#
# creating an order in which they could have been discovered. However, here#
# we want to know not the number of the fossil but the taxon to which it is#
# assigned. Let's use our real data (brachiopods from the Induan stage)#
# instead of numbers:#
sample(CleanData[["Induan"]])#
#
# Again, if we try it a few times we should see that it varies:#
sample(CleanData[["Induan"]])#
sample(CleanData[["Induan"]])#
sample(CleanData[["Induan"]])#
sample(CleanData[["Induan"]])#
sample(CleanData[["Induan"]])#
#
# Note that it might *appear* to change quite often as some names are#
# duplicated, but remember that "underneath" it we could be sampling fossil 1#
# of genus A followed by fossil two of genus A one time and fossil 2 followed#
# by fossil 1 another time and we would just see genus A twice in a row both#
# ways.#
##
# Now, to really mimic sampling verus richness what we want to record across#
# our resample (from left to right) are two things: 1) the sample size and 2)#
# the number of unique genera sampled. Thus for the first value this is going#
# to be one (fossil/occurrence) and one (genus):#
ReSample <- sample(CleanData[["Induan"]])#
ReSample[1]#
#
# Whereas for the next value it will be two (fossils/occurrences), but#
# possibly either one (if our genus from before is sampled again) or two if#
# we now sample a different genus:#
ReSample[1:2]#
#
# It would be tedious to continue in this way manually, so let's write a#
# little function to do this job for us (including counting the unique#
# names in each size sample)...:#
ReSampler <- function(NamesVector) {ShuffledSample <- sample(NamesVector);#
  matrix(c(1:length(ShuffledSample),#
  unlist(lapply(as.list(1:length(ShuffledSample)),#
  function(x) length(unique(ShuffledSample[1:x]))))), nrow = 2, byrow = TRUE,#
  dimnames = list(c("SampleSize", "NUnique"), c()))}#
#
# ...and apply it to the Induan brachiopods:#
ReSampler(CleanData[["Induan"]])#
#
# Note that sample size will always increment up by one on the top row, but the#
# bottom row can vary each time:#
ReSampler(CleanData[["Induan"]])#
ReSampler(CleanData[["Induan"]])#
ReSampler(CleanData[["Induan"]])#
ReSampler(CleanData[["Induan"]])#
ReSampler(CleanData[["Induan"]])#
#
# Thus we really want to repeat this process multiple times so we can get (for#
# example) a mean expectation for number of genera based on a given number of#
# fossil occurrences. Again, manually doing this would be tedious, so lets's#
# write some code to do it...:#
MultiReSampler <- function(NamesVector, NReplicates) apply(do.call(rbind,#
  lapply(as.list(1:NReplicates),#
  function(x) ReSampler(NamesVector)["NUnique", ])), 2, mean)#
#
# ...and test it out 100 times:#
MultiReSamples <- MultiReSampler(NamesVector = CleanData[["Induan"]],#
  NReplicates = 100)#
MultiReSamples#
#
# These results are best understood graphically:#
plot(x = 1:length(MultiReSamples), y = MultiReSamples, xlab = "N Occurrences",#
  ylab = "Genus richness (N unique genera)", type = "l")#
#
# What we have here is a rarefaction curve. It clearly shows that as we add#
# samples (go from left to right) we also add divesrity (genus richness).#
# Let's try this again, but with a different stage, the Anisian:#
MultiReSamples <- MultiReSampler(NamesVector = CleanData[["Anisian"]],#
  NReplicates = 100)#
plot(x = 1:length(MultiReSamples), y = MultiReSamples, xlab = "N Occurrences",#
  ylab = "Genus richness (N unique genera)", type = "l")#
#
# You should se this is a much larger sample (x-axis extends to much higher#
# values). But also that the shape of the curve is now much clearer and appears#
# to be asymptoting (i.e. it gets less steep fom left to right). Now let's#
# produce a plot where we use all our stages so we can see the various#
# rarefaction curves simultaneously (this might take a while to run):#
MultiReSamples <- lapply(as.list(StageNames), function(x)#
  MultiReSampler(NamesVector = CleanData[[x]], NReplicates = 100))#
names(MultiReSamples) <- StageNames#
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), y = seq(from = 1,#
  to = max(unlist(lapply(MultiReSamples, max))),#
  length.out = max(unlist(lapply(MultiReSamples, length)))), log = "xy",#
  type = "n", xlab = "N Occurrences", ylab = "Genus richness")#
for(i in StageNames) points(x = 1:length(MultiReSamples[[i]]),#
  y = MultiReSamples[[i]], type = "l",#
  col = viridis::viridis(length(StageNames))[StageNames == i], lwd = 2)#
legend("topleft", legend = StageNames, col = viridis::viridis(length(StageNames)),#
  lwd = 2, bty = "n", cex = 1)
#################################################################################
#                                                                              ##
#                   SCRIPT II - RAREFACTION AND BOOTSTRAPPING                  ##
#                                                                              ##
#################################################################################
#
# SCRIPT AIMS:#
##
# 1. Introduce basics of resampling.#
# 2. Learn hot to rarefy and bootstrap data in R.#
# 3. Generate rarefied and bootstrapped richness estimates.#
#
# Make sure the packages are loaded into memory...:#
PackageBundle <- c("devtools", "earth", "iNEXT", "metatree", "nlme", "paleoTS",#
  "plotrix", "praise", "tidyverse", "velociraptr", "viridis")#
for(pkg in c(PackageBundle, "metatree")) try(library(pkg,#
  character.only = TRUE), silent = TRUE)#
#
# ...alongside the data the data into R:#
RawData <- utils::read.csv("https://paleobiodb.org/data1.2/occs/list.csv?base_name=Bivalvia&interval=Capitanian,Norian&show=coords,paleoloc,class",#
  header = TRUE, stringsAsFactors = FALSE)#
RawData <- RawData[, c("occurrence_no", "collection_no", "phylum", "class",#
  "order", "family", "genus", "accepted_name", "early_interval",#
  "late_interval", "max_ma", "min_ma", "lng", "lat", "paleolng",#
  "paleolat", "identified_rank")]#
RawData <- dplyr::filter(RawData, nchar(genus) > 0)#
RawData <- dplyr::distinct(RawData, accepted_name, collection_no,#
  .keep_all = TRUE)#
StageNames <- c("Capitanian", "Wuchiapingian", "Changhsingian", "Induan",#
  "Olenekian", "Anisian", "Ladinian", "Carnian", "Norian")#
StageMidpoints <- c(263.1, 257, 253.2, 251.7, 249.2, 244.6, 239.5, 232, 217.75)#
RawData <- dplyr::filter(RawData, nchar(late_interval) == 0) %>%#
  dplyr::filter(early_interval %in% StageNames)#
CleanData <- lapply(as.list(StageNames), function(x)#
  {unlist(lapply(strsplit(RawData[RawData[, "early_interval"] == x,#
  "genus"], split = " "), function(y) y[1]))})#
names(CleanData) <- StageNames#
#
# One way to deal with sampling bias is to artifically resample the data. This#
# allows us to, for example, quantify and plot the relationship between sampling#
# and the thing we are measuring (here genus richness) as well as set an equal#
# sampling level to use across a range of samples (here six geologic stages#
# spanning the Permian-Traissic extinction). A great many packages include#
# functions to perform the two resamling methods we will use here (rarefaction#
# and bootstrapping), but we will just write our own code as the process is#
# simple enough and it should aid understanding and avoid "black boxes".#
##
# Both resampling processes can be coded in R using a simple base R function#
# called "sample". We can see what this does if just give it the numbers 1:10:#
base::sample(1:10)#
#
# You shoudl see it basically "shuffles" them. try running it a few times to#
# confirm that the answer will vary:#
base::sample(1:10)#
base::sample(1:10)#
base::sample(1:10)#
base::sample(1:10)#
base::sample(1:10)#
#
# We can imagine each number represents a fossil and we are artifically#
# creating an order in which they could have been discovered. However, here#
# we want to know not the number of the fossil but the taxon to which it is#
# assigned. Let's use our real data (brachiopods from the Induan stage)#
# instead of numbers:#
sample(CleanData[["Induan"]])#
#
# Again, if we try it a few times we should see that it varies:#
sample(CleanData[["Induan"]])#
sample(CleanData[["Induan"]])#
sample(CleanData[["Induan"]])#
sample(CleanData[["Induan"]])#
sample(CleanData[["Induan"]])#
#
# Note that it might *appear* to change quite often as some names are#
# duplicated, but remember that "underneath" it we could be sampling fossil 1#
# of genus A followed by fossil two of genus A one time and fossil 2 followed#
# by fossil 1 another time and we would just see genus A twice in a row both#
# ways.#
##
# Now, to really mimic sampling verus richness what we want to record across#
# our resample (from left to right) are two things: 1) the sample size and 2)#
# the number of unique genera sampled. Thus for the first value this is going#
# to be one (fossil/occurrence) and one (genus):#
ReSample <- sample(CleanData[["Induan"]])#
ReSample[1]#
#
# Whereas for the next value it will be two (fossils/occurrences), but#
# possibly either one (if our genus from before is sampled again) or two if#
# we now sample a different genus:#
ReSample[1:2]#
#
# It would be tedious to continue in this way manually, so let's write a#
# little function to do this job for us (including counting the unique#
# names in each size sample)...:#
ReSampler <- function(NamesVector) {ShuffledSample <- sample(NamesVector);#
  matrix(c(1:length(ShuffledSample),#
  unlist(lapply(as.list(1:length(ShuffledSample)),#
  function(x) length(unique(ShuffledSample[1:x]))))), nrow = 2, byrow = TRUE,#
  dimnames = list(c("SampleSize", "NUnique"), c()))}#
#
# ...and apply it to the Induan brachiopods:#
ReSampler(CleanData[["Induan"]])#
#
# Note that sample size will always increment up by one on the top row, but the#
# bottom row can vary each time:#
ReSampler(CleanData[["Induan"]])#
ReSampler(CleanData[["Induan"]])#
ReSampler(CleanData[["Induan"]])#
ReSampler(CleanData[["Induan"]])#
ReSampler(CleanData[["Induan"]])#
#
# Thus we really want to repeat this process multiple times so we can get (for#
# example) a mean expectation for number of genera based on a given number of#
# fossil occurrences. Again, manually doing this would be tedious, so lets's#
# write some code to do it...:#
MultiReSampler <- function(NamesVector, NReplicates) apply(do.call(rbind,#
  lapply(as.list(1:NReplicates),#
  function(x) ReSampler(NamesVector)["NUnique", ])), 2, mean)#
#
# ...and test it out 100 times:#
MultiReSamples <- MultiReSampler(NamesVector = CleanData[["Induan"]],#
  NReplicates = 100)#
MultiReSamples#
#
# These results are best understood graphically:#
plot(x = 1:length(MultiReSamples), y = MultiReSamples, xlab = "N Occurrences",#
  ylab = "Genus richness (N unique genera)", type = "l")#
#
# What we have here is a rarefaction curve. It clearly shows that as we add#
# samples (go from left to right) we also add divesrity (genus richness).#
# Let's try this again, but with a different stage, the Anisian:#
MultiReSamples <- MultiReSampler(NamesVector = CleanData[["Anisian"]],#
  NReplicates = 100)#
plot(x = 1:length(MultiReSamples), y = MultiReSamples, xlab = "N Occurrences",#
  ylab = "Genus richness (N unique genera)", type = "l")#
#
# You should se this is a much larger sample (x-axis extends to much higher#
# values). But also that the shape of the curve is now much clearer and appears#
# to be asymptoting (i.e. it gets less steep fom left to right). Now let's#
# produce a plot where we use all our stages so we can see the various#
# rarefaction curves simultaneously (this might take a while to run):#
MultiReSamples <- lapply(as.list(StageNames), function(x)#
  MultiReSampler(NamesVector = CleanData[[x]], NReplicates = 100))#
names(MultiReSamples) <- StageNames#
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), y = seq(from = 1,#
  to = max(unlist(lapply(MultiReSamples, max))),#
  length.out = max(unlist(lapply(MultiReSamples, length)))), log = "xy",#
  type = "n", xlab = "N Occurrences", ylab = "Genus richness")#
for(i in StageNames) points(x = 1:length(MultiReSamples[[i]]),#
  y = MultiReSamples[[i]], type = "l",#
  col = viridis::viridis(length(StageNames))[StageNames == i], lwd = 2)#
legend("topleft", legend = StageNames, col = viridis::viridis(length(StageNames)),#
  lwd = 2, bty = "n", cex = 1)
#################################################################################
#                                                                              ##
#                   SCRIPT II - RAREFACTION AND BOOTSTRAPPING                  ##
#                                                                              ##
#################################################################################
#
# SCRIPT AIMS:#
##
# 1. Introduce basics of resampling.#
# 2. Learn hot to rarefy and bootstrap data in R.#
# 3. Generate rarefied and bootstrapped richness estimates.#
#
# Make sure the packages are loaded into memory...:#
PackageBundle <- c("devtools", "earth", "iNEXT", "metatree", "nlme", "paleoTS",#
  "plotrix", "praise", "tidyverse", "velociraptr", "viridis")#
for(pkg in c(PackageBundle, "metatree")) try(library(pkg,#
  character.only = TRUE), silent = TRUE)#
#
# ...alongside the data the data into R:#
RawData <- utils::read.csv("https://paleobiodb.org/data1.2/occs/list.csv?base_name=Bivalvia&interval=Capitanian,Norian&show=coords,paleoloc,class",#
  header = TRUE, stringsAsFactors = FALSE)#
RawData <- RawData[, c("occurrence_no", "collection_no", "phylum", "class",#
  "order", "family", "genus", "accepted_name", "early_interval",#
  "late_interval", "max_ma", "min_ma", "lng", "lat", "paleolng",#
  "paleolat", "identified_rank")]#
RawData <- dplyr::filter(RawData, nchar(genus) > 0)#
RawData <- dplyr::distinct(RawData, accepted_name, collection_no,#
  .keep_all = TRUE)#
StageNames <- c("Capitanian", "Wuchiapingian", "Changhsingian", "Induan",#
  "Olenekian", "Anisian")#
StageMidpoints <- c(263.1, 257, 253.2, 251.7, 249.2, 244.6)#
RawData <- dplyr::filter(RawData, nchar(late_interval) == 0) %>%#
  dplyr::filter(early_interval %in% StageNames)#
CleanData <- lapply(as.list(StageNames), function(x)#
  {unlist(lapply(strsplit(RawData[RawData[, "early_interval"] == x,#
  "genus"], split = " "), function(y) y[1]))})#
names(CleanData) <- StageNames#
#
# One way to deal with sampling bias is to artifically resample the data. This#
# allows us to, for example, quantify and plot the relationship between sampling#
# and the thing we are measuring (here genus richness) as well as set an equal#
# sampling level to use across a range of samples (here six geologic stages#
# spanning the Permian-Traissic extinction). A great many packages include#
# functions to perform the two resamling methods we will use here (rarefaction#
# and bootstrapping), but we will just write our own code as the process is#
# simple enough and it should aid understanding and avoid "black boxes".#
##
# Both resampling processes can be coded in R using a simple base R function#
# called "sample". We can see what this does if just give it the numbers 1:10:#
base::sample(1:10)#
#
# You shoudl see it basically "shuffles" them. try running it a few times to#
# confirm that the answer will vary:#
base::sample(1:10)#
base::sample(1:10)#
base::sample(1:10)#
base::sample(1:10)#
base::sample(1:10)#
#
# We can imagine each number represents a fossil and we are artifically#
# creating an order in which they could have been discovered. However, here#
# we want to know not the number of the fossil but the taxon to which it is#
# assigned. Let's use our real data (brachiopods from the Induan stage)#
# instead of numbers:#
sample(CleanData[["Induan"]])#
#
# Again, if we try it a few times we should see that it varies:#
sample(CleanData[["Induan"]])#
sample(CleanData[["Induan"]])#
sample(CleanData[["Induan"]])#
sample(CleanData[["Induan"]])#
sample(CleanData[["Induan"]])#
#
# Note that it might *appear* to change quite often as some names are#
# duplicated, but remember that "underneath" it we could be sampling fossil 1#
# of genus A followed by fossil two of genus A one time and fossil 2 followed#
# by fossil 1 another time and we would just see genus A twice in a row both#
# ways.#
##
# Now, to really mimic sampling verus richness what we want to record across#
# our resample (from left to right) are two things: 1) the sample size and 2)#
# the number of unique genera sampled. Thus for the first value this is going#
# to be one (fossil/occurrence) and one (genus):#
ReSample <- sample(CleanData[["Induan"]])#
ReSample[1]#
#
# Whereas for the next value it will be two (fossils/occurrences), but#
# possibly either one (if our genus from before is sampled again) or two if#
# we now sample a different genus:#
ReSample[1:2]#
#
# It would be tedious to continue in this way manually, so let's write a#
# little function to do this job for us (including counting the unique#
# names in each size sample)...:#
ReSampler <- function(NamesVector) {ShuffledSample <- sample(NamesVector);#
  matrix(c(1:length(ShuffledSample),#
  unlist(lapply(as.list(1:length(ShuffledSample)),#
  function(x) length(unique(ShuffledSample[1:x]))))), nrow = 2, byrow = TRUE,#
  dimnames = list(c("SampleSize", "NUnique"), c()))}#
#
# ...and apply it to the Induan brachiopods:#
ReSampler(CleanData[["Induan"]])#
#
# Note that sample size will always increment up by one on the top row, but the#
# bottom row can vary each time:#
ReSampler(CleanData[["Induan"]])#
ReSampler(CleanData[["Induan"]])#
ReSampler(CleanData[["Induan"]])#
ReSampler(CleanData[["Induan"]])#
ReSampler(CleanData[["Induan"]])#
#
# Thus we really want to repeat this process multiple times so we can get (for#
# example) a mean expectation for number of genera based on a given number of#
# fossil occurrences. Again, manually doing this would be tedious, so lets's#
# write some code to do it...:#
MultiReSampler <- function(NamesVector, NReplicates) apply(do.call(rbind,#
  lapply(as.list(1:NReplicates),#
  function(x) ReSampler(NamesVector)["NUnique", ])), 2, mean)#
#
# ...and test it out 100 times:#
MultiReSamples <- MultiReSampler(NamesVector = CleanData[["Induan"]],#
  NReplicates = 100)#
MultiReSamples#
#
# These results are best understood graphically:#
plot(x = 1:length(MultiReSamples), y = MultiReSamples, xlab = "N Occurrences",#
  ylab = "Genus richness (N unique genera)", type = "l")#
#
# What we have here is a rarefaction curve. It clearly shows that as we add#
# samples (go from left to right) we also add divesrity (genus richness).#
# Let's try this again, but with a different stage, the Anisian:#
MultiReSamples <- MultiReSampler(NamesVector = CleanData[["Anisian"]],#
  NReplicates = 100)#
plot(x = 1:length(MultiReSamples), y = MultiReSamples, xlab = "N Occurrences",#
  ylab = "Genus richness (N unique genera)", type = "l")#
#
# You should se this is a much larger sample (x-axis extends to much higher#
# values). But also that the shape of the curve is now much clearer and appears#
# to be asymptoting (i.e. it gets less steep fom left to right). Now let's#
# produce a plot where we use all our stages so we can see the various#
# rarefaction curves simultaneously (this might take a while to run):#
MultiReSamples <- lapply(as.list(StageNames), function(x)#
  MultiReSampler(NamesVector = CleanData[[x]], NReplicates = 100))#
names(MultiReSamples) <- StageNames#
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), y = seq(from = 1,#
  to = max(unlist(lapply(MultiReSamples, max))),#
  length.out = max(unlist(lapply(MultiReSamples, length)))), log = "xy",#
  type = "n", xlab = "N Occurrences", ylab = "Genus richness")#
for(i in StageNames) points(x = 1:length(MultiReSamples[[i]]),#
  y = MultiReSamples[[i]], type = "l",#
  col = viridis::viridis(length(StageNames))[StageNames == i], lwd = 2)#
legend("topleft", legend = StageNames, col = viridis::viridis(length(StageNames)),#
  lwd = 2, bty = "n", cex = 1)
MultiReSamples <- lapply(as.list(StageNames), function(x)#
  MultiReSampler(NamesVector = CleanData[[x]], NReplicates = 100))#
names(MultiReSamples) <- StageNames#
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), y = seq(from = 1,#
  to = max(unlist(lapply(MultiReSamples, max))),#
  length.out = max(unlist(lapply(MultiReSamples, length)))), log = "xy",#
  type = "n", xlab = "N Occurrences", ylab = "Genus richness")#
for(i in StageNames) points(x = 1:length(MultiReSamples[[i]]),#
  y = MultiReSamples[[i]], type = "l",#
  col = viridis::viridis(length(StageNames))[StageNames == i], lwd = 2)#
legend("topleft", legend = StageNames, col = viridis::viridis(length(StageNames)),#
  lwd = 2, bty = "n", cex = 1)
#################################################################################
#                                                                              ##
#                SCRIPT I - SETUP AND GETTING PBDB DATA INTO R                 ##
#                                                                              ##
#################################################################################
#
# SCRIPT AIMS:#
##
# 1. Install and load the packages required for the workshop.#
# 2. Introduce the PBDB and its' API.#
# 3. Get some example data into R for use in the later scripts.#
#
# First up we need to install the packages we will want to use (note this may#
# take a while and you might be prompted to install additional packages):#
PackageBundle <- c("devtools", "earth", "iNEXT", "nlme", "paleoTS", "plotrix",#
  "praise", "tidyverse", "velociraptr", "viridis")#
utils::install.packages(PackageBundle, dependencies = TRUE)#
devtools::install_github("graemetlloyd/metatree")#
#
# And load these into memory:#
for(pkg in c(PackageBundle, "metatree")) try(library(pkg,#
  character.only = TRUE), silent = TRUE)#
#
# If you are familiar with R then you will know the hardest part in using a#
# package or script is to get your data into R in the format required by the#
# functions you want to use. Here we are going to take advantage of the#
# Paleobiology Database's "API" (short for Application Programming Interface),#
# which lets us "download" data directly into R. We are also going to use as#
# an example data set Permo-Triassic bivalves.#
##
# We can begin by setting up some variables:#
Taxa <- "Bivalvia" # Set "Taxa" as the taxonomic group of interest#
StartInterval <- "Capitanian" # Set start interval for sampling window#
StopInterval <- "Anisian" # Set stop interval for sampling window#
#
# In case you want to alter these to your own purposes then you should also#
# run the following lines which will ensure things get fromatted properly#
# for use with the API:#
Taxa <- paste(Taxa, collapse = ",")#
StartInterval <- gsub(" ", "%20", StartInterval)#
StopInterval <- gsub(" ", "%20", StopInterval)#
#
# We are now ready to use the API, but to do we have to produce a formatted#
# URL (Uniform Resource Locator; i.e., a web address).#
##
# These will always begin with:#
"https://paleobiodb.org/data1.2"#
#
# This is simply the top-level of the database with data1.2 indicating we#
# are using version 1.2 (the latest version) of the API. Next we want the#
# type of query, here we want some fossil occurrences (which is what most#
# queries are going to be). Here we are going to ask for them as a CSV#
# (comma-separated values):#
"https://paleobiodb.org/data1.2/occs/list.csv"#
#
# It is important to note that this means R will assume any comma it finds#
# in the output represents a division between columns of data. This means#
# if any of the data fields we want output contain a comma things are going#
# to break and hence why other formats (e.g., JSON) are also available).#
# Here we should be fine though.#
##
# Next we need to tell the database what taxon we actually want data for, so#
# we can use our Taxa variable from above with:#
paste0("https://paleobiodb.org/data1.2/occs/list.csv?base_name=", Taxa)#
#
# It is worth pointing out that, again, things can go wrong this way if#
# names are duplicated in the database. An example is the genus "Glyptolepis"#
# which is both a plant (type of conifer)...:#
utils::browseURL("https://paleobiodb.org/classic/basicTaxonInfo?taxon_no=291933")#
#
# ...and a fish (lobe-fin):#
utils::browseURL("https://paleobiodb.org/classic/basicTaxonInfo?taxon_no=34920")#
#
# Thus if we ask the database for Glyptolepis the response from the database#
# might not be what you expect. Let's skip ahead and ask for this data to#
# see what happens:#
utils::read.csv("https://paleobiodb.org/data1.2/occs/list.csv?base_name=Glyptolepis&show=coords,paleoloc,class&limit=all", header = T, na.strings = "")#
#
# Instead of an error message (there are two Glyptotlepises!) the API just#
# goes with one of them (the plant). Note this is not happening because#
# there are no occurrences of the fish in the database. We can check that#
# this is true by asking for the "right" Glyptolepis (at least if you are a#
# fish person) with:#
utils::read.csv("https://paleobiodb.org/data1.2/occs/list.csv?taxon_id=34920&show=coords,paleoloc,class&limit=all",#
  header = T, na.strings = "")#
#
# Thus if you *really* want to be sure you are getting the data you want you#
# should use taxon_id= and the taxon number, and not base_name= and the taxon#
# name. Again, with nrachiopods we are OK, but remember that the ICZN and#
# ICBN are separate entities so there is nothing to stop someone naming a#
# group of plants Bivalvia!#
##
# Now we have stated what taxon we want the next thing to do is add any#
# additional options we want to add to our query. The obvious one here is the#
# sampling window. We can do this with the interval= option and as this is an#
# addition to the query we proceed it with an ampersand (&):#
paste0("https://paleobiodb.org/data1.2/occs/list.csv?base_name=", Taxa,#
  "&interval=", StartInterval, ",", StopInterval)#
#
# Note that the start and end of the interval have to be separated by a comma.#
##
# We can now add some additional options for what we want the output to include#
# with show=. If you want multiple things, agaian, these must be seoarated by#
# commas. Here we will ask for coordinate data (coords), palaeo-locality data#
# (paleoloc) and taxonomic hierarchy data (class):#
paste0("https://paleobiodb.org/data1.2/occs/list.csv?base_name=", Taxa,#
  "&interval=", StartInterval, ",", StopInterval,#
  "&show=coords,paleoloc,class")#
#
# One final tip is to make sure you only get "regular" taxa and not something#
# from a parataxonomy (like egg or footprint "species") with the pres= option#
# and the value "regular":#
paste0("https://paleobiodb.org/data1.2/occs/list.csv?base_name=", Taxa,#
  "&interval=", StartInterval, ",", StopInterval,#
  "&show=coords,paleoloc,class&pres=regular")#
#
# Now we have a complete URL we can store it in a variable...:#
URL <- paste0("https://paleobiodb.org/data1.2/occs/list.csv?base_name=",#
  Taxa, "&interval=", StartInterval, ",", StopInterval,#
  "&show=coords,paleoloc,class&pres=regular")#
#
# ...and then use the read.csv function to read the data into R:#
RawData <- utils::read.csv(URL, header = TRUE, stringsAsFactors = FALSE)#
#
# This is a lot of data!:#
nrow(RawData)#
#
# So best to just look at part of it to begin with:#
head(RawData)#
#
# Note that you can do similar queries in packages such as velociraptr or#
# metatree, e.g.:#
VRData <- velociraptr::downloadPBDB(Taxa = Taxa, StartInterval = StartInterval, StopInterval = StopInterval)#
MTData <- metatree::PaleobiologyDBOccurrenceQuerier(unlist(lapply(apply(#
  metatree::PaleobiologyDBChildFinder("1", Taxa, interval = c(StartInterval,#
  StopInterval), returnrank = "3"), 1, list), function(x) {x <-#
  unlist(x)[c("OriginalTaxonNo", "ResolvedTaxonNo")]; gsub("txn:|var:",#
  "", unname(x[!is.na(x)][1]))})))#
#
# But here we will stick with manual use of the API as it gives us more#
# options/control of the output.#
##
# Importantly, you should never take a raw data query like these and use it#
# without some kind of scrutiny. But first we will simply trim away some of#
# the database fields (columns) we don't really need:#
RawData <- RawData[, c("occurrence_no", "collection_no", "phylum", "class",#
  "order", "family", "genus", "accepted_name", "early_interval",#
  "late_interval", "max_ma", "min_ma", "lng", "lat", "paleolng",#
  "paleolat", "identified_rank")]#
#
# We have already excluded egg and trace fossils ("form taxa" in the language#
# of the PBDB), but we also have a bunch of fossils that are only assignable#
# to some higher-level group:#
unique(RawData[, "identified_rank"])#
#
# There are clever ways some of these can be used to set some minimum level#
# of species diversity where no lower-level taxa are known, but for now we#
# will simply remove anything above genus-level (the level of analysis we#
# will use here):#
RawData <- dplyr::filter(RawData, nchar(genus) > 0)#
#
# We can see this has shrunk the data, but not by much:#
nrow(RawData)#
#
# Anotehr important issue to consider is that synonymisation of taxa in the#
# PBDB can lead to separate entries with the same name (as junior synonyms are#
# replaced with their senior counterparts. If you want to know about richness#
# this is an issue, as it artificially inflates your estimate.#
##
#  We can stop this from happening by stripping out combinations of the same#
# collection no. AND accepted name.#
RawData <- dplyr::distinct(RawData, accepted_name, collection_no,#
  .keep_all = TRUE)#
#
# This has shrunk our data a little more:#
nrow(RawData)#
#
# Next we will consider occurrences not assigned to the stage(s) we want to#
# use as out time bins, but first we need to explicitly state what these are:#
StageNames <- c("Capitanian", "Wuchiapingian", "Changhsingian", "Induan",#
  "Olenekian", "Anisian")#
#
# Whilst we are at it we will also create a vector of stage midpoints we can#
# use later for (e.g.) plots:#
StageMidpoints <- c(263.1, 257, 253.2, 251.7, 249.2, 244.6)#
#
# Now we can use this information to only retain occurrences assigned to#
# *single* one of our named stages with:#
RawData <- dplyr::filter(RawData, nchar(late_interval) == 0) %>%#
  dplyr::filter(early_interval %in% StageNames)#
#
# Note that we are doing this in a simple, automated fashion, which loses#
# lots of occurrences unnecessarily, such as those dated to a single substage#
# or regional biozone and only do so here for ease.#
##
# We can now extract clean data (the genus names for each fossil occurrence)#
# as vectors for each stage and store them as a list:#
CleanData <- lapply(as.list(StageNames), function(x)#
  {unlist(lapply(strsplit(RawData[RawData[, "early_interval"] == x,#
  "genus"], split = " "), function(y) y[1]))})#
#
# And add the stage names for each one:#
names(CleanData) <- StageNames#
#
# We cna then access the names given to each occurrence in a stage with (for#
# the Induan):#
CleanData[["Induan"]]#
#
# Note that this is a small list as these are the occurrences from the first#
# stage after the Permo-Traissic extinction. Things are not looking good for#
# our bivalves.#
##
# We can do a simple (face value) diversity curve with:#
plot(x = StageMidpoints, y = unlist(lapply(CleanData, function(x)#
  length(unique(x)))), xlab = "Time (Ma)", ylab = "Richness (N genera)",#
  type = "l", xlim = c(max(StageMidpoints), min(StageMidpoints)))
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), y = seq(from = 1,#
  to = max(unlist(lapply(MultiReSamples, max))),#
  length.out = max(unlist(lapply(MultiReSamples, length)))), log = "xy",#
  type = "n", xlab = "N Occurrences", ylab = "Genus richness")#
for(i in StageNames) points(x = 1:length(MultiReSamples[[i]]),#
  y = MultiReSamples[[i]], type = "l",#
  col = viridis::viridis(length(StageNames))[StageNames == i], lwd = 2)#
legend("topleft", legend = StageNames, col = viridis::viridis(length(StageNames)),#
  lwd = 2, bty = "n", cex = 1)
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), y = seq(from = 1,#
to = max(unlist(lapply(MultiReSamples, max))),#
length.out = max(unlist(lapply(MultiReSamples, length)))), log = "xy",#
type = "n", xlab = "N Occurrences", ylab = "Genus richness")#
for(i in StageNames) points(x = 1:length(MultiReSamples[[i]]),#
y = MultiReSamples[[i]], type = "l",#
col = viridis::viridis(length(StageNames))[StageNames == i], lwd = 2)#
legend("topleft", legend = StageNames, col = viridis::viridis(length(StageNames)),#
lwd = 2, bty = "n", cex = 1)#
#
SamplingLevel <- 100#
lines(x = c(SamplingLevel, SamplingLevel), y = c(1, 10000), lty = 2, lwd = 1)
par(mfrow=c(2, 1))#
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), y = seq(from = 1,#
  to = max(unlist(lapply(MultiReSamples, max))),#
  length.out = max(unlist(lapply(MultiReSamples, length)))), log = "xy",#
  type = "n", xlab = "N Occurrences", ylab = "Genus richness")#
for(i in StageNames) points(x = 1:length(MultiReSamples[[i]]),#
  y = MultiReSamples[[i]], type = "l",#
  col = viridis::viridis(length(StageNames))[StageNames == i], lwd = 2)#
legend("topleft", legend = StageNames, col = viridis::viridis(length(StageNames)),#
  lwd = 2, bty = "n", cex = 1)#
#
SamplingLevel <- 100#
lines(x = c(SamplingLevel, SamplingLevel), y = c(1, 10000), lty = 2, lwd = 1)#
plot(x = StageMidpoints, y = lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]]), xlab = "Time (Ma)",#
  ylab = "Richness (N genera)", type = "l",#
  xlim = c(max(StageMidpoints), min(StageMidpoints)))
par(mfrow = c(1, 2))#
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), y = seq(from = 1,#
  to = max(unlist(lapply(MultiReSamples, max))),#
  length.out = max(unlist(lapply(MultiReSamples, length)))), log = "xy",#
  type = "n", xlab = "N Occurrences", ylab = "Genus richness")#
for(i in StageNames) points(x = 1:length(MultiReSamples[[i]]),#
  y = MultiReSamples[[i]], type = "l",#
  col = viridis::viridis(length(StageNames))[StageNames == i], lwd = 2)#
legend("topleft", legend = StageNames, col = viridis::viridis(length(StageNames)),#
  lwd = 2, bty = "n", cex = 1)#
#
SamplingLevel <- 100#
lines(x = c(SamplingLevel, SamplingLevel), y = c(1, 10000), lty = 2, lwd = 1)#
plot(x = StageMidpoints, y = lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]]), xlab = "Time (Ma)",#
  ylab = "Richness (N genera)", type = "l",#
  xlim = c(max(StageMidpoints), min(StageMidpoints)))
SamplingLevel <- 100#
par(mfrow = c(1, 2))#
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), y = seq(from = 1,#
  to = max(unlist(lapply(MultiReSamples, max))),#
  length.out = max(unlist(lapply(MultiReSamples, length)))), log = "xy",#
  type = "n", xlab = "N Occurrences", ylab = "Genus richness")#
for(i in StageNames) points(x = 1:length(MultiReSamples[[i]]),#
  y = MultiReSamples[[i]], type = "l",#
  col = viridis::viridis(length(StageNames))[StageNames == i], lwd = 2)#
legend("topleft", legend = StageNames, col = viridis::viridis(length(StageNames)),#
  lwd = 2, bty = "n", cex = 1)#
lines(x = c(SamplingLevel, SamplingLevel), y = c(1, 10000), lty = 2, lwd = 1)#
plot(x = StageMidpoints, y = lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]]), xlab = "Time (Ma)",#
  ylab = "Richness (N genera)", type = "l",#
  xlim = c(max(StageMidpoints), min(StageMidpoints)))
SamplingLevel <- 50#
par(mfrow = c(1, 2))#
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), y = seq(from = 1,#
  to = max(unlist(lapply(MultiReSamples, max))),#
  length.out = max(unlist(lapply(MultiReSamples, length)))), log = "xy",#
  type = "n", xlab = "N Occurrences", ylab = "Genus richness")#
for(i in StageNames) points(x = 1:length(MultiReSamples[[i]]),#
  y = MultiReSamples[[i]], type = "l",#
  col = viridis::viridis(length(StageNames))[StageNames == i], lwd = 2)#
legend("topleft", legend = StageNames, col = viridis::viridis(length(StageNames)),#
  lwd = 2, bty = "n", cex = 1)#
lines(x = c(SamplingLevel, SamplingLevel), y = c(1, 10000), lty = 2, lwd = 1)#
plot(x = StageMidpoints, y = lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]]), xlab = "Time (Ma)",#
  ylab = "Richness (N genera)", type = "l",#
  xlim = c(max(StageMidpoints), min(StageMidpoints)))
SamplingLevel <- 200#
par(mfrow = c(1, 2))#
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), y = seq(from = 1,#
  to = max(unlist(lapply(MultiReSamples, max))),#
  length.out = max(unlist(lapply(MultiReSamples, length)))), log = "xy",#
  type = "n", xlab = "N Occurrences", ylab = "Genus richness")#
for(i in StageNames) points(x = 1:length(MultiReSamples[[i]]),#
  y = MultiReSamples[[i]], type = "l",#
  col = viridis::viridis(length(StageNames))[StageNames == i], lwd = 2)#
legend("topleft", legend = StageNames, col = viridis::viridis(length(StageNames)),#
  lwd = 2, bty = "n", cex = 1)#
lines(x = c(SamplingLevel, SamplingLevel), y = c(1, 10000), lty = 2, lwd = 1)#
plot(x = StageMidpoints, y = lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]]), xlab = "Time (Ma)",#
  ylab = "Richness (N genera)", type = "l",#
  xlim = c(max(StageMidpoints), min(StageMidpoints)))
SamplingLevel <- 20#
par(mfrow = c(1, 2))#
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), y = seq(from = 1,#
  to = max(unlist(lapply(MultiReSamples, max))),#
  length.out = max(unlist(lapply(MultiReSamples, length)))), log = "xy",#
  type = "n", xlab = "N Occurrences", ylab = "Genus richness")#
for(i in StageNames) points(x = 1:length(MultiReSamples[[i]]),#
  y = MultiReSamples[[i]], type = "l",#
  col = viridis::viridis(length(StageNames))[StageNames == i], lwd = 2)#
legend("topleft", legend = StageNames, col = viridis::viridis(length(StageNames)),#
  lwd = 2, bty = "n", cex = 1)#
lines(x = c(SamplingLevel, SamplingLevel), y = c(1, 10000), lty = 2, lwd = 1)#
plot(x = StageMidpoints, y = lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]]), xlab = "Time (Ma)",#
  ylab = "Richness (N genera)", type = "l",#
  xlim = c(max(StageMidpoints), min(StageMidpoints)))
SamplingLevel <- 1#
par(mfrow = c(1, 2))#
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), y = seq(from = 1,#
  to = max(unlist(lapply(MultiReSamples, max))),#
  length.out = max(unlist(lapply(MultiReSamples, length)))), log = "xy",#
  type = "n", xlab = "N Occurrences", ylab = "Genus richness")#
for(i in StageNames) points(x = 1:length(MultiReSamples[[i]]),#
  y = MultiReSamples[[i]], type = "l",#
  col = viridis::viridis(length(StageNames))[StageNames == i], lwd = 2)#
legend("topleft", legend = StageNames, col = viridis::viridis(length(StageNames)),#
  lwd = 2, bty = "n", cex = 1)#
lines(x = c(SamplingLevel, SamplingLevel), y = c(1, 10000), lty = 2, lwd = 1)#
plot(x = StageMidpoints, y = lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]]), xlab = "Time (Ma)",#
  ylab = "Richness (N genera)", type = "l",#
  xlim = c(max(StageMidpoints), min(StageMidpoints)))
SamplingLevel <- 10#
par(mfrow = c(1, 2))#
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), y = seq(from = 1,#
  to = max(unlist(lapply(MultiReSamples, max))),#
  length.out = max(unlist(lapply(MultiReSamples, length)))), log = "xy",#
  type = "n", xlab = "N Occurrences", ylab = "Genus richness")#
for(i in StageNames) points(x = 1:length(MultiReSamples[[i]]),#
  y = MultiReSamples[[i]], type = "l",#
  col = viridis::viridis(length(StageNames))[StageNames == i], lwd = 2)#
legend("topleft", legend = StageNames, col = viridis::viridis(length(StageNames)),#
  lwd = 2, bty = "n", cex = 1)#
lines(x = c(SamplingLevel, SamplingLevel), y = c(1, 10000), lty = 2, lwd = 1)#
plot(x = StageMidpoints, y = lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]]), xlab = "Time (Ma)",#
  ylab = "Richness (N genera)", type = "l",#
  xlim = c(max(StageMidpoints), min(StageMidpoints)))
SamplingLevel <- 100#
par(mfrow = c(1, 2))#
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), y = seq(from = 1,#
  to = max(unlist(lapply(MultiReSamples, max))),#
  length.out = max(unlist(lapply(MultiReSamples, length)))), log = "xy",#
  type = "n", xlab = "N Occurrences", ylab = "Genus richness")#
for(i in StageNames) points(x = 1:length(MultiReSamples[[i]]),#
  y = MultiReSamples[[i]], type = "l",#
  col = viridis::viridis(length(StageNames))[StageNames == i], lwd = 2)#
legend("topleft", legend = StageNames, col = viridis::viridis(length(StageNames)),#
  lwd = 2, bty = "n", cex = 0.7)#
lines(x = c(SamplingLevel, SamplingLevel), y = c(1, 10000), lty = 2, lwd = 1)#
plot(x = StageMidpoints, y = lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]]), xlab = "Time (Ma)",#
  ylab = "Richness (N genera)", type = "l",#
  xlim = c(max(StageMidpoints), min(StageMidpoints)))#
points(x = StageMidpoints, y = lapply(MultiReSamples,#
function(x) x[[SamplingLevel]]), pch = 20, cex = 2, col = viridis::viridis(length(StageNames)))
SamplingLevel <- 100#
par(mfrow = c(1, 2))#
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), y = seq(from = 1,#
  to = max(unlist(lapply(MultiReSamples, max))),#
  length.out = max(unlist(lapply(MultiReSamples, length)))), log = "xy",#
  type = "n", xlab = "N Occurrences", ylab = "Genus richness")#
for(i in StageNames) points(x = 1:length(MultiReSamples[[i]]),#
  y = MultiReSamples[[i]], type = "l",#
  col = viridis::viridis(length(StageNames))[StageNames == i], lwd = 2)#
legend("topleft", legend = StageNames, col = viridis::viridis(length(StageNames)),#
  lwd = 2, bty = "n", cex = 0.7)#
lines(x = c(SamplingLevel, SamplingLevel), y = c(1, 10000), lty = 2, lwd = 1)#
plot(x = StageMidpoints, y = lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]]), xlab = "Time (Ma)",#
  ylab = "Genus richness", type = "l",#
  xlim = c(max(StageMidpoints), min(StageMidpoints)))#
points(x = StageMidpoints, y = lapply(MultiReSamples,#
function(x) x[[SamplingLevel]]), pch = 20, cex = 2, col = viridis::viridis(length(StageNames)))
lapply(MultiReSamples,#
function(x) x[[SamplingLevel]])
SamplingLevel <- 100#
par(mfrow = c(1, 2))#
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), y = seq(from = 1,#
  to = max(unlist(lapply(MultiReSamples, max))),#
  length.out = max(unlist(lapply(MultiReSamples, length)))), log = "xy",#
  type = "n", xlab = "N Occurrences", ylab = "Genus richness")#
for(i in StageNames) points(x = 1:length(MultiReSamples[[i]]),#
  y = MultiReSamples[[i]], type = "l",#
  col = viridis::viridis(length(StageNames))[StageNames == i], lwd = 2)#
legend("topleft", legend = StageNames, col = viridis::viridis(length(StageNames)),#
  lwd = 2, bty = "n", cex = 0.7)#
lines(x = c(SamplingLevel, SamplingLevel), y = c(1, 10000), lty = 2, lwd = 1)#
plot(x = StageMidpoints, y = lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]]), xlab = "Time (Ma)",#
  ylab = "Genus richness", type = "l",#
  xlim = c(max(StageMidpoints), min(StageMidpoints)))#
points(x = StageMidpoints, y = unlist(lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]])), pch = 20, cex = 2,#
  col = viridis::viridis(length(StageNames)))
plot(new=FASLE)
plot(new=FALSE)
plot(x = StageMidpoints, y = lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]]), xlab = "Time (Ma)",#
  ylab = "Genus richness", type = "l",#
  xlim = c(max(StageMidpoints), min(StageMidpoints)), new=FALSE)#
points(x = StageMidpoints, y = unlist(lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]])), pch = 20, cex = 2,#
  col = viridis::viridis(length(StageNames)))
SamplingLevel <- 100#
par(mfrow = c(1, 2))#
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), y = seq(from = 1,#
  to = max(unlist(lapply(MultiReSamples, max))),#
  length.out = max(unlist(lapply(MultiReSamples, length)))), log = "xy",#
  type = "n", xlab = "N Occurrences", ylab = "Genus richness")#
for(i in StageNames) points(x = 1:length(MultiReSamples[[i]]),#
  y = MultiReSamples[[i]], type = "l",#
  col = viridis::viridis(length(StageNames))[StageNames == i], lwd = 2)#
legend("topleft", legend = StageNames, col = viridis::viridis(length(StageNames)),#
  lwd = 2, bty = "n", cex = 0.7)#
lines(x = c(SamplingLevel, SamplingLevel), y = c(1, 10000), lty = 2, lwd = 1)#
plot(x = StageMidpoints, y = lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]]), xlab = "Time (Ma)",#
  ylab = "Genus richness", type = "l",#
  xlim = c(max(StageMidpoints), min(StageMidpoints)), new=FALSE)#
points(x = StageMidpoints, y = unlist(lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]])), pch = 20, cex = 2,#
  col = viridis::viridis(length(StageNames)))
SamplingLevel <- 100#
par(mfrow = c(1, 2))#
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), y = seq(from = 1,#
  to = max(unlist(lapply(MultiReSamples, max))),#
  length.out = max(unlist(lapply(MultiReSamples, length)))), log = "xy",#
  type = "n", xlab = "N Occurrences", ylab = "Genus richness")#
for(i in StageNames) points(x = 1:length(MultiReSamples[[i]]),#
  y = MultiReSamples[[i]], type = "l",#
  col = viridis::viridis(length(StageNames))[StageNames == i], lwd = 2)#
legend("topleft", legend = StageNames, col = viridis::viridis(length(StageNames)),#
  lwd = 2, bty = "n", cex = 0.7)#
lines(x = c(SamplingLevel, SamplingLevel), y = c(1, 10000), lty = 2, lwd = 1)#
plot(x = StageMidpoints, y = lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]]), xlab = "Time (Ma)",#
  ylab = "Genus richness", type = "l",#
  xlim = c(max(StageMidpoints), min(StageMidpoints)), add = TRUE)#
points(x = StageMidpoints, y = unlist(lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]])), pch = 20, cex = 2,#
  col = viridis::viridis(length(StageNames)))
SamplingLevel <- 100#
par(mfrow = c(1, 2))#
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), y = seq(from = 1,#
  to = max(unlist(lapply(MultiReSamples, max))),#
  length.out = max(unlist(lapply(MultiReSamples, length)))), log = "xy",#
  type = "n", xlab = "N Occurrences", ylab = "Genus richness")#
for(i in StageNames) points(x = 1:length(MultiReSamples[[i]]),#
  y = MultiReSamples[[i]], type = "l",#
  col = viridis::viridis(length(StageNames))[StageNames == i], lwd = 2)#
legend("topleft", legend = StageNames, col = viridis::viridis(length(StageNames)),#
  lwd = 2, bty = "n", cex = 0.7)#
lines(x = c(SamplingLevel, SamplingLevel), y = c(1, 10000), lty = 2, lwd = 1)#
plot(x = StageMidpoints, y = lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]]), xlab = "Time (Ma)",#
  ylab = "Genus richness", type = "l",#
  xlim = c(max(StageMidpoints), min(StageMidpoints)))#
points(x = StageMidpoints, y = unlist(lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]])), pch = 20, cex = 2,#
  col = viridis::viridis(length(StageNames)))
SamplingLevel <- 100#
par(mfrow = c(1, 2))#
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), y = seq(from = 1,#
  to = max(unlist(lapply(MultiReSamples, max))),#
  length.out = max(unlist(lapply(MultiReSamples, length)))), log = "xy",#
  type = "n", xlab = "N Occurrences", ylab = "Genus richness")#
for(i in StageNames) points(x = 1:length(MultiReSamples[[i]]),#
  y = MultiReSamples[[i]], type = "l",#
  col = viridis::viridis(length(StageNames))[StageNames == i], lwd = 2)#
legend("topleft", legend = StageNames, col = viridis::viridis(length(StageNames)),#
  lwd = 2, bty = "n", cex = 0.7)#
lines(x = c(SamplingLevel, SamplingLevel), y = c(1, 10000), lty = 2, lwd = 1)#
plot(x = StageMidpoints, y = unlist(lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]])), xlab = "Time (Ma)",#
  ylab = "Genus richness", type = "l",#
xlim = c(max(StageMidpoints), min(StageMidpoints)), ylim = c(1, max(unlist(lapply(MultiReSamples,#
function(x) x[[SamplingLevel]])))))#
points(x = StageMidpoints, y = unlist(lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]])), pch = 20, cex = 2,#
  col = viridis::viridis(length(StageNames)))
SamplingLevel <- 100#
par(mfrow = c(1, 2))#
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), y = seq(from = 1,#
  to = max(unlist(lapply(MultiReSamples, max))),#
  length.out = max(unlist(lapply(MultiReSamples, length)))), log = "xy",#
  type = "n", xlab = "N Occurrences", ylab = "Genus richness")#
for(i in StageNames) points(x = 1:length(MultiReSamples[[i]]),#
  y = MultiReSamples[[i]], type = "l",#
  col = viridis::viridis(length(StageNames))[StageNames == i], lwd = 2)#
legend("topleft", legend = StageNames, col = viridis::viridis(length(StageNames)),#
  lwd = 2, bty = "n", cex = 0.7)#
lines(x = c(SamplingLevel, SamplingLevel), y = c(1, 10000), lty = 2, lwd = 1)#
plot(x = StageMidpoints, y = unlist(lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]])), xlab = "Time (Ma)",#
  ylab = "Genus richness", type = "l", xlim = c(max(StageMidpoints),#
  min(StageMidpoints)), ylim = c(1, max(unlist(lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]])))), log = "y")#
points(x = StageMidpoints, y = unlist(lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]])), pch = 20, cex = 2,#
  col = viridis::viridis(length(StageNames)))
max(unlist(MultiReSamples))
SamplingLevel <- 100#
par(mfrow = c(1, 2))#
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), y = seq(from = 1,#
  to = max(unlist(lapply(MultiReSamples, max))),#
  length.out = max(unlist(lapply(MultiReSamples, length)))), log = "xy",#
  type = "n", xlab = "N Occurrences", ylab = "Genus richness")#
for(i in StageNames) points(x = 1:length(MultiReSamples[[i]]),#
  y = MultiReSamples[[i]], type = "l",#
  col = viridis::viridis(length(StageNames))[StageNames == i], lwd = 2)#
legend("topleft", legend = StageNames, col = viridis::viridis(length(StageNames)),#
  lwd = 2, bty = "n", cex = 0.7)#
lines(x = c(SamplingLevel, SamplingLevel), y = c(1, 10000), lty = 2, lwd = 1)#
plot(x = StageMidpoints, y = unlist(lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]])), xlab = "Time (Ma)",#
  ylab = "Genus richness", type = "l", xlim = c(max(StageMidpoints),#
  min(StageMidpoints)), ylim = c(1, max(unlist(MultiReSamples))), log = "y")#
points(x = StageMidpoints, y = unlist(lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]])), pch = 20, cex = 2,#
  col = viridis::viridis(length(StageNames)))
MultiReSamples <- lapply(as.list(StageNames), function(x)#
  MultiReSampler(NamesVector = CleanData[[x]], NReplicates = 100))#
names(MultiReSamples) <- StageNames#
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), y = seq(from = 1,#
  to = max(unlist(lapply(MultiReSamples, max))),#
  length.out = max(unlist(lapply(MultiReSamples, length)))), log = "xy",#
  type = "n", xlab = "N Occurrences", ylab = "Genus richness")#
for(i in StageNames) points(x = 1:length(MultiReSamples[[i]]),#
  y = MultiReSamples[[i]], type = "l",#
  col = viridis::viridis(length(StageNames))[StageNames == i], lwd = 2)#
legend("topleft", legend = StageNames, col = viridis::viridis(length(StageNames)),#
  lwd = 2, bty = "n", cex = 1)
SamplingLevel <- 100#
par(mfrow = c(1, 2))#
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), y = seq(from = 1,#
  to = max(unlist(lapply(MultiReSamples, max))),#
  length.out = max(unlist(lapply(MultiReSamples, length)))), log = "xy",#
  type = "n", xlab = "N Occurrences", ylab = "Genus richness")#
for(i in StageNames) points(x = 1:length(MultiReSamples[[i]]),#
  y = MultiReSamples[[i]], type = "l",#
  col = viridis::viridis(length(StageNames))[StageNames == i], lwd = 2)#
legend("topleft", legend = StageNames, col = viridis::viridis(length(StageNames)),#
  lwd = 2, bty = "n", cex = 0.7)#
lines(x = c(SamplingLevel, SamplingLevel), y = c(1, 10000), lty = 2, lwd = 1)#
plot(x = StageMidpoints, y = unlist(lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]])), xlab = "Time (Ma)",#
  ylab = "Genus richness", type = "l", xlim = c(max(StageMidpoints),#
  min(StageMidpoints)), ylim = c(1, max(unlist(MultiReSamples))), log = "y")#
points(x = StageMidpoints, y = unlist(lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]])), pch = 20, cex = 2,#
  col = viridis::viridis(length(StageNames)))
base::sample(1:10)
base::sample(1:10, replace = FALSE)
# There are optiosn fro this function that we have not explored, specifically#
# the "replace" option. By deafult we have this set to FALSE:#
base::sample(1:10, replace = FALSE)
base::sample(CleanData[["Induan"]])
# ...and apply it to the Induan bivalves:#
ReSampler(CleanData[["Induan"]])
base::sample(1:10, replace = FALSE)
# What happens if instead we set this to true:#
base::sample(1:10, replace = TRUE)
base::sample(1:10, replace = TRUE)#
base::sample(1:10, replace = TRUE)#
base::sample(1:10, replace = TRUE)#
base::sample(1:10, replace = TRUE)#
base::sample(1:10, replace = TRUE)
ReSampler <- function(NamesVector, Type) {#
  if(Type == "rarefaction") Replace <- FALSE#
  if(Type == "bootstrap") Replace <- TRUE#
  ShuffledSample <- base::sample(NamesVector, replace = Replace)#
  matrix(c(1:length(ShuffledSample), unlist(lapply(as.list(1:length(ShuffledSample)),#
  function(x) length(unique(ShuffledSample[1:x]))))), nrow = 2, byrow = TRUE,#
  dimnames = list(c("SampleSize", "NUnique"), c()))}#
MultiReSampler <- function(NamesVector, NReplicates, Type)#
  apply(do.call(rbind, lapply(as.list(1:NReplicates),#
  function(x) ReSampler(NamesVector, Type = Type)["NUnique", ])), 2, mean)#
#
# ...try bootstrapping our samples instead...:#
MultiReSamples <- lapply(as.list(StageNames), function(x)#
  MultiReSampler(NamesVector = CleanData[[x]], NReplicates = 100, Type = "bootstrap"))#
names(MultiReSamples) <- StageNames
SamplingLevel <- 100#
par(mfrow = c(1, 2))#
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), y = seq(from = 1,#
  to = max(unlist(lapply(MultiReSamples, max))),#
  length.out = max(unlist(lapply(MultiReSamples, length)))), log = "xy",#
  type = "n", xlab = "N Occurrences", ylab = "Genus richness")#
for(i in StageNames) points(x = 1:length(MultiReSamples[[i]]),#
  y = MultiReSamples[[i]], type = "l",#
  col = viridis::viridis(length(StageNames))[StageNames == i], lwd = 2)#
legend("topleft", legend = StageNames, col = viridis::viridis(length(StageNames)),#
  lwd = 2, bty = "n", cex = 0.7)#
lines(x = c(SamplingLevel, SamplingLevel), y = c(1, 10000), lty = 2, lwd = 1)#
plot(x = StageMidpoints, y = unlist(lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]])), xlab = "Time (Ma)",#
  ylab = "Genus richness", type = "l", xlim = c(max(StageMidpoints),#
  min(StageMidpoints)), ylim = c(1, max(unlist(MultiReSamples))), log = "y")#
points(x = StageMidpoints, y = unlist(lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]])), pch = 20, cex = 2,#
  col = viridis::viridis(length(StageNames)))
head(RawData)
unique(RawData[, "collection_no"])
utils::browseURL("https://paleobiodb.org/classic/basicCollectionSearch?collection_no=197722&fbclid=IwAR1z4s0eFfUjpIB054h3UmTMJFaSf8AEiC-hyNSFpltogDdOicHGq1yIy2Y")
utils::browseURL("https://paleobiodb.org/classic/displayCollResults?a=basicCollectionSearch&collection_no=197722")
unique(RawData[, "collection_no"])
?unique
lapply(as.list(unique(RawData[, "collection_no"])), function(x) {which(RawData[, "collection_no"] == x)})
SamplingLevel <- 100#
par(mfrow = c(1, 2))#
plot(x = 1:max(unlist(lapply(MultiReSamples, length))), y = seq(from = 1,#
  to = max(unlist(lapply(MultiReSamples, max))),#
  length.out = max(unlist(lapply(MultiReSamples, length)))), log = "xy",#
  type = "n", xlab = "N Occurrences", ylab = "Genus richness")#
for(i in StageNames) points(x = 1:length(MultiReSamples[[i]]),#
  y = MultiReSamples[[i]], type = "l",#
  col = viridis::viridis(length(StageNames))[StageNames == i], lwd = 2)#
legend("topleft", legend = StageNames, col = viridis::viridis(length(StageNames)),#
  lwd = 2, bty = "n", cex = 0.7)#
lines(x = c(SamplingLevel, SamplingLevel), y = c(1, 10000), lty = 2, lwd = 1)#
plot(x = StageMidpoints, y = unlist(lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]])), xlab = "Time (Ma)",#
  ylab = "Genus richness", type = "l", xlim = c(max(StageMidpoints),#
  min(StageMidpoints)), ylim = c(1, max(unlist(MultiReSamples))), log = "y")#
points(x = StageMidpoints, y = unlist(lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]])), pch = 20, cex = 2,#
  col = viridis::viridis(length(StageNames)))
lapply(as.list(unique(RawData[, "collection_no"])), function(x) {CollectionRows <- which(RawData[, "collection_no"] == x)})
lapply(as.list(unique(RawData[, "collection_no"])), function(x) {CollectionRows <- which(RawData[, "collection_no"] == x); RawData[CollectionRows[1], "start_interval"]})
olnames(RawData)
colnames(RawData)
lapply(as.list(unique(RawData[, "collection_no"])), function(x) {CollectionRows <- which(RawData[, "collection_no"] == x); RawData[CollectionRows[1], "early_interval"]})
lapply(as.list(unique(RawData[, "collection_no"])), function(x) {CollectionRows <- which(RawData[, "collection_no"] == x); CollectionStage <- RawData[CollectionRows[1], "early_interval"]; list(CollectionStage)})
lapply(as.list(unique(RawData[, "collection_no"])), function(x) {CollectionRows <- which(RawData[, "collection_no"] == x); list(CollectionStage = RawData[CollectionRows[1], "early_interval"])})
lapply(as.list(unique(RawData[, "collection_no"])), function(x) {CollectionRows <- which(RawData[, "collection_no"] == x); list(CollectionStage = RawData[CollectionRows[1], "early_interval"], CollectionGenera = RawData[CollectionRows, "genus"])})
lapply(as.list(unique(RawData[, "collection_no"])), function(x) {CollectionRows <- which(RawData[, "collection_no"] == x); list(CollectionStage = RawData[CollectionRows[1], "early_interval"], CollectionGenera = unlist(lapply(strsplit(RawData[CollectionRows, "genus"], split = " "), function(y) y[1])))})
lapply(as.list(unique(RawData[, "collection_no"])), function(x) {CollectionRows <- which(RawData[, "collection_no"] == x); list(CollectionStage = RawData[CollectionRows[1], "early_interval"], CollectionGenera = unique(unlist(lapply(strsplit(RawData[CollectionRows, "genus"], split = " "), function(y) y[1]))))})
CollectionsList <- lapply(as.list(unique(RawData[, "collection_no"])),#
  function(x) {CollectionRows <- which(RawData[, "collection_no"] == x);#
  list(CollectionStage = RawData[CollectionRows[1], "early_interval"],#
  CollectionGenera = unique(unlist(lapply(strsplit(RawData[CollectionRows,#
  "genus"], split = " "), function(y) y[1]))))})
CollectionsList[[1]]
which(unlist(lapply(CollectionsList, function(x) x$CollectionStage == "Induan")))
which(unlist(lapply(CollectionsList, function(x)#
  x$CollectionStage == "Induan")))
base::sample(which(unlist(lapply(CollectionsList, function(x)#
  x$CollectionStage == "Induan"))), replace = TRUE)
CollectionsList[base::sample(which(unlist(lapply(CollectionsList, function(x)#
  x$CollectionStage == "Induan"))), replace = TRUE)]
lapply(CollectionsList[base::sample(which(unlist(lapply(CollectionsList,#
  function(x) x$CollectionStage == "Induan"))), replace = TRUE)], function(y)#
  y$CollectionGenera)
unlist(lapply(CollectionsList[base::sample(which(unlist(lapply(CollectionsList,#
  function(x) x$CollectionStage == "Induan"))), replace = TRUE)], function(y)#
  y$CollectionGenera))
unique(unlist(lapply(CollectionsList[base::sample(which(unlist(lapply(#
  CollectionsList, function(x) x$CollectionStage == "Induan"))),#
  replace = TRUE)], function(y) y$CollectionGenera)))
sample(1:10, size = 10)
sample(1:10, size = 100)
sample(1:10, size = 100, replace = TRUE)
base::sample(1:10, replace = TRUE, size = 20)
which(unlist(lapply(CollectionsList, function(x)#
  x$CollectionStage == "Induan")))
length(which(unlist(lapply(CollectionsList, function(x)#
  x$CollectionStage == "Induan"))))
# To set this for our Induan stage we can add the size= option with:#
unique(unlist(lapply(CollectionsList[base::sample(which(unlist(lapply(#
  CollectionsList, function(x) x$CollectionStage == "Induan"))),#
  replace = TRUE, size = SamplingLevel)], function(y) y$CollectionGenera)))
lapply(as.list(StageNames), function(z) unique(unlist(lapply(CollectionsList[base::sample(which(unlist(lapply(#
  CollectionsList, function(x) x$CollectionStage == z))),#
  replace = TRUE, size = SamplingLevel)], function(y) y$CollectionGenera))))
lapply(as.list(StageNames), function(z) unique(unlist(lapply(CollectionsList[#
  base::sample(which(unlist(lapply(CollectionsList, function(x)#
  x$CollectionStage == z))), replace = TRUE, size = SamplingLevel)],#
  function(y) y$CollectionGenera))))
NReplicates <- 10#
#
lapply(as.list(StageNames), function(z)#
lapply(as.list(1:NReplicates), function(q) length(unique(unlist(lapply(CollectionsList[base::sample(which(unlist(lapply(CollectionsList, function(x) x$CollectionStage == z))), replace = TRUE, size = SamplingLevel)], function(y) y$CollectionGenera)))))#
#
)
NReplicates <- 100#
#
lapply(as.list(StageNames), function(z)#
unlist(lapply(as.list(1:NReplicates), function(q) length(unique(unlist(lapply(CollectionsList[base::sample(which(unlist(lapply(CollectionsList, function(x) x$CollectionStage == z))), replace = TRUE, size = SamplingLevel)], function(y) y$CollectionGenera))))))#
#
)
NReplicates <- 100#
#
lapply(as.list(StageNames), function(z)#
mean(unlist(lapply(as.list(1:NReplicates), function(q) length(unique(unlist(lapply(CollectionsList[base::sample(which(unlist(lapply(CollectionsList, function(x) x$CollectionStage == z))), replace = TRUE, size = SamplingLevel)], function(y) y$CollectionGenera)))))))#
#
)
unlist(lapply(as.list(StageNames), function(z) mean(unlist(lapply(as.list(1:NReplicates), function(q) length(unique(unlist(lapply(CollectionsList[base::sample(which(unlist(lapply(CollectionsList, function(x) x$CollectionStage == z))), replace = TRUE, size = SamplingLevel)], function(y) y$CollectionGenera)))))))))
NReplicates <- 100#
BootstrappedCollections <- unlist(lapply(as.list(StageNames), function(z)#
  mean(unlist(lapply(as.list(1:NReplicates), function(q)#
  length(unique(unlist(lapply(CollectionsList[base::sample(#
  which(unlist(lapply(CollectionsList, function(x) x$CollectionStage == z))),#
  replace = TRUE, size = SamplingLevel)], function(y)#
  y$CollectionGenera)))))))))
BootstrappedCollections
plot(x = StageMidpoints, y = BootstrappedCollections, xlab = "Time (Ma)",#
  ylab = "Genus richness", type = "l", xlim = c(max(StageMidpoints),#
  min(StageMidpoints)), ylim = c(1, max(unlist(MultiReSamples))), log = "y")#
points(x = StageMidpoints, y = BootstrappedCollections, pch = 20, cex = 2,#
  col = viridis::viridis(length(StageNames)))
plot(x = StageMidpoints, y = BootstrappedCollections, xlab = "Time (Ma)",#
  ylab = "Genus richness", type = "l", xlim = c(max(StageMidpoints),#
  min(StageMidpoints)), ylim = c(1, max(unlist(MultiReSamples))))#
points(x = StageMidpoints, y = BootstrappedCollections, pch = 20, cex = 2,#
  col = viridis::viridis(length(StageNames)))
# We can plot this as a time series (as we have before) with:#
plot(x = StageMidpoints, y = BootstrappedCollections, xlab = "Time (Ma)",#
  ylab = "Genus richness", type = "l", xlim = c(max(StageMidpoints),#
  min(StageMidpoints)), ylim = c(1, max(unlist(MultiReSamples))), log = "y")#
points(x = StageMidpoints, y = BootstrappedCollections, pch = 20, cex = 2,#
  col = viridis::viridis(length(StageNames)))
CleanData
par(mfrow = c(3, 1))#
plot(x = StageMidpoints, y = unlist(lapply(CleanData, function(x)#
  length(unique(x)))), xlab = "Time (Ma)", ylab = "Richness (N genera)",#
  type = "l", xlim = c(max(StageMidpoints), min(StageMidpoints)))#
# We can plot this as a time series (as we have before) with:#
plot(x = StageMidpoints, y = BootstrappedCollections, xlab = "Time (Ma)",#
ylab = "Genus richness", type = "l", xlim = c(max(StageMidpoints),#
min(StageMidpoints)), ylim = c(1, max(unlist(MultiReSamples))), log = "y")#
points(x = StageMidpoints, y = BootstrappedCollections, pch = 20, cex = 2,#
col = viridis::viridis(length(StageNames)))
par(mfrow = c(3, 1))#
plot(x = StageMidpoints, y = unlist(lapply(CleanData, function(x)#
  length(unique(x)))), xlab = "Time (Ma)", ylab = "Richness (N genera)",#
  type = "l", xlim = c(max(StageMidpoints), min(StageMidpoints)))#
#
plot(x = StageMidpoints, y = unlist(lapply(MultiReSamples,#
function(x) x[[SamplingLevel]])), xlab = "Time (Ma)",#
ylab = "Genus richness", type = "l", xlim = c(max(StageMidpoints),#
min(StageMidpoints)), ylim = c(1, max(unlist(MultiReSamples))), log = "y")#
points(x = StageMidpoints, y = unlist(lapply(MultiReSamples,#
function(x) x[[SamplingLevel]])), pch = 20, cex = 2,#
col = viridis::viridis(length(StageNames)))#
#
# We can plot this as a time series (as we have before) with:#
plot(x = StageMidpoints, y = BootstrappedCollections, xlab = "Time (Ma)",#
  ylab = "Genus richness", type = "l", xlim = c(max(StageMidpoints),#
  min(StageMidpoints)), ylim = c(1, max(unlist(MultiReSamples))), log = "y")#
points(x = StageMidpoints, y = BootstrappedCollections, pch = 20, cex = 2,#
  col = viridis::viridis(length(StageNames)))
par(mfrow = c(3, 1))#
plot(x = StageMidpoints, y = unlist(lapply(CleanData, function(x)#
  length(unique(x)))), xlab = "Time (Ma)", ylab = "Richness (N genera)",#
  type = "l", xlim = c(max(StageMidpoints), min(StageMidpoints)),#
  ylim = c(1, max(unlist(lapply(CleanData,#
  function(x) length(unique(x)))))))#
points(x = StageMidpoints, y = unlist(lapply(CleanData, function(x)#
  length(unique(x)))), pch = 20, cex = 2,#
  col = viridis::viridis(length(StageNames)))#
plot(x = StageMidpoints, y = unlist(lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]])), xlab = "Time (Ma)",#
  ylab = "Genus richness", type = "l", xlim = c(max(StageMidpoints),#
  min(StageMidpoints)), ylim = c(1, max(unlist(MultiReSamples))), log = "y")#
points(x = StageMidpoints, y = unlist(lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]])), pch = 20, cex = 2,#
  col = viridis::viridis(length(StageNames)))#
plot(x = StageMidpoints, y = BootstrappedCollections, xlab = "Time (Ma)",#
  ylab = "Genus richness", type = "l", xlim = c(max(StageMidpoints),#
  min(StageMidpoints)), ylim = c(1, max(unlist(MultiReSamples))), log = "y")#
points(x = StageMidpoints, y = BootstrappedCollections, pch = 20, cex = 2,#
  col = viridis::viridis(length(StageNames)))
par(mfrow = c(3, 1))#
plot(x = StageMidpoints, y = unlist(lapply(CleanData, function(x)#
  length(unique(x)))), xlab = "Time (Ma)", ylab = "Richness (N genera)",#
  type = "l", xlim = c(max(StageMidpoints), min(StageMidpoints)),#
  ylim = c(1, max(unlist(lapply(CleanData,#
  function(x) length(unique(x)))))), log = "y")#
points(x = StageMidpoints, y = unlist(lapply(CleanData, function(x)#
  length(unique(x)))), pch = 20, cex = 2,#
  col = viridis::viridis(length(StageNames)))#
plot(x = StageMidpoints, y = unlist(lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]])), xlab = "Time (Ma)",#
  ylab = "Genus richness", type = "l", xlim = c(max(StageMidpoints),#
  min(StageMidpoints)), ylim = c(1, max(unlist(MultiReSamples))), log = "y")#
points(x = StageMidpoints, y = unlist(lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]])), pch = 20, cex = 2,#
  col = viridis::viridis(length(StageNames)))#
plot(x = StageMidpoints, y = BootstrappedCollections, xlab = "Time (Ma)",#
  ylab = "Genus richness", type = "l", xlim = c(max(StageMidpoints),#
  min(StageMidpoints)), ylim = c(1, max(unlist(MultiReSamples))), log = "y")#
points(x = StageMidpoints, y = BootstrappedCollections, pch = 20, cex = 2,#
  col = viridis::viridis(length(StageNames)))
par(mfrow = c(3, 1))#
plot(x = StageMidpoints, y = unlist(lapply(CleanData, function(x)#
  length(unique(x)))), xlab = "Time (Ma)", ylab = "Richness (N genera)",#
  type = "l", xlim = c(max(StageMidpoints), min(StageMidpoints)),#
  ylim = c(1, max(unlist(lapply(CleanData,#
  function(x) length(unique(x)))))), log = "y", main = "Raw sampled-in-bin")#
points(x = StageMidpoints, y = unlist(lapply(CleanData, function(x)#
  length(unique(x)))), pch = 20, cex = 2,#
  col = viridis::viridis(length(StageNames)))#
plot(x = StageMidpoints, y = unlist(lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]])), xlab = "Time (Ma)",#
  ylab = "Genus richness", type = "l", xlim = c(max(StageMidpoints),#
  min(StageMidpoints)), ylim = c(1, max(unlist(MultiReSamples))), log = "y",#
  main = "Rarefied sampled-in-bin")#
points(x = StageMidpoints, y = unlist(lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]])), pch = 20, cex = 2,#
  col = viridis::viridis(length(StageNames)))#
plot(x = StageMidpoints, y = BootstrappedCollections, xlab = "Time (Ma)",#
  ylab = "Genus richness", type = "l", xlim = c(max(StageMidpoints),#
  min(StageMidpoints)), ylim = c(1, max(unlist(MultiReSamples))), log = "y",#
  main = "Collection bootstrapped sampled-in-bin")#
points(x = StageMidpoints, y = BootstrappedCollections, pch = 20, cex = 2,#
  col = viridis::viridis(length(StageNames)))
# To finish up we can compare some of these results side-by-side:#
par(mfrow = c(3, 1))#
plot(x = StageMidpoints, y = unlist(lapply(CleanData, function(x)#
  length(unique(x)))), xlab = "Time (Ma)", ylab = "Richness (N genera)",#
  type = "l", xlim = c(max(StageMidpoints), min(StageMidpoints)),#
  ylim = c(1, max(unlist(lapply(CleanData,#
  function(x) length(unique(x)))))), log = "y", main = "Raw sampled-in-bin")#
points(x = StageMidpoints, y = unlist(lapply(CleanData, function(x)#
  length(unique(x)))), pch = 20, cex = 2,#
  col = viridis::viridis(length(StageNames)))#
plot(x = StageMidpoints, y = unlist(lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]])), xlab = "Time (Ma)",#
  ylab = "Genus richness", type = "l", xlim = c(max(StageMidpoints),#
  min(StageMidpoints)), ylim = c(1, max(unlist(MultiReSamples))), log = "y",#
  main = "Rarefied sampled-in-bin")#
points(x = StageMidpoints, y = unlist(lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]])), pch = 20, cex = 2,#
  col = viridis::viridis(length(StageNames)))#
plot(x = StageMidpoints, y = BootstrappedCollections, xlab = "Time (Ma)",#
  ylab = "Genus richness", type = "l", xlim = c(max(StageMidpoints),#
  min(StageMidpoints)), ylim = c(1, max(unlist(MultiReSamples))), log = "y",#
  main = "Collection bootstrapped sampled-in-bin")#
points(x = StageMidpoints, y = BootstrappedCollections, pch = 20, cex = 2,#
  col = viridis::viridis(length(StageNames)))
BuildMetatreeReconciliation(c("Cygnus olor", "Cygnus sumnerensis"))
# To finish up we can compare some of these results side-by-side:#
par(mfrow = c(3, 1))#
plot(x = StageMidpoints, y = unlist(lapply(CleanData, function(x)#
  length(unique(x)))), xlab = "Time (Ma)", ylab = "Richness (N genera)",#
  type = "l", xlim = c(max(StageMidpoints), min(StageMidpoints)),#
  ylim = c(1, max(unlist(lapply(CleanData,#
  function(x) length(unique(x)))))), log = "y", main = "Raw sampled-in-bin")#
points(x = StageMidpoints, y = unlist(lapply(CleanData, function(x)#
  length(unique(x)))), pch = 20, cex = 2,#
  col = viridis::viridis(length(StageNames)))#
plot(x = StageMidpoints, y = unlist(lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]])), xlab = "Time (Ma)",#
  ylab = "Genus richness", type = "l", xlim = c(max(StageMidpoints),#
  min(StageMidpoints)), ylim = c(1, max(unlist(MultiReSamples))), log = "y",#
  main = "Rarefied sampled-in-bin")#
points(x = StageMidpoints, y = unlist(lapply(MultiReSamples,#
  function(x) x[[SamplingLevel]])), pch = 20, cex = 2,#
  col = viridis::viridis(length(StageNames)))#
plot(x = StageMidpoints, y = BootstrappedCollections, xlab = "Time (Ma)",#
  ylab = "Genus richness", type = "l", xlim = c(max(StageMidpoints),#
  min(StageMidpoints)), ylim = c(1, max(unlist(MultiReSamples))), log = "y",#
  main = "Collection bootstrapped sampled-in-bin")#
points(x = StageMidpoints, y = BootstrappedCollections, pch = 20, cex = 2,#
  col = viridis::viridis(length(StageNames)))
list.files(path = "~/Dropbox/Mammal_Supertree/ProjectBlackFish/Input data/XML")
gsub(".xml", "", list.files(path = "~/Dropbox/Mammal_Supertree/ProjectBlackFish/Input data/XML"))
SourceFiles <- gsub(".xml", "", list.files(path = "~/Dropbox/Mammal_Supertree/ProjectBlackFish/Input data/XML"))#
#
WaitingRoomFiles <- gsub(".xml", "", list.files(path = "~/Dropbox/Mammal_Supertree/ProjectBlackFish/Input data/WaitingRoom/XML"))
MammalsHTML <- readLines("http://www.graemetlloyd.com/matrmamm.html")
MammalsHTML[:50:55]
MammalsHTML[50:55]
MammalsHTML[150:155]
grep("<p class=\"hangingindent\">", MammalsHTML)
lapply(as.list(grep("<p class=\"hangingindent\">", MammalsHTML)), function(x) grep("</p>", MammalsHTML[x:length(MammalsHTML)])[1])
lapply(as.list(grep("<p class=\"hangingindent\">", MammalsHTML)), function(x) MammalsHTML[x:length(MammalsHTML)][1:grep("</p>", MammalsHTML[x:length(MammalsHTML)])[1]])
lapply(as.list(SourceFiles[1:2]), function(x) lapply(HTMLFormattedRefs, function(y) grep(x, y)))
HTMLFormattedRefs <- lapply(as.list(grep("<p class=\"hangingindent\">", MammalsHTML)), function(x) MammalsHTML[x:length(MammalsHTML)][1:grep("</p>", MammalsHTML[x:length(MammalsHTML)])[1]])
lapply(as.list(SourceFiles[1:2]), function(x) lapply(HTMLFormattedRefs, function(y) grep(x, y)))
lapply(as.list(SourceFiles[1:2]), function(x) unlist(lapply(HTMLFormattedRefs, function(y) length(grep(x, y)))))
lapply(as.list(SourceFiles[1:2]), function(x) which(unlist(lapply(HTMLFormattedRefs, function(y) length(grep(x, y)))) == 1))
lapply(as.list(SourceFiles[1:2]), function(x) HTMLFormattedRefs[[unlist(lapply(HTMLFormattedRefs, function(y) length(grep(x, y)))) == 1]])
lapply(as.list(SourceFiles[1:2]), function(x) HTMLFormattedRefs[[which(unlist(lapply(HTMLFormattedRefs, function(y) length(grep(x, y)))) == 1)]])
HTMLFormattedRefs <- lapply(as.list(grep("<p class=\"hangingindent\">", MammalsHTML)), function(x) MammalsHTML[x:length(MammalsHTML)][1:grep("</p>", MammalsHTML[x:length(MammalsHTML)])[1]])#
#
lapply(as.list(SourceFiles[1:2]), function(x) HTMLFormattedRefs[[which(unlist(lapply(HTMLFormattedRefs, function(y) length(grep(x, y)))) == 1)]])
lapply(as.list(SourceFiles[1:2]), function(x) {HTMLRef <- HTMLFormattedRefs[[which(unlist(lapply(HTMLFormattedRefs, function(y) length(grep(x, y)))) == 1)]]; while(length(grep("  ", HTMLRef)) > 0) HTMLRef <- gsub("  ", " ", HTMLRef); HTMLRef})
lapply(as.list(SourceFiles[1:2]), function(x) {HTMLRef <- HTMLFormattedRefs[[which(unlist(lapply(HTMLFormattedRefs, function(y) length(grep(x, y)))) == 1)]]; while(length(grep("  ", HTMLRef)) > 0) HTMLRef <- gsub("  ", " ", HTMLRef); paste(HTMLRef, collapse = "")})
lapply(as.list(SourceFiles[1:2]), function(x) {HTMLRef <- HTMLFormattedRefs[[which(unlist(lapply(HTMLFormattedRefs, function(y) length(grep(x, y)))) == 1)]]; while(length(grep("  ", HTMLRef)) > 0) HTMLRef <- gsub("  ", " ", HTMLRef); HTMLRef <- paste(HTMLRef, collapse = ""); strsplit(HTMLRef, split = "<br>")[[1]][1]})
HTMLFormattedRefs <- lapply(as.list(grep("<p class=\"hangingindent\">", MammalsHTML)), function(x) MammalsHTML[x:length(MammalsHTML)][1:grep("</p>", MammalsHTML[x:length(MammalsHTML)])[1]])#
#
lapply(as.list(SourceFiles[1:2]), function(x) {HTMLRef <- HTMLFormattedRefs[[which(unlist(lapply(HTMLFormattedRefs, function(y) length(grep(x, y)))) == 1)]]; while(length(grep("  ", HTMLRef)) > 0) HTMLRef <- gsub("  ", " ", HTMLRef); HTMLRef <- paste(HTMLRef, collapse = ""); HTMLRef <- strsplit(HTMLRef, split = "<br>")[[1]][1]; HTMLRef <- gsub(" <p class=\"hangingindent\">", "", HTMLRef)})
lapply(as.list(SourceFiles[1:2]), function(x) {HTMLRef <- HTMLFormattedRefs[[which(unlist(lapply(HTMLFormattedRefs, function(y) length(grep(x, y)))) == 1)]]; while(length(grep("  ", HTMLRef)) > 0) HTMLRef <- gsub("  ", " ", HTMLRef); HTMLRef <- paste(HTMLRef, collapse = ""); HTMLRef <- strsplit(HTMLRef, split = "<br>")[[1]][1]; HTMLRef <- gsub(" <p class=\"hangingindent\">", "", HTMLRef); gsub("<b>|</b>", "**", HTMLRef)})
lapply(as.list(SourceFiles[1:2]), function(x) {HTMLRef <- HTMLFormattedRefs[[which(unlist(lapply(HTMLFormattedRefs, function(y) length(grep(x, y)))) == 1)]]; while(length(grep("  ", HTMLRef)) > 0) HTMLRef <- gsub("  ", " ", HTMLRef); HTMLRef <- paste(HTMLRef, collapse = ""); HTMLRef <- strsplit(HTMLRef, split = "<br>")[[1]][1]; HTMLRef <- gsub(" <p class=\"hangingindent\">", "", HTMLRef); HTMLRef <- gsub("<b>|</b>", "**", HTMLRef); HTMLRef <- gsub("<em>|</em>", "*", HTMLRef); HTMLRef})
paste(unlist(lapply(as.list(SourceFiles[1:2]), function(x) {HTMLRef <- HTMLFormattedRefs[[which(unlist(lapply(HTMLFormattedRefs, function(y) length(grep(x, y)))) == 1)]]; while(length(grep("  ", HTMLRef)) > 0) HTMLRef <- gsub("  ", " ", HTMLRef); HTMLRef <- paste(HTMLRef, collapse = ""); HTMLRef <- strsplit(HTMLRef, split = "<br>")[[1]][1]; HTMLRef <- gsub(" <p class=\"hangingindent\">", "", HTMLRef); HTMLRef <- gsub("<b>|</b>", "**", HTMLRef); HTMLRef <- gsub("<em>|</em>", "*", HTMLRef); HTMLRef})), sep = "\n")
# SCRIPT TO [...]#
SourceFiles <- gsub(".xml", "", list.files(path = "~/Dropbox/Mammal_Supertree/ProjectBlackFish/Input data/XML"))#
#
WaitingRoomFiles <- gsub(".xml", "", list.files(path = "~/Dropbox/Mammal_Supertree/ProjectBlackFish/Input data/WaitingRoom/XML"))#
#
MammalsHTML <- readLines("http://www.graemetlloyd.com/matrmamm.html")#
#
HTMLFormattedRefs <- lapply(as.list(grep("<p class=\"hangingindent\">", MammalsHTML)), function(x) MammalsHTML[x:length(MammalsHTML)][1:grep("</p>", MammalsHTML[x:length(MammalsHTML)])[1]])#
#
MarkdownSourceRefs <- paste(unlist(lapply(as.list(SourceFiles), function(x) {HTMLRef <- HTMLFormattedRefs[[which(unlist(lapply(HTMLFormattedRefs, function(y) length(grep(x, y)))) == 1)]]; while(length(grep("  ", HTMLRef)) > 0) HTMLRef <- gsub("  ", " ", HTMLRef); HTMLRef <- paste(HTMLRef, collapse = ""); HTMLRef <- strsplit(HTMLRef, split = "<br>")[[1]][1]; HTMLRef <- gsub(" <p class=\"hangingindent\">", "", HTMLRef); HTMLRef <- gsub("<b>|</b>", "**", HTMLRef); HTMLRef <- gsub("<em>|</em>", "*", HTMLRef); HTMLRef})), sep = "\n")#
#
MarkdownWaitingRoomRefs <- paste(unlist(lapply(as.list(WaitingRoomFiles), function(x) {HTMLRef <- HTMLFormattedRefs[[which(unlist(lapply(HTMLFormattedRefs, function(y) length(grep(x, y)))) == 1)]]; while(length(grep("  ", HTMLRef)) > 0) HTMLRef <- gsub("  ", " ", HTMLRef); HTMLRef <- paste(HTMLRef, collapse = ""); HTMLRef <- strsplit(HTMLRef, split = "<br>")[[1]][1]; HTMLRef <- gsub(" <p class=\"hangingindent\">", "", HTMLRef); HTMLRef <- gsub("<b>|</b>", "**", HTMLRef); HTMLRef <- gsub("<em>|</em>", "*", HTMLRef); HTMLRef})), sep = "\n")
library(pandocfilters)
?pandocfilters
paste("# References for included source data\n", MarkdownSourceRefs, "# References for excluded source data (to recently discovered)\n", MarkdownWaitingRoomRefs, sep = "\n")
paste("# References for included source data\n", paste(MarkdownSourceRefs, sep = "\n"), "# References for excluded source data (to recently discovered)\n", paste(MarkdownWaitingRoomRefs, sep = "\n"), sep = "\n")
paste("# References for included source data\n", paste(MarkdownSourceRefs, collapse = "\n"), "# References for excluded source data (to recently discovered)\n", paste(MarkdownWaitingRoomRefs, collapse = "\n"), sep = "\n")
library(metatree)
Metatree(MRPDirectory = "~/Dropbox/Mammal_Supertree/ProjectPlanetOfTheApes/InputData/MRP"#
  XMLDirectory = "~/Dropbox/Mammal_Supertree/ProjectPlanetOfTheApes/InputData/XML"#
  InclusiveDataList = c()#
  ExclusiveDataList = c("Andrews_1988a", "Beard_et_MacPhee_1994a", "Begun_et_Kordos_1997a", "Burger_2010aa", "Gebo_etal_2001a", "Kimbel_etal_2004a", "Pattinson_etal_2015a", "Maiolino_etal_2012a", "Seiffert_etal_2015a", "Rose_1997a", "Marivaux_etal_2001a", "Boyer_etal_2017ab", "Boyer_etal_2017ac"),#
  TargetClade = "Primates"#
  HigherTaxaToCollapse = c()#
  MissingSpecies = "exclude"#
  Interval = NULL#
  VeilLine = TRUE,#
  IncludeSpecimenLevelOTUs = TRUE#
  RelativeWeights = c(0, 100, 10, 1),#
  WeightCombination = "sum"#
  ReportContradictionsToScreen = FALSE,#
  BackboneConstraint = "Springer_etal_2012a"#
  MonophylyConstraint = NULL#
  ExcludeTaxonomyMRP = FALSE#
  # Subfunction that gives just MRPs where matrix is still intact (has rows and columns):#
  ActiveMRP <- function(MRPList) unname(which(unlist(lapply(MRPList, function(x) prod(dim(x$Matrix)))) > 0))#
  # Subfunction to make multi-taxon reconciliations unique OTUs:#
  SeparateMultiTaxonReconciliations <- function(ListBlock) {#
    # Find comma rows (multiple taxa in initial reconciliation):#
    commarows <- grep(",", rownames(ListBlock$Matrix))#
    # If there is at least one multiple-taxon reconciliation:#
    if(length(commarows) > 0) {#
      # For each multiple-taxon reconciliation in reverse order (to avoid later rows not matching):#
      for(j in rev(commarows)) {#
        # Get multiple names of reconciliation:#
        multiplenames <- strsplit(rownames(ListBlock$Matrix)[j], "%%%%")[[1]]#
        # Get multiple-taxon numbers:#
        multitaxonnumbers <- strsplit(multiplenames[1], ";")[[1]]#
        # Get multiple-taxon names:#
        multitaxonnames <- strsplit(multiplenames[2], ",")[[1]]#
        # Check data integrity with respect to multiple-taxon values:#
        if(length(multitaxonnumbers) != length(multitaxonnames)) stop(paste("Problem with multiple-taxon reconciliation(s) in ", ListBlock$FileName, " (check commas and semi-colons are correct; i.e., of same length).", sep = ""))#
        # Add new rows at base of matrix:#
        ListBlock$Matrix <- rbind(ListBlock$Matrix, matrix(rep(ListBlock$Matrix[j, ], length(multitaxonnumbers)), nrow = length(multitaxonnumbers), byrow = TRUE, dimnames = list(paste(multitaxonnumbers, multitaxonnames, sep = "%%%%"), c())))#
        # Remove now redundant row from matrix:#
        ListBlock$Matrix <- ListBlock$Matrix[-j, , drop = FALSE]#
      }#
    }#
    # Return updated list block:#
    return(ListBlock)#
  }#
  # Subfunction to find contradicting MRP characters between a string (single character) and a matrix (multiple characters):#
  MRPCharacterContradiction <- function(MRPCharacterString, MRPCharacterMatrix) {#
    # Check MRP string has names and stop and warn user if not:#
    if(is.null(names(MRPCharacterString))) stop("MRPCharacterString must have names. Add and try again.")#
    # Check MRP matrix has names and stop and warn user if not:#
    if(is.null(rownames(MRPCharacterMatrix))) stop("MRPCharacterMatrix must have row names. Add and try again.")#
    # Check MRP string and matrix match in size and stop and warn user if not:#
    if(length(MRPCharacterString) != nrow(MRPCharacterMatrix)) stop("MRPCharacterString must have the same length as the number of rows of MRPCharacterMatrix. Check data and try again.")#
    # Check names of MRP string and matrix match and stop and warn user if not:#
    if(!all(sort(names(MRPCharacterString)) == sort(rownames(MRPCharacterMatrix)))) stop("MRPCharacterString names must match row names of MRPCharacterMatrix. Check names and try again.")#
    # Check only zeroes and ones are coded and stop and warn user if not:#
    if(length(setdiff(unique(c(MRPCharacterString, MRPCharacterMatrix)), c("0", "1"))) > 0) stop("Both MRPCharacterString and MRPCharacterMatrix must consist exclusively of the characters \"0\" and \"1\". Check data and try again.")#
    # Check MRP string contains both zeroe and ones and stop and warn user if not:#
    if(length(unique(MRPCharacterString)) < 2) stop("MRPCharacterString must contain both zeroes and ones.")#
    # Check every MRP matrix column contains both zeroe and ones and stop and warn user if not:#
    if(length(unique(as.vector(MRPCharacterMatrix))) < 2) stop("MRPCharacterMatrix must contain both zeroes and ones.")#
    # Find names corresponding to scores of "0" in the MRP string:#
    StringZeroNames <- names(which(MRPCharacterString == "0"))#
    # Find names corresponding to scores of "1" in the MRP string:#
    StringOneNames <- names(which(MRPCharacterString == "1"))#
    # Find any matrix columns that contradict the string character (both "0" and "1" coded for zero and one matches in MRP string):#
    ContradictionColumns <- which(apply(MRPCharacterMatrix, 2, function(x) length(unique(x[StringZeroNames])) == 2 && length(unique(x[StringOneNames])) == 2))#
    # Return contradicting columns:#
    return(ContradictionColumns)#
  }#
  # Subfunction to produce intra matrix weights:#
  MRPIntraMatrixWeights <- function(MRPMatrix) {#
    # Get a list of characters that contradict with each character in turn:#
    ContradictionList <- lapply(apply(MRPMatrix, 2, as.list), function(x) MRPCharacterContradiction(unlist(x), MRPMatrix))#
    # Add every character to its' own list:#
    ContradictionList <- mapply(function(x, y) c(x, y), x = as.list(1:ncol(MRPMatrix)), y = ContradictionList)#
    # Build vector of intra matrix weights:#
    IntraMatrixWeights <- 1 / unlist(lapply(ContradictionList, function(x) length(unique(unlist(ContradictionList[x])))))#
    # Return intra matrix weights:#
    return(IntraMatrixWeights)#
  }#
  # Subfunction to collapse vector of string to single formatted string:#
  WriteListAsString <- function(ListOfItems, OxfordComma = TRUE) {#
    # If not using Oxford comma set final bridge as not having one:#
    if(!OxfordComma) FinalBridge <- " and "#
    # If using Oxford comma set final bridge as having one:#
    if(OxfordComma) FinalBridge <- ", and "#
    # If list is a single item make that the output:#
    if(length(ListOfItems) == 1) Output <- ListOfItems#
    # If list is two items join with a simple and:#
    if(length(ListOfItems) == 2) Output <- paste(ListOfItems, collapse = " and ")#
    # If three or more items format as list with Oxford Comma option included:#
    if(length(ListOfItems) > 2) Output <- paste(paste(ListOfItems[1:(length(ListOfItems) - 2)], collapse = ", "), paste(ListOfItems[(length(ListOfItems) - 1):length(ListOfItems)], collapse = FinalBridge), sep = ", ")#
    # Return output:#
    return(Output)#
  }#
  # Subfunction to find taxonomy-phylogeny contradictions and turn them into warning messages:#
  ListContradictions <- function(TaxonomyMRP, MRPMatrix, ContradictionTaxa, DataSetName) {#
    # Subfunction to build warning messages:#
    BuildWarningMessages <- function(BoundMatrix, ContradictionTaxon, DataSetName) {#
      # Create four blocks for matching:#
      ZeroZero <- ZeroOne <- OneZero <- OneOne <- BoundMatrix#
      # Fill blocks with zeroes:#
      ZeroOne[, 1] <- OneZero[, 2] <- ZeroZero[1:length(ZeroZero)] <- "0"#
      # Fill blocks with ones:#
      ZeroOne[, 2] <- OneZero[, 1] <- OneOne[1:length(OneOne)] <- "1"#
      # Build empty list of names:#
      NamesList <- list()#
      # Store names where scores are zero and zero:#
      NamesList[["ZeroZeroNames"]] <- names(which(apply(BoundMatrix == ZeroZero, 1, all)))#
      # Store names where scores are zero and one:#
      NamesList[["ZeroOneNames"]] <- names(which(apply(BoundMatrix == ZeroOne, 1, all)))#
      # Store names where scores are one and zero:#
      NamesList[["OneZeroNames"]] <- names(which(apply(BoundMatrix == OneZero, 1, all)))#
      # Store names where scores are one and one:#
      NamesList[["OneOneNames"]] <- names(which(apply(BoundMatrix == OneOne, 1, all)))#
      # Prune down to just the minimum list lengths (the likley problem candidate(s)):#
      NamesList <- NamesList[unlist(lapply(NamesList, length)) == min(unlist(lapply(NamesList, length)))]#
      # Collapse each item of the list to a singel string:#
      NamesList <- lapply(NamesList, WriteListAsString)#
      # Find datasets with second case (apparent taxa outside clade that should be inside):#
      CaseOne <- match(c("ZeroZeroNames", "OneZeroNames"), names(NamesList))#
      # Find datasets with second case (apparent taxa inside clade that should be outside):#
      CaseTwo <- match(c("ZeroOneNames", "OneOneNames"), names(NamesList))#
      # Remove NAs from first case matches:#
      CaseOne <- CaseOne[!is.na(CaseOne)]#
      # Remove NAs from second case matches:#
      CaseTwo <- CaseTwo[!is.na(CaseTwo)]#
      # If first case exists then reformat string with message to user:#
      if(length(CaseOne) > 0) NamesList[CaseOne] <- lapply(NamesList[CaseOne], function(x) paste("In ", DataSetName, " the following taxa were found outside ", ContradictionTaxon, " when taxonomy suggests they should be inside: ", x, ". Check data set and/or taxonomy that this is correct.\n", sep = ""))#
      # If second case exists then reformat string with message to user:#
      if(length(CaseTwo) > 0) NamesList[CaseTwo] <- lapply(NamesList[CaseTwo], function(x) paste("In ", DataSetName, " the following taxa were found inside ", ContradictionTaxon, " when taxonomy suggests they should be outside: ", x, ". Check data set and/or taxonomy that this is correct.\n", sep = ""))#
      # Reformat names list as a vector for output:#
      Output <- unname(unlist(NamesList))#
      # If multiple values then reformat into a single value:#
      if(length(Output) > 1) Output <- paste("In ", DataSetName, " one of the following is true:\n", paste(paste(paste(1:length(Output), ". T", sep = ""), gsub(paste("In ", DataSetName, " t| Check data set and/or taxonomy that this is correct.\n", sep = ""), "", Output), rep("\n", length(Output)), sep = ""), collapse = ""), "Check data set and/or taxonomy that this is correct.\n", sep = "")#
      # Return output:#
      return(Output)#
    }#
    # Build output into unique values (as can get duplicates):#
    Output <- unique(unlist(lapply(as.list(ContradictionTaxa), function(x) lapply(as.list(MRPCharacterContradiction(TaxonomyMRP[, x], MRPMatrix)), function(y) {BoundMatrix <- cbind(TaxonomyMRP[rownames(MRPMatrix), x], MRPMatrix[, y]); BuildWarningMessages(BoundMatrix, x, DataSetName)}))))#
    # Return output:#
    return(Output)#
  }#
  # Check MRPDirectory is formatted correctly adn stop and warn user if not:#
  if(!all(is.character(MRPDirectory)) || length(MRPDirectory) != 1) stop("MRPDirectory must be a single character string indicating the path to the folder containing the MRP files.")#
  # Check XMLDirectory is formatted correctly adn stop and warn user if not:#
  if(!all(is.character(XMLDirectory)) || length(XMLDirectory) != 1) stop("XMLDirectory must be a single character string indicating the path to the folder containing the XML files.")#
  # Check TargetClade is formatted correctly adn stop and warn user if not:#
  if(!all(is.character(TargetClade)) || length(TargetClade) != 1) stop("TargetClade must be a single character string indicating the desired clade the metatree will represent.")#
  # Check MissingSpecies respresents a valid option:#
  if(length(setdiff(MissingSpecies, c("all", "exclude", "genus"))) > 0) stop("MissingSpecies must be one of \"all\", \"exclude\", or \"genus\".")#
  # Check VeilLine is a logical and stop and warn user if not:#
  if(!is.logical(VeilLine)) stop("VeilLine must be a logical (TRUE or FALSE).")#
  # Check IncludeSpecimenLevelOTUs is a logical and stop and warn user if not:#
  if(!is.logical(IncludeSpecimenLevelOTUs)) stop("IncludeSpecimenLevelOTUs must be a logical (TRUE or FALSE).")#
  # Set defualt of constraint in use to FALSE:#
  ConstraintInUse <- FALSE#
  # Check that there is a maximum of one constraint tree being used and stop and warn user if so.#
  # Technically it ought to be possible to do this, but it leaves open some potentially horrendous disasters best avoided for now:#
  if(!is.null(BackboneConstraint) && !is.null(MonophylyConstraint)) stop("Cannot currently apply a backbone constraint and a monophyly constraint simultaneously.")#
  # If backbone constraint is set:#
  if(!is.null(BackboneConstraint)) {#
    # Set constraint in use to TRUE:#
    ConstraintInUse <- TRUE#
    # Check is only a single value and stop and warn user if not:#
    if(length(BackboneConstraint) > 1) stop("BackboneConstraint must be a single value. (Cannot apply two backbone constraints simultaneously.)")#
    # Check is a string and stop and warn user if not:#
    if(!is.character(BackboneConstraint)) stop("BackboneConstraint must be a text string. Reformat and try again.")#
    # Set constraint data set to backbone constraint:#
    ConstraintDataSet <- BackboneConstraint#
    # Set constraint type to backbone:#
    ConstraintType <- "backbone"#
#
  }#
  # If monophyly onstraint is set:#
  if(!is.null(MonophylyConstraint)) {#
    # Set constraint in use to TRUE:#
    ConstraintInUse <- TRUE#
#
    # Check is only a single value and stop and warn user if not:#
    if(length(MonophylyConstraint) > 1) stop("MonophylyConstraint must be a single value. (Cannot apply two monophyly constraints simultaneously.)")#
    # Check is a string and stop and warn user if not:#
    if(!is.character(MonophylyConstraint)) stop("MonophylyConstraint must be a text string. Reformat and try again.")#
    # Set constraint data set to monophyly constraint:#
    ConstraintDataSet <- MonophylyConstraint#
    # Set constraint type to monophyly:#
    ConstraintType <- "monophyly"#
  }#
  # Check VeilLine is a logical and stop and warn user if not:#
  if(!is.logical(ReportContradictionsToScreen)) stop("ReportContradictionsToScreen must be a logical (TRUE or FALSE).")#
  # List of types of resolution that require finding a senior synonym:#
  synonyms <- c("corrected to", "misspelling of", "objective synonym of", "obsolete variant of", "recombined as", "replaced by", "subjective synonym of")#
  # List of types of resolution that require changing reconciliation to DELETE:#
  DeletionCategories <- c("nomen dubium", "nomen vanum", "nomen nudum", "nomen oblitum", "invalid subgroup of")#
  # Print current processing status:#
  cat("Reading MRP data...")#
  # Set working directory as MRP directory:#
  setwd(MRPDirectory)#
  # List MRP files (or just use inclusivedatalist if set):#
  MRPFileList <- strsplit(ifelse(length(InclusiveDataList) > 0, paste(setdiff(sort(unique(InclusiveDataList)), sort(unique(ExclusiveDataList))), "mrp.nex", sep = "", collapse = "%%"), paste(setdiff(gsub("mrp\\.nex", "", list.files()), sort(unique(ExclusiveDataList))), "mrp.nex", sep = "", collapse = "%%")), "%%")[[1]]#
  # If a backbone constraint is used and is a file check it is present in the source data and stop and warn user if not:#
  if(!is.null(BackboneConstraint)) if(is.na(match(paste(BackboneConstraint, "mrp.nex", sep = ""), MRPFileList))) stop("Backbone constraint file not found in data. Check name and try again.")#
  # If a monophyly constraint is used and is a file check it is present in the source data and stop and warn user if not:#
  if(!is.null(MonophylyConstraint)) if(is.na(match(paste(MonophylyConstraint, "mrp.nex", sep = ""), MRPFileList))) stop("Monophyly constraint file not found in data. Check name and try again.")#
  # Check there are four relative weights values and stop and warn user if not:#
  if(length(RelativeWeights) != 4) stop("RelativeWeights must consist of exactly four values. Fix and try again.")#
  # Check relative weights are numeric and stop and warn user if not:#
  if(!is.numeric(RelativeWeights)) stop("RelativeWeights must consist of numeric values. Fix and try again.")#
  # Check there are no negative weights and at least one positive weight is being used and stop and wanr user if not:#
  if(sum(RelativeWeights) <= 0 || any(RelativeWeights < 0)) stop("RelativeWeights must include at least one positive value and negative values are not allowed. Fix and try again.")#
  # Check only a single weight combination value is being used and stop and warn user if not:#
  if(length(WeightCombination) != 1) stop("WeightCombination must consist of a single value.")#
  # Check weight combintion is a valid option and stop and warn if not:#
  if(length(setdiff(WeightCombination, c("product", "sum"))) > 0) stop("WeightCombination must be one of \"product\" or \"sum\" only. Check spelling and try again.")#
  # Read in all MRP files and store in a list (include duplicate headers to store parent sibling info later):#
  MRPList <- lapply(lapply(as.list(MRPFileList), Claddis::ReadMorphNexus), function(x) {y <- list(x$Matrix_1$Matrix, x$Matrix_1$Weights, "", "", ""); names(y) <- c("Matrix", "Weights", "FileName", "Parent", "Sibling"); y})#
  # Set names of MRP files:#
  names(MRPList) <- gsub("mrp.nex", "", MRPFileList)#
  # Find maximum input weight:#
  MaximumInputWeight <- max(unlist(lapply(MRPList, function(x) x$Weights)))#
  # Resacle all input weights zero to one by dividing through by maximum input weight:#
  MRPList <- lapply(MRPList, function(x) {x$Weights <- x$Weights / MaximumInputWeight; x})#
  # Print current processing status:#
  cat("Done\nReading XML data...")#
  # Set working directory as XML (i.e., metadata) directory:#
  setwd(XMLDirectory)#
  # List MRP files (or just use inslusivedatalist if set):#
  XMLFileList <- strsplit(ifelse(length(InclusiveDataList) > 0, paste(setdiff(sort(unique(InclusiveDataList)), sort(unique(ExclusiveDataList))), ".xml", sep = "", collapse = "%%"), paste(setdiff(gsub("\\.xml", "", list.files()), sort(unique(ExclusiveDataList))), ".xml", sep = "", collapse = "%%")), "%%")[[1]]#
  # Check there are no MRPs not listed as XMLs and vice versa (should return empty vector):#
  MRPXMLunion <- c(setdiff(gsub("\\.xml", "", XMLFileList), gsub("mrp\\.nex", "", MRPFileList)), setdiff(gsub("mrp\\.nex", "", MRPFileList), gsub("\\.xml", "", XMLFileList)))#
  # Stop if MRP datasets not listed as XMLs and vice versa:#
  if(length(MRPXMLunion) > 0) stop(paste("Datasets do not match (MRP and XML)!:", MRPXMLunion, collapse = " "))#
  # Read in all XML files and store in a list (reformatting subgenera as GenusSubgenus along the way):#
  XMLList <- lapply(as.list(XMLFileList), function(x) {y <- ReadMetatreeXML(x); y$SourceTree$Taxa$TagContents[, "recon_name"] <- gsub("_\\(|\\)", "", y$SourceTree$Taxa$TagContents[, "recon_name"]); y})#
  # Add names to XML list:#
  names(XMLList) <- gsub(".xml", "", XMLFileList)#
  # Collapse to just pertinent information:#
  XMLList <- lapply(XMLList, function(x) {y <- list(); y[["TaxonMatrix"]] <- x$SourceTree$Taxa$TagContents; y[["FileName"]] <- unname(unlist(x$SourceTree$Filename)); y[["Parent"]] <- unname(unlist(x$SourceTree$Parent)); y[["Sibling"]] <- unname(unlist(x$SourceTree$Sibling)); y})#
  # Find any files that contain duplicated taxon names:#
  FilesWithDuplicatedTaxonNames <- names(XMLList)[which(unlist(lapply(XMLList, function(x) any(duplicated(x$TaxonMatrix[, "ListValue"])))))]#
  # If duplicate names were found stop and warn user:#
  if(length(FilesWithDuplicatedTaxonNames) > 0) stop(paste("The following files contain duplicate taxon names: ", paste(FilesWithDuplicatedTaxonNames, collapse = ", "), ". Ensure all taxon names are unique and try again.", sep = ""))#
  # Find any taxon names that do not match between MRP and XML:#
  TaxonMismatches <- mapply(function(x, y) {MRPNames <- rownames(x$Matrix); XMLNames <- y$TaxonMatrix[, "ListValue"]; c(setdiff(MRPNames, XMLNames), setdiff(XMLNames, MRPNames))}, x = MRPList[names(MRPList)], y = XMLList[names(MRPList)])#
  # Find any files with mismatching taxon names between MRP and XML:#
  FilesWithTaxonMismatches <- names(TaxonMismatches)[which(unlist(lapply(TaxonMismatches, function(x) length(x))) > 0)]#
  # If such files are found then stop and warn user:#
  if(length(FilesWithTaxonMismatches) > 0) stop(paste("The following files contain mismatching taxon names between the MRP and XML versions: ", paste(FilesWithTaxonMismatches, collapse = ", "), ". Ensure all taxon names match and try again.", sep = ""))#
  # Compile any name issues:#
  NameIssues <- lapply(XMLList, function(x) {TaxonMatrix <- x$TaxonMatrix; SpacesFound <- c(grep(" ", TaxonMatrix[, "recon_name"]), grep(" ", TaxonMatrix[, "recon_no"]), grep(" ", TaxonMatrix[, "ListValue"])); EmptyValuesFound <- c(which(TaxonMatrix[, "recon_name"] == ""), which(TaxonMatrix[, "recon_no"] == ""), which(TaxonMatrix[, "ListValue"] == "")); RogueNumberCharacters <- setdiff(unique(unlist(strsplit(TaxonMatrix[, "recon_no"], ""))), c(0:9, ";", "-")); RogueNameCharacters <- setdiff(unique(c(unlist(strsplit(TaxonMatrix[, "recon_name"], "")), unlist(strsplit(TaxonMatrix[, "ListValue"], "")))), c(LETTERS, letters, 0:9, "_", ",")); y <- list(SpacesFound, EmptyValuesFound, RogueNumberCharacters, RogueNameCharacters); names(y) <- c("SpacesFound", "EmptyValuesFound", "RogueNumberCharacters", "RogueNameCharacters"); y})#
  # Find any files with spaces in taxon names:#
  FilesWithSpaces <- names(NameIssues)[unlist(lapply(NameIssues, function(x) length(x$SpacesFound))) > 0]#
  # Find any values with empty values for taxon names:#
  FilesWithEmptyValues <- names(NameIssues)[unlist(lapply(NameIssues, function(x) length(x$EmptyValuesFound))) > 0]#
  # Files with rogue values in the recon number field:#
  FilesWithRogueTaxonNumbers <- names(NameIssues)[unlist(lapply(NameIssues, function(x) length(x$RogueNumberCharacters))) > 0]#
  # Files with rogue values in the name fields:#
  FilesWithRogueTaxonNames <- names(NameIssues)[unlist(lapply(NameIssues, function(x) length(x$RogueNameCharacters))) > 0]#
  # If issues with spaces in names stop and warn user:#
  if(length(FilesWithSpaces) > 0) stop(paste("The following files contain spaces in the taxonomic reconciliation (names or numbers): ", paste(FilesWithSpaces, collapse = ", "), ". Remove spaces and try again.", sep = ""))#
  # If issues with empty names stop and warn user:#
  if(length(FilesWithEmptyValues) > 0) stop(paste("The following files contain empty values in the taxonomic reconciliation (names or numbers): ", paste(FilesWithEmptyValues, collapse = ", "), ". Ensure all values are filled and try again.", sep = ""))#
  # If issues with rogue characters in number field stop and warn user:#
  if(length(FilesWithRogueTaxonNumbers) > 0) stop(paste("The following files contain rogue values in the taxonomic reconciliation (numbers): ", paste(FilesWithRogueTaxonNumbers, collapse = ", "), ". Ensure all taxon numbers only include semicolon(s) (the separating character) or dashes (for negative values) and try again.", sep = ""))#
  # If issues with rogue characters in name field stop and warn user:#
  if(length(FilesWithRogueTaxonNames) > 0) stop(paste("The following files contain rogue values in the taxonomic reconciliation (names): ", paste(FilesWithRogueTaxonNames, collapse = ", "), ". Ensure all taxon names are formed from alphanumerics, commas (the separating character) or underscores and try again.", sep = ""))#
  # Reconcile OTU names with XML version:#
  MRPList <- mapply(function(x, y) {rownames(x$Matrix)[unlist(lapply(as.list(y$TaxonMatrix[, "ListValue"]), function(z) which(rownames(x$Matrix) == z)))] <- paste(y$TaxonMatrix[, "recon_no"], y$TaxonMatrix[, "recon_name"], sep = "%%%%"); x$FileName <- y$FileName; if(!is.null(y$Parent)) x$Parent <- y$Parent; if(!is.null(y$Sibling)) x$Sibling <- y$Sibling; x}, x = MRPList[names(MRPList)], y = XMLList[names(MRPList)], SIMPLIFY = FALSE)#
#
  # Print current processing status:#
  cat("Done\nChecking for unsampled parents and siblings...")#
  # Extract parent and sibling names:#
  ParentAndSiblingNames <- sort(unlist(lapply(as.list(unique(unname(unlist(lapply(MRPList, '[', c("Parent", "Sibling")))))), function(x) x[nchar(x) > 0])))#
  # Warn user about any unsampled parents and/or siblings:#
  if(length(setdiff(ParentAndSiblingNames, names(MRPList))) > 0) print(paste("The following parents and siblings are not in the sample (check they are correct or add them into the sample): ", paste(setdiff(ParentAndSiblingNames, names(MRPList)), collapse = ", "), sep = ""))#
  # Print current processing status:#
  cat("Done\nFinding initial multiple-taxon reconciliations...")#
  # Separate out multi-taxon reconcilations:#
  MRPList <- lapply(MRPList, SeparateMultiTaxonReconciliations)#
  # If excluding specimen-level OTUs:#
  if(!IncludeSpecimenLevelOTUs) {#
    # Print current processing status:#
    cat("Done\nRemoving specimen-level OTUs...")#
    # Convert specimen-level OTUs to taxa to DELETE:#
    MRPList <- lapply(MRPList, function(x) {RowNamesToDelete <- which(unlist(lapply(strsplit(rownames(x$Matrix), split = ""), function(y) sum(y == "_") > 2))); if(length(RowNamesToDelete) > 0) rownames(x$Matrix)[RowNamesToDelete] <- "0%%%%DELETE"; x})#
  }#
  # Print current processing status:#
  cat("Done\nRemoving taxa with initial reconciliations of \"DELETE\"...")#
  # Remove any taxa reconciled as DELETE:#
  MRPList <- lapply(MRPList, function(x) {DeleteRows <- which(unlist(lapply(strsplit(rownames(x$Matrix), split = "%%%%"), function(y) y[2])) == "DELETE"); if(length(DeleteRows) > 0) x$Matrix <- x$Matrix[-DeleteRows, , drop = FALSE]; x})#
  # Prune matrices following deletion:#
  MRPList[ActiveMRP(MRPList)] <- lapply(MRPList[ActiveMRP(MRPList)], function(x) {y <- PisaniMRPPrune(Claddis::MakeMorphMatrix(x$Matrix, Weights = x$Weights, ignore.duplicate.taxa = TRUE)); x$Matrix <- y$Matrix_1$Matrix; x$Weights <- y$Matrix_1$Weights; x})#
#
  # Print current processing status:#
  cat("Done\nSearching for and collapsing pre-reconciliation duplicated taxa...")#
  # Collapse any duplicate taxon names:#
  MRPList[ActiveMRP(MRPList)] <- lapply(MRPList[ActiveMRP(MRPList)], function(x) {y <- Claddis::MakeMorphMatrix(x$Matrix, Weights = x$Weights, ignore.duplicate.taxa = TRUE); if(any(duplicated(rownames(y$Matrix_1$Matrix)))) {DuplicateNames <- setdiff(unlist(lapply(strsplit(rownames(y$Matrix_1$Matrix)[duplicated(rownames(y$Matrix_1$Matrix))], split = "%%%%"), '[', 2)), "DELETE"); if(length(DuplicateNames) > 0) cat(paste("\nDuplicate resolved OTU name(s) found in ", x$FileName, ": ", paste(DuplicateNames, collapse = ", "), ". Check this is correct.", sep = "")); y <- CollapseDuplicateTaxonMRP(y)}; x$Matrix <- y$Matrix_1$Matrix; x$Weights <- y$Matrix_1$Weights; x})#
  # Print current processing status:#
  cat("Done\nBuilding initial taxonomy matrix...")#
  # Create taxonomy matrix to store all taxon resolution data:#
  TaxonomyMatrix <- do.call(rbind, strsplit(unique(unname(unlist(lapply(MRPList[ActiveMRP(MRPList)], function(x) rownames(x$Matrix))))), split ="%%%%"))#
  # Add column names:#
  colnames(TaxonomyMatrix) <- c("TaxonNo", "TaxonName")#
  # Print current processing status:#
  cat("Done\nChecking for missing taxon numbers...")#
  # If any "-1" taxa found stop and tell user:#
  if(any(TaxonomyMatrix[, "TaxonNo"] == "-1")) stop(paste("The following taxa have the reconciliation number \"-1\": ", paste(TaxonomyMatrix[TaxonomyMatrix[, "TaxonNo"] == "-1", "TaxonName"], collapse = ", "), sep = ""))#
  # Print current processing status:#
  cat("Done\nBuilding initial Paleobiology Database reconciliation list...")#
  # Create resolved taxon numbers matrix:#
  ResolvedTaxonNumbers <- cbind(unique(TaxonomyMatrix[, "TaxonNo"]), PaleobiologyDBTaxaQuerier(taxon_nos = unique(TaxonomyMatrix[, "TaxonNo"]), interval = NULL))#
  # Deal with subgenera:#
  ResolvedTaxonNumbers[, "TaxonName"] <- gsub(" \\(|\\)", "", ResolvedTaxonNumbers[, "TaxonName"])#
  # Add column names to first value (input number):#
  colnames(ResolvedTaxonNumbers)[1] <- "InputNo"#
  # If specifying an Interval:#
  if(!all(is.null(Interval))) {#
    # Do same query for just taxa in Interval:#
    ResolvedTaxonNumbersInterval <- cbind(unique(TaxonomyMatrix[, "TaxonNo"]), PaleobiologyDBTaxaQuerier(taxon_nos = unique(TaxonomyMatrix[, "TaxonNo"]), interval = Interval))#
    # Deal with subgenera:#
    ResolvedTaxonNumbersInterval[, "TaxonName"] <- gsub(" \\(|\\)", "", ResolvedTaxonNumbersInterval[, "TaxonName"])#
    # Invert variable so only includes taxa outside Interval:#
    ResolvedTaxonNumbersInterval <- ResolvedTaxonNumbers[is.na(ResolvedTaxonNumbersInterval[, "TaxonName"]), ]#
    # Find any nomen dubia etc. to delete:#
    DeleteRows <- which(unlist(lapply(lapply(lapply(as.list(ResolvedTaxonNumbersInterval[, "TaxonValidity"]), match, x = DeletionCategories), sort), length)) > 0)#
    # If there are deletes then remove them from the matrix:#
    if(length(DeleteRows) > 0) ResolvedTaxonNumbersInterval <- ResolvedTaxonNumbersInterval[-DeleteRows, , drop = FALSE]#
  }#
  # Print current processing status:#
  cat("Done\nChecking taxon names match with database version...")#
  # Vector to store any failed matches:#
  failedmatches <- vector(mode = "character")#
  # For each initially reconciled name:#
  for(i in 1:nrow(TaxonomyMatrix)) {#
    # Get resolved name:#
    resolvedname <- gsub(" ", "_", ResolvedTaxonNumbers[which(ResolvedTaxonNumbers[, "InputNo"] == TaxonomyMatrix[i, "TaxonNo"]), "TaxonName"])#
    # Get input name:#
    inputname <- TaxonomyMatrix[i, "TaxonName"]#
    # Check names truly match (i.e., deals with case of indets where direct match not possible) and store if not:#
    if(resolvedname != inputname && any(is.na(match(strsplit(resolvedname, "_")[[1]], strsplit(inputname, "_")[[1]])))) failedmatches <- c(failedmatches, paste("Input name ", inputname, " does not match database name for corresponding number (", resolvedname, ").", sep = ""))#
  }#
  # If there are failed matches:#
  if(length(failedmatches) > 0) {#
    # Provide list to user:#
    cat(paste(failedmatches, collapse = "\n"))#
    # Stop function (will break later otherwise):#
    stop("")#
  }#
  # Print current processing status:#
  cat("Done\nChecking taxon validities...")#
  # Check for any new kind of resolution (should be empty vector):#
  newresolutions <- setdiff(sort(unique(ResolvedTaxonNumbers[, "TaxonValidity"])), c(DeletionCategories, synonyms))#
  # Stop if new resolutiosn found (need to add these to the resolution types above):#
  if(length(newresolutions) > 0) stop(paste("New resolution type found!: ", newresolutions, sep = ""))#
  # Print current processing status:#
  cat("Done\nBuilding synonymy tables...")#
  # Empty vector to store rows that correspond to some form of junior synonym:#
  synonymrows <- c()#
  # Find all junior synonym rows:#
  for(i in synonyms) synonymrows <- sort(c(synonymrows, which(ResolvedTaxonNumbers[, "TaxonValidity"] == i)))#
  # Set junior synonym matrix:#
  JuniorSynonyms <- ResolvedTaxonNumbers[synonymrows, , drop = FALSE]#
  # Create empty matrix to store senior synoyms:#
  SeniorSynonyms <- matrix(nrow = 0, ncol = 8, dimnames = list(c(), c("OriginalTaxonNo", "ResolvedTaxonNo", "TaxonName", "TaxonRank", "ParentTaxonNo", "TaxonValidity", "AcceptedNumber", "AcceptedName")))#
  # Reconcile senior synonym with database:#
  currenttaxa <- PaleobiologyDBTaxaQuerier(gsub("txn:", "", ResolvedTaxonNumbers[synonymrows, "AcceptedNumber"]))#
  # Deal with subgenera:#
  currenttaxa[, "TaxonName"] <- gsub(" \\(|\\)", "", currenttaxa[, "TaxonName"])#
  # While there are taxa with validity issues:#
  while(any(!is.na(currenttaxa[, "TaxonValidity"]))) {#
    # Isolate rows to check (i.e., just rows where validity isn't NA (i.e., resolved):#
    rowstocheck <- which(!is.na(currenttaxa[, "TaxonValidity"]))#
    # Check just those taxa:#
    currenttaxa[rowstocheck, ] <- PaleobiologyDBTaxaQuerier(taxon_nos = gsub("txn:", "", currenttaxa[rowstocheck, "AcceptedNumber"]), taxon_names = currenttaxa[rowstocheck, "AcceptedName"])#
    # Deal with subgenera:#
    currenttaxa[rowstocheck, "TaxonName"] <- gsub(" \\(|\\)", "", currenttaxa[rowstocheck, "TaxonName"])#
  }#
  # Make current taxa into senior synonyms list:#
  SeniorSynonyms <- currenttaxa#
  # If using an Interval:#
  if(!all(is.null(Interval))) {#
    # Update resolved taxon numbers to valid taxa only:#
    ResolvedTaxonNumbersInterval[which(!is.na(match(ResolvedTaxonNumbersInterval[, "InputNo"], JuniorSynonyms[, "InputNo"]))), c("OriginalTaxonNo", "ResolvedTaxonNo", "TaxonName", "TaxonRank", "ParentTaxonNo", "TaxonValidity", "AcceptedNumber", "AcceptedName")] <- SeniorSynonyms[match(ResolvedTaxonNumbersInterval[, "InputNo"], JuniorSynonyms[, "InputNo"])[!is.na(match(ResolvedTaxonNumbersInterval[, "InputNo"], JuniorSynonyms[, "InputNo"]))], c("OriginalTaxonNo", "ResolvedTaxonNo", "TaxonName", "TaxonRank", "ParentTaxonNo", "TaxonValidity", "AcceptedNumber", "AcceptedName")]#
  }#
  # Only complete this step if including specimen-level OTUs (there will not be any at this stage anyway if set as FALSE):#
  if(IncludeSpecimenLevelOTUs) {#
    # Print current processing status:#
    cat("Done\nChecking validity of indeterminate taxon reconciliations...")#
    # Get list of indeterminates:#
    indeterminates <- TaxonomyMatrix[which((unlist(lapply(lapply(strsplit(TaxonomyMatrix[, "TaxonName"], "_"), '==', "aff"), sum)) + unlist(lapply(lapply(strsplit(TaxonomyMatrix[, "TaxonName"], "_"), '==', "cf"), sum)) + unlist(lapply(lapply(strsplit(TaxonomyMatrix[, "TaxonName"], "_"), '==', "indet"), sum)) + unlist(lapply(lapply(strsplit(TaxonomyMatrix[, "TaxonName"], "_"), '==', "sp"), sum))) > 0), "TaxonName"]#
    # For each indeterminate:#
    for(i in indeterminates) {#
      # Get resolved row number:#
      resolvedrownumber <- which(ResolvedTaxonNumbers[, "InputNo"] == TaxonomyMatrix[which(TaxonomyMatrix[, "TaxonName"] == i), "TaxonNo"])#
      # If a possible invalid taxon (validity is not blank):#
      if(!is.na(ResolvedTaxonNumbers[resolvedrownumber, "TaxonValidity"])) {#
        # Get accepted number of taxon (may be NA):#
        AcceptedNumber <- gsub("txn:", "", ResolvedTaxonNumbers[resolvedrownumber, "AcceptedNumber"])#
        # If accepted number is blank (NA) stop adn warn user taxon is invalid:#
        if(is.na(AcceptedNumber)) stop(paste(i, " assigned to a taxon that is invalid, consider renaming.", sep = ""))#
        # If accepted numebr is different to input number stop and warn user taxon is synonymised:#
        if(AcceptedNumber != ResolvedTaxonNumbers[resolvedrownumber, "InputNo"]) stop(paste(i, " assigned to a taxon that is invalid, consider renaming.", sep = ""))#
      }#
    }#
  }#
#
  # Print current processing status:#
  cat("Done\nDeleting taxa resolved as nomen dubium and the like...")#
  # Get input numbers that should be deleted:#
  NumbersToDelete <- ResolvedTaxonNumbers[unlist(lapply(as.list(DeletionCategories), function(x) which(ResolvedTaxonNumbers[, "TaxonValidity"] == x))), "InputNo"]#
  # As long as there are numbers to delete:#
  if(length(NumbersToDelete) > 0) {#
    # Remove any taxa to delete:#
    MRPList[ActiveMRP(MRPList)] <- lapply(MRPList[ActiveMRP(MRPList)], function(x) {TaxonNumbers <- do.call(rbind, strsplit(rownames(x$Matrix), split = "%%%%"))[, 1]; DeleteRows <- sort(match(NumbersToDelete, TaxonNumbers)); if(length(DeleteRows) > 0) x$Matrix <- x$Matrix[-DeleteRows, , drop = FALSE]; x})#
    # Prune matrices following deletion:#
    MRPList[ActiveMRP(MRPList)] <- lapply(MRPList[ActiveMRP(MRPList)], function(x) {y <- PisaniMRPPrune(Claddis::MakeMorphMatrix(x$Matrix, Weights = x$Weights, ignore.duplicate.taxa = TRUE)); x$Matrix <- y$Matrix_1$Matrix; x$Weights <- y$Matrix_1$Weights; x})#
  }#
  # Print current processing status:#
  cat("Done\nReplacing junior synonyms with senior synonyms...")#
  # Rebuild junior synonyms into a vector of names:#
  JuniorSynonymsVector <- paste(JuniorSynonyms[, "InputNo"], gsub(" ", "_", JuniorSynonyms[, "TaxonName"]), sep = "%%%%")#
  # Rebuild senior synonyms into a vector of names:#
  SeniorSynonymsVector <- paste(unlist(lapply(apply(SeniorSynonyms[, c("OriginalTaxonNo", "ResolvedTaxonNo"), drop = FALSE], 1, as.list), function(x) unname(gsub("txn:|var:", "", unlist(x)[!is.na(unlist(x))][1])))), gsub(" ", "_", SeniorSynonyms[, "TaxonName"]), sep = "%%%%")#
  # Build synonym matrix:#
  SynonymyMatrix <- cbind(JuniorSynonymsVector, SeniorSynonymsVector)#
  # Replace junior synonyms with senior synonyms:#
  MRPList[ActiveMRP(MRPList)] <- lapply(MRPList[ActiveMRP(MRPList)], function(x) {SynonymyRows <- sort(match(SynonymyMatrix[, 1], rownames(x$Matrix))); if(length(SynonymyRows) > 0) rownames(x$Matrix)[SynonymyRows] <- SynonymyMatrix[match(rownames(x$Matrix)[SynonymyRows], SynonymyMatrix[, 1]), 2]; x})#
#
  # Collapse any duplicate taxa created by this substitution:#
  MRPList[ActiveMRP(MRPList)] <- lapply(MRPList[ActiveMRP(MRPList)], function(x) {y <- Claddis::MakeMorphMatrix(x$Matrix, Weights = x$Weights, ignore.duplicate.taxa = TRUE); if(any(duplicated(rownames(y$Matrix_1$Matrix)))) {DuplicateNames <- rownames(y$Matrix_1$Matrix)[duplicated(rownames(y$Matrix_1$Matrix))]; y <- CollapseDuplicateTaxonMRP(y)}; x$Matrix <- y$Matrix_1$Matrix; x$Weights <- y$Matrix_1$Weights; x})#
  # Prune characters made redundant by these collapses:#
  MRPList[ActiveMRP(MRPList)] <- lapply(MRPList[ActiveMRP(MRPList)], function(x) {y <- PisaniMRPPrune(Claddis::MakeMorphMatrix(x$Matrix, Weights = x$Weights, ignore.duplicate.taxa = TRUE)); x$Matrix <- y$Matrix_1$Matrix; x$Weights <- y$Matrix_1$Weights; x})#
  # GOT TO HERE WITH REFACTOR (BUT HAVE JUMPED AROUND A BUNCH, SO...)#
#
  # Print current processing status:#
  cat("Done\nBuilding taxonomy...")#
  # Get a list of the valid OTU names (may be pruned down later to just those in target clade):#
  ValidOTUNames <- unique(unlist(lapply(lapply(MRPList, '[[', "Matrix"), rownames)))[grep("_", unique(unlist(lapply(lapply(MRPList, '[[', "Matrix"), rownames))))]#
  # Replace junior with senior synonyms in resolved names matrix:#
  ResolvedTaxonNumbers[synonymrows, c("OriginalTaxonNo", "ResolvedTaxonNo", "TaxonName", "TaxonRank", "ParentTaxonNo", "TaxonValidity", "AcceptedNumber", "AcceptedName")] <- SeniorSynonyms#
  # Overwrite resolved number with resolved taxon number:#
  ResolvedTaxonNumbers[, "ResolvedTaxonNo"] <- gsub("txn:|var:", "", unlist(lapply(lapply(apply(ResolvedTaxonNumbers[, c("OriginalTaxonNo", "ResolvedTaxonNo")], 1, sort), rev), '[', 1)))#
  # Remove original taxon number column:#
  ResolvedTaxonNumbers <- ResolvedTaxonNumbers[, -which(colnames(ResolvedTaxonNumbers) == "OriginalTaxonNo")]#
  # Remove deleted taxa from resolved names matrix (if there are any):#
  if(length(which(!is.na(ResolvedTaxonNumbers[, "TaxonValidity"]))) > 0) ResolvedTaxonNumbers <- ResolvedTaxonNumbers[-which(!is.na(ResolvedTaxonNumbers[, "TaxonValidity"])), , drop = FALSE]#
  # Reformat parent taxon numbers into just numbers:#
  ResolvedTaxonNumbers[, "ParentTaxonNo"] <- gsub("txn:", "", ResolvedTaxonNumbers[, "ParentTaxonNo"])#
  # Collapse resolved matrix to just field with values (i.e., drop valid and senior synonym columns):#
  ResolvedTaxonNumbers <- ResolvedTaxonNumbers[, c("ResolvedTaxonNo", "TaxonName", "TaxonRank", "ParentTaxonNo")]#
  # If doing something with missing species (i.e., those not currently included as OTUs, but existing in target clade):#
  if(MissingSpecies != "exclude") {#
    # Find all descendants of target clade:#
    AllChildren <- PaleobiologyDBDescendantFinder(taxon_nos = "1", taxon_names = TargetClade, validonly = TRUE, returnrank = "3", interval = Interval)#
    # Deal with subgenera:#
    AllChildren[, "TaxonName"] <- gsub(" \\(|\\)", "", AllChildren[, "TaxonName"])#
    # If inserting all missing species get all possible species parent numbers:#
    if(MissingSpecies == "all") CurrentSpeciesParentNumbers <- unique(c(gsub("txn:", "", AllChildren[, "ParentTaxonNo"]), ResolvedTaxonNumbers[which(ResolvedTaxonNumbers[, "TaxonRank"] == 3), "ParentTaxonNo"]))#
    # If only inserting missing species at genus-level find parent numbers of all current species (i.e., potential genera to add):#
    if(MissingSpecies == "genus") CurrentSpeciesParentNumbers <- unique(ResolvedTaxonNumbers[which(ResolvedTaxonNumbers[, "TaxonRank"] == 3), "ParentTaxonNo"])#
    # Find any parents not already present in resolved numbers matrix:#
    AsYetUnsampledSpeciesParents <- setdiff(CurrentSpeciesParentNumbers, ResolvedTaxonNumbers[, "ResolvedTaxonNo"])#
    # If such parents exist:#
    if(length(AsYetUnsampledSpeciesParents) > 0) {#
      # Find unsampled species parents:#
      CurrentSpeciesParents <- PaleobiologyDBTaxaQuerier(taxon_nos = AsYetUnsampledSpeciesParents)#
      # Deal with subgenera:#
      CurrentSpeciesParents[, "TaxonName"] <- gsub(" \\(|\\)", "", CurrentSpeciesParents[, "TaxonName"])#
      # Find rows corresponding to valid genera:#
      ValidGenusRows <- intersect(which(is.na(CurrentSpeciesParents[, "TaxonValidity"])), which(CurrentSpeciesParents[, "TaxonRank"] == "5"))#
      # If there are valid genera then add these to resolved taxon numbers:#
      if(length(ValidGenusRows) > 0) ResolvedTaxonNumbers <- rbind(ResolvedTaxonNumbers, cbind(unname(gsub("txn:|var:", "", unlist(lapply(lapply(lapply(apply(CurrentSpeciesParents[ValidGenusRows, c("OriginalTaxonNo", "ResolvedTaxonNo"), drop = FALSE], 1, list), unlist), sort, decreasing = TRUE), '[', 1)))), CurrentSpeciesParents[ValidGenusRows, c("TaxonName", "TaxonRank")] , gsub("txn:", "", CurrentSpeciesParents[ValidGenusRows, "ParentTaxonNo"])))#
    }#
    # If including all species:#
    if(MissingSpecies == "all") {#
      # Update Valid OTUs accordingly#
      ValidOTUNames <- unique(c(ValidOTUNames, gsub(" ", "_", paste(unlist(lapply(strsplit(gsub("NA", "", paste(AllChildren[, "OriginalTaxonNo"], AllChildren[, "ResolvedTaxonNo"], sep = "")), split = "var:|txn:"), '[[', 2)), AllChildren[, "TaxonName"], sep = "%%%%"))))#
      # Set new children to add to resolved taxon numbers later:#
      NewChildren <- matrix(c(gsub("txn:|var:", "", unlist(lapply(apply(AllChildren[, c("OriginalTaxonNo", "ResolvedTaxonNo")], 1, sort, decreasing = TRUE), '[', 1))), AllChildren[, c("TaxonName", "TaxonRank")], gsub("txn:", "", AllChildren[, "ParentTaxonNo"])), ncol = 4)#
    }#
    # If including only species assigned to genus-level OTUs:#
    if(MissingSpecies == "genus") {#
      # Get current genus numbers (to check what has already been included):#
      CurrentGenusNumbers <- ResolvedTaxonNumbers[which(ResolvedTaxonNumbers[, "TaxonRank"] == 5), "ResolvedTaxonNo"]#
      # Get children of sampled genera:#
      GeneraChildren <- PaleobiologyDBDescendantFinder(taxon_nos = CurrentGenusNumbers, validonly = TRUE, returnrank = "3")#
      # Deal with subgenera:#
      GeneraChildren[, "TaxonName"] <- gsub(" \\(|\\)", "", GeneraChildren[, "TaxonName"])#
      # Update valid OTUs with children of all sampled genera:#
      ValidOTUNames <- unique(c(ValidOTUNames, gsub(" ", "_", paste(unlist(lapply(strsplit(gsub("NA", "", paste(GeneraChildren[, "OriginalTaxonNo"], GeneraChildren[, "ResolvedTaxonNo"], sep = "")), split = "var:|txn:"), '[[', 2)), GeneraChildren[, "TaxonName"], sep = "%%%%"))))#
      # Set new children to add to resolved taxon numbers later:#
      NewChildren <- matrix(c(gsub("txn:|var:", "", unlist(lapply(apply(GeneraChildren[, c("OriginalTaxonNo", "ResolvedTaxonNo")], 1, sort, decreasing = TRUE), '[', 1))), GeneraChildren[, c("TaxonName", "TaxonRank")], gsub("txn:", "", GeneraChildren[, "ParentTaxonNo"])), ncol = 4)#
    }#
    # Find any new children not already included in resolved taxon numbers list:#
    ChildrenToAdd <- setdiff(NewChildren[, 1], ResolvedTaxonNumbers[, "ResolvedTaxonNo"])#
    # If there are children to add then add them to resolved taxon numbers:#
    if(length(ChildrenToAdd) > 0) ResolvedTaxonNumbers <- rbind(ResolvedTaxonNumbers, NewChildren[match(ChildrenToAdd, NewChildren[, 1]), ])#
  }#
  # Find parents of all resolved taxon numbers (need to make sure these are valid or will propogate errors):#
  ParentMatrix <- PaleobiologyDBTaxaQuerier(ResolvedTaxonNumbers[, "ParentTaxonNo"], original = TRUE)#
  # If any are invalid then update to valid version:#
  if(any(!is.na(ParentMatrix[, "AcceptedNumber"]))) ParentMatrix[!is.na(ParentMatrix[, "AcceptedNumber"]), ] <- do.call(rbind, lapply(as.list(gsub("txn:", "", ParentMatrix[!is.na(ParentMatrix[, "AcceptedNumber"]), "AcceptedNumber"])), function(x) PaleobiologyDBTaxaQuerier(x, original = FALSE)))#
  # Update parent numbers to valid versions only:#
  ResolvedTaxonNumbers[, "ParentTaxonNo"] <- unname(unlist(lapply(apply(ParentMatrix[, c("OriginalTaxonNo", "ResolvedTaxonNo")], 1, list), function(x) {x <- unlist(x); gsub("txn:|var:", "", x[!is.na(x)][1])})))#
  # Get initial parent child relationships based on OTUs:#
  ParentChildRelationships <- paste(unlist(lapply(strsplit(ValidOTUNames, "%%%%"), '[', 1)), ResolvedTaxonNumbers[match(unlist(lapply(strsplit(ValidOTUNames, "%%%%"), '[', 1)), ResolvedTaxonNumbers[, "ResolvedTaxonNo"]), "ParentTaxonNo"], sep = " belongs to ")#
  # If including specimen level OTUs:#
  if(IncludeSpecimenLevelOTUs) {#
    # Find which rows correspond to indeterminate and sp taxa (i.e., those where parent should be initial reconciliation):#
    indetsandsps <- sort(c(which(unlist(lapply(lapply(lapply(lapply(lapply(strsplit(ValidOTUNames, "%%%%"), '[', 2), strsplit, split = "_"), unlist), '==', "indet"), any))), which(unlist(lapply(lapply(lapply(lapply(lapply(strsplit(ValidOTUNames, "%%%%"), '[', 2), strsplit, split = "_"), unlist), '==', "sp"), any)))))#
    # If such taxa exist then update parent child relationships accordingly:#
    if(length(indetsandsps) > 0) ParentChildRelationships[indetsandsps] <- paste(unlist(lapply(strsplit(ValidOTUNames[indetsandsps], "%%%%"), '[', 1)), unlist(lapply(strsplit(ValidOTUNames[indetsandsps], "%%%%"), '[', 1)), sep = " belongs to ")#
  }#
  # Get list of new children (for which parents are needed) - excludes "Life" which has no parent:#
  newchildren <- setdiff(unlist(lapply(strsplit(ParentChildRelationships, " belongs to "), '[', 2)), "28595")#
  # As long as there are still children in need of parents:#
  while(length(newchildren) > 0) {#
    # Find any numbers missing for the taxonomy name resolution matrix:#
    missingfromresolutions <- newchildren[which(is.na(match(newchildren, ResolvedTaxonNumbers[, "ResolvedTaxonNo"])))]#
    # If there are such numbers:#
    if(length(missingfromresolutions) > 0) {#
      # Get raw query data for new names#
      rawquery <- PaleobiologyDBTaxaQuerier(taxon_nos = missingfromresolutions)#
      # Look for synonymy rows (taxon validity is a synonym type):#
      NewSynonymRows <- sort(unique(unname(unlist(lapply(as.list(synonyms), function(x) which(rawquery[, "TaxonValidity"] == x))))))#
      # If synonyms were found:#
      if(length(NewSynonymRows) > 0) {#
        # Fix any synonyms (replace junior with senior):#
        rawquery[NewSynonymRows, c("ResolvedTaxonNo", "TaxonName")] <- rawquery[NewSynonymRows, c("AcceptedNumber", "AcceptedName"), drop = FALSE]#
        # Remove now obsolete validity data:#
        rawquery[NewSynonymRows, c("TaxonValidity", "AcceptedNumber", "AcceptedName")] <- NA#
      }#
      # Deal with subgenera:#
      rawquery[, "TaxonName"] <- gsub(" \\(|\\)", "", rawquery[, "TaxonName"])#
      # Add formatted results of query to resolved names matrix:#
      ResolvedTaxonNumbers <- rbind(ResolvedTaxonNumbers, unname(cbind(gsub("txn:|var:", "", unname(unlist(lapply(lapply(lapply(apply(rawquery[, c("OriginalTaxonNo", "ResolvedTaxonNo"), drop = FALSE], 1, list), unlist), sort, decreasing = TRUE), '[', 1)))), rawquery[, c("TaxonName", "TaxonRank"), drop = FALSE], gsub("txn:", "", rawquery[, "ParentTaxonNo"]))))#
    }#
    # Add new parent child relationships to list:#
    ParentChildRelationships <- c(ParentChildRelationships, paste(ResolvedTaxonNumbers[match(newchildren, ResolvedTaxonNumbers[, "ResolvedTaxonNo"]), "ResolvedTaxonNo"], ResolvedTaxonNumbers[match(newchildren, ResolvedTaxonNumbers[, "ResolvedTaxonNo"]), "ParentTaxonNo"], sep = " belongs to "))#
    # Update new children:#
    newchildren <- setdiff(ResolvedTaxonNumbers[match(newchildren, ResolvedTaxonNumbers[, "ResolvedTaxonNo"]), "ParentTaxonNo"], "28595")#
  }#
  # If Life is missing then add it at bottom:#
  if(all(!ResolvedTaxonNumbers[, "ResolvedTaxonNo"] == "28595")) ResolvedTaxonNumbers <- rbind(ResolvedTaxonNumbers, c("28595", "Life", "25", NA))#
  # Convert parent-child relationships into a matrix (columns for child and parent):#
  parentchildmatrix <- matrix(unlist(strsplit(ParentChildRelationships, split = " belongs to ")), ncol = 2, byrow = TRUE, dimnames = list(c(), c("Child", "Parent")))#
  # Update parent-child matrix with child names:#
  parentchildmatrix[, "Child"] <- ResolvedTaxonNumbers[match(parentchildmatrix[, "Child"], ResolvedTaxonNumbers[, "ResolvedTaxonNo"]), "TaxonName"]#
  # Update parent-child matrix with parent names:#
  parentchildmatrix[, "Parent"] <- ResolvedTaxonNumbers[match(parentchildmatrix[, "Parent"], ResolvedTaxonNumbers[, "ResolvedTaxonNo"]), "TaxonName"]#
  # Add valid OTU names into parent-child matrix:#
  parentchildmatrix[c(1:length(ValidOTUNames)), "Child"] <- unlist(lapply(strsplit(ValidOTUNames, "%%%%"), '[', 2))#
  # Add missing taxon ("Life") to parent-child matrix:#
  parentchildmatrix[which(is.na(parentchildmatrix[, "Parent"])), "Parent"] <- "Life"#
  # Create empty taxonomy MRP matrix:#
  TaxonomyMRP <- matrix(0, nrow = length(ValidOTUNames), ncol = length(sort(unique(parentchildmatrix[, "Parent"]))), dimnames = list(sort(unlist(lapply(strsplit(ValidOTUNames, "%%%%"), '[', 2))), sort(unique(parentchildmatrix[, "Parent"]))))#
  # Remove duplicates:#
  parentchildmatrix <- matrix(unlist(strsplit(unique(paste(parentchildmatrix[, "Child"], parentchildmatrix[, "Parent"], sep = "%%%%")), "%%%%")), ncol = 2, byrow = TRUE, dimnames = list(c(), c("Child", "Parent")))#
  # Check for duplicate names:#
  if(any(duplicated(sort(unlist(lapply(strsplit(ValidOTUNames, "%%%%"), '[[', 2)))))) stop(paste("The following OTU names are duplicated in the database (check and correct): ", paste(sort(unlist(lapply(strsplit(ValidOTUNames, "%%%%"), '[[', 2)))[duplicated(sort(unlist(lapply(strsplit(ValidOTUNames, "%%%%"), '[[', 2))))], sep = ", "), sep = ""))#
  # For each OTU (traces up through hierarchy until its presence in every higher taxon to which it belongs is assigned)::#
  for(i in 1:length(ValidOTUNames)) {#
    # Set starting current child taxon:#
    currentchild <- parentchildmatrix[i, "Child"]#
    # Set starting current parent taxon:#
    currentparent <- setdiff(parentchildmatrix[which(parentchildmatrix[, "Child"] == currentchild), "Parent"], currentchild)#
    # Record presence of child in parent in taxonomy matrix:#
    TaxonomyMRP[parentchildmatrix[i, "Child"], currentparent] <- 1#
    # As long as the parent is not "Life" (top of taxonomic hierarchy not reached):#
    while(currentparent != "Life") {#
      # Check there is not a duplicate taxon issue and stop and warn user if there is:#
      if(length(currentparent) > 1) stop(paste(currentchild, " is duplicated in the Paleobiology Database! Fix and try again.", sep = ""))#
      # Update child with previous parent:#
      currentchild <- currentparent#
      # Update parent with new parent:#
      currentparent <- setdiff(parentchildmatrix[which(parentchildmatrix[, "Child"] == currentchild), "Parent"], currentchild)#
      # Record presence of child in parent:#
      TaxonomyMRP[parentchildmatrix[i, "Child"], currentparent] <- 1#
    }#
  }#
  # Print current processing status:#
  cat("Done\nDealing with subgenera...")#
  # Find any subgenera names (as supraspecific column names only):#
  subgenerarows <- grep("\\(", colnames(TaxonomyMRP))#
  # If subgenera found make these single names (i.e., removes parentheses that will screw up Newick trees later):#
  if(length(subgenerarows) > 0) colnames(TaxonomyMRP)[subgenerarows] <- gsub("\\(|\\)| ", "", colnames(TaxonomyMRP)[subgenerarows])#
  # Correct subgenera in MRP list too:#
  MRPList <- lapply(MRPList, function(x) {NamesToCheck <- rownames(x$Matrix); NamesToCheck <- gsub("_\\(|\\)", "", NamesToCheck); rownames(x$Matrix) <- NamesToCheck; x})#
  # Print current processing status:#
  cat("Done\nTidying up taxonomy...")#
  # Check target clade is actually found:#
  if(length(which(colnames(TaxonomyMRP) == TargetClade)) == 0) stop("Target clade not found in taxonomy. Check spelling/Paleobiology database validity.")#
  # Work out which taxa are actually valid OTUs (belong to target clade):#
  NewValidOTUs <- names(which(TaxonomyMRP[, TargetClade] == 1))#
  # Find any subspecies names:#
  SubspeciesNames <- NewValidOTUs[unlist(lapply(strsplit(NewValidOTUs, split = ""), function(x) all(c(sum(x == "_") == 2, length(grep("[:A-Z:]", x)) == 1))))]#
  # Only continue if subspecies were found:#
  if(length(SubspeciesNames) > 0) {#
    # Find any subspecues where species is not in sample:#
    SubspeciesWhereSpeciesIsNotFound <- SubspeciesNames[!unlist(lapply(as.list(SubspeciesNames), function(x) any(NewValidOTUs == paste(strsplit(x, split = "_")[[1]][1:2], collapse = "_"))))]#
    # If subspecies without sampled species :#
    if(length(SubspeciesWhereSpeciesIsNotFound) > 0) {#
      # Rename these with species names:#
      NewValidOTUs[match(SubspeciesWhereSpeciesIsNotFound, NewValidOTUs)] <- unlist(lapply(strsplit(SubspeciesWhereSpeciesIsNotFound, split = "_"), function(x) paste(x[1:2], collapse = "_")))#
      # Rename taxonomy MRP rownames with species names too:#
      rownames(TaxonomyMRP)[match(SubspeciesWhereSpeciesIsNotFound, rownames(TaxonomyMRP))] <- unlist(lapply(strsplit(SubspeciesWhereSpeciesIsNotFound, split = "_"), function(x) paste(x[1:2], collapse = "_")))#
    }#
    # Collapse subspecies back to just the names where the species is already sampled:#
    SubspeciesNames <- setdiff(SubspeciesNames, SubspeciesWhereSpeciesIsNotFound)#
    # If there are subspecies where species already exists then prune these from the taxonomy MRP:#
    if(length(SubspeciesNames) > 0) NewValidOTUs <- NewValidOTUs[-match(SubspeciesNames, NewValidOTUs)]#
  }#
  # Modify this if using intervals:#
  if(!all(is.null(Interval))) NewValidOTUs <- setdiff(NewValidOTUs, gsub(" ", "_", ResolvedTaxonNumbersInterval[, "TaxonName"]))#
  # Can now strip out numbers from taxon names:#
  for(i in 1:length(MRPList)) if(!is.null(rownames(MRPList[[i]]$Matrix))) rownames(MRPList[[i]]$Matrix) <- unlist(lapply(strsplit(rownames(MRPList[[i]]$Matrix), "%%%%"), '[', 2))#
  # Collapse taxonomy MRP to just new valid taxa:#
  TaxonomyMRP <- TaxonomyMRP[NewValidOTUs, ]#
  # Make taxonomy MRP into list:#
  TaxonomyMRPlist <- split(TaxonomyMRP, rep(1:ncol(TaxonomyMRP), each = nrow(TaxonomyMRP)))#
  # Add column names to list:#
  names(TaxonomyMRPlist) <- colnames(TaxonomyMRP)#
  # Find higher taxa for which every taxon is present:#
  redundanthighertaxa <- colnames(TaxonomyMRP)[intersect(which(unlist(lapply(lapply(TaxonomyMRPlist, unique), length)) == 1), which(unlist(lapply(lapply(TaxonomyMRPlist, unique), '[', 1)) == 1))]#
  # Empty higher taxa:#
  emptyhighertaxa <- colnames(TaxonomyMRP)[intersect(which(unlist(lapply(lapply(TaxonomyMRPlist, unique), length)) == 1), which(unlist(lapply(lapply(TaxonomyMRPlist, unique), '[', 1)) == 0))]#
  # Find taxonomic autapomorphies (those with just one OTU and hence redundant):#
  taxonomicautapomorphies <- names(which(unlist(lapply(TaxonomyMRPlist, sum)) == 1))#
  # Collapse taxonomy MRP by removing constant characters (i.e., most of the subgroups just established - not autapomorphies as they can be substitutes later!):#
  TaxonomyMRP <- TaxonomyMRP[, -match(c(redundanthighertaxa, emptyhighertaxa), colnames(TaxonomyMRP)), drop = FALSE]#
  # Print current processing status:#
  cat("Done\nSubstituting valid OTUs for supraspecific taxa...")#
  # Find datasets with (valid) surpaspecific OTUs:#
  datasetswithsupraspecificOTUs <- which(unlist(lapply(lapply(lapply(lapply(MRPList, '[[', "Matrix"), rownames), intersect, y = colnames(TaxonomyMRP)), length)) > 0)#
  # If such data sets exist:#
  if(length(datasetswithsupraspecificOTUs) > 0) {#
    # For each such data set:#
    for(i in datasetswithsupraspecificOTUs) {#
      # Find higher taxa that will need to be replaced:#
      highertaxatoreplace <- intersect(rownames(MRPList[[i]]$Matrix), colnames(TaxonomyMRP))#
      # For each higher taxon to replace:#
      for(j in highertaxatoreplace) {#
        # Find substitue names from taxonomy:#
        substitutenames <- names(which(TaxonomyMRP[, j] == 1))#
        # Add these to end of matrix using coding for higher taxon:#
        MRPList[[i]]$Matrix <- rbind(MRPList[[i]]$Matrix, matrix(rep(MRPList[[i]]$Matrix[j, ], length(substitutenames)), nrow = length(substitutenames), byrow = TRUE, dimnames = list(substitutenames, c())))#
        # Remove now replaced higher taxon from matrix:#
        MRPList[[i]]$Matrix <- MRPList[[i]]$Matrix[-which(rownames(MRPList[[i]]$Matrix) == j), , drop = FALSE]#
      }#
    }#
  }#
  # Print current processing status:#
  cat("Done\nRetracting subspecies into species...")#
  # Replace all subspecies with their species name:#
  MRPList[ActiveMRP(MRPList)] <- lapply(MRPList[ActiveMRP(MRPList)], function(x) {UnderscoreAndCapitalCounts <- matrix(unlist(lapply(strsplit(rownames(x$Matrix), split = ""), function(y) c(sum(y == "_"), length(grep("[:A-Z:]", y))))), ncol = 2, byrow = TRUE, dimnames = list(c(), c("Underscores", "Capitals"))); SubspeciesRows <- intersect(which(UnderscoreAndCapitalCounts[, "Underscores"] == 2), which(UnderscoreAndCapitalCounts[, "Capitals"] == 1)); if(length(SubspeciesRows) > 0) rownames(x$Matrix)[SubspeciesRows] <- unlist(lapply(strsplit(rownames(x$Matrix)[SubspeciesRows], split = "_"), function(z) paste(z[1:2], collapse = "_"))); x})#
  # Collapse any duplicate taxon names:#
  MRPList[ActiveMRP(MRPList)] <- lapply(MRPList[ActiveMRP(MRPList)], function(x) {y <- Claddis::MakeMorphMatrix(x$Matrix, Weights = x$Weights, ignore.duplicate.taxa = TRUE); if(any(duplicated(rownames(y$Matrix_1$Matrix)))) {DuplicateNames <- rownames(y$Matrix_1$Matrix)[duplicated(rownames(y$Matrix_1$Matrix))]; if(length(DuplicateNames) > 0) cat(paste("\nDuplicate resolved OTU name(s) found post higher-taxon substitution in ", x$FileName, ": ", paste(DuplicateNames, collapse = ", "), ". Check this is correct.", sep = "")); y <- CollapseDuplicateTaxonMRP(y)}; x$Matrix <- y$Matrix_1$Matrix; x$Weights <- y$Matrix_1$Weights; x})#
  # Print current processing status:#
  cat("Done\nFurther tidying of taxonomy...")#
  # If applying an Interval:#
  if(!all(is.null(Interval))) {#
    # Find any rows to delete (because they represent taxa outside the Interval):#
    RowsToDelete <- sort(match(gsub(" ", "_", ResolvedTaxonNumbersInterval[ResolvedTaxonNumbersInterval[, "TaxonRank"] == "3", "TaxonName"]), rownames(TaxonomyMRP)))#
    # If found then remove these from the taxonomy MRP:#
    if(length(RowsToDelete) > 0) TaxonomyMRP <- TaxonomyMRP[-RowsToDelete, , drop = FALSE]#
  }#
  # Collapse taxonomy MRP by removing autapomorphic characters (if any):#
  if(length(taxonomicautapomorphies) > 0) TaxonomyMRP <- TaxonomyMRP[, -match(taxonomicautapomorphies, colnames(TaxonomyMRP)), drop = FALSE]#
  # Overwrite taxonomy MRP list with strings for each column:#
  TaxonomyMRPlist <- apply(TaxonomyMRP, 2, paste, collapse = "")#
  # Find any duplicated MRP strings:#
  duplicatedMRPstrings <- rle(sort(TaxonomyMRPlist))$values[which(rle(sort(TaxonomyMRPlist))$lengths > 1)]#
  # If there are duplicated columns (i.e., redundant MRP characters in the taxonomy):#
  if(length(duplicatedMRPstrings) > 0) {#
    # For each duplicated character:#
    for(i in duplicatedMRPstrings) {#
      # Get duplicated columns for current MRP string:#
      duplicatedcolumns <- which(TaxonomyMRPlist == i)#
      # Form new column name by collapsing higher taxa that are duplicated to a single string:#
      newcolumnname <- paste(names(duplicatedcolumns), collapse = "_et_")#
      # Overwrite first duplicated column name with new collapsed name:#
      colnames(TaxonomyMRP)[duplicatedcolumns[1]] <- newcolumnname#
      # Remove redundant columns from matrix:#
      TaxonomyMRP <- TaxonomyMRP[, -duplicatedcolumns[2:length(duplicatedcolumns)], drop = FALSE]#
      # Remove redundant columns from list:#
      TaxonomyMRPlist <- TaxonomyMRPlist[-duplicatedcolumns[2:length(duplicatedcolumns)]]#
    }#
  }#
  # Print current processing status:#
  cat("Done\nRemoving outgroups, empty supraspecific taxa and those outside the sampling interval...")#
  # Find any remaining taxa that now need to be deleted (outgroups to target clade and empty higher taxa):#
  TaxaToDelete <- setdiff(unlist(lapply(lapply(MRPList, '[[', "Matrix"), rownames)), NewValidOTUs)#
  # If applying an Interval then add taxa outside of it to the deletes list:#
  if(!all(is.null(Interval))) TaxaToDelete <- unique(c(TaxaToDelete, gsub(" ", "_", ResolvedTaxonNumbersInterval[ResolvedTaxonNumbersInterval[, "TaxonRank"] == "3", "TaxonName"])))#
  # If there are species to exclude:#
  if(length(SpeciesToExclude) > 0) {#
    # Build vector of all current OTU names:#
    OTUNames <- unique(unlist(lapply(MRPList, function(x) rownames(x$Matrix))))#
    # Find any missing names (in exclude list but not in tree):#
    MissingNames <- setdiff(SpeciesToExclude, OTUNames)#
    # If any are found stop and warn user:#
    if(length(MissingNames) > 0) stop(paste("The following SpeciesToExclude were not actually found in the data: ", paste(MissingNames, collapse = ", "), ". Check they are spelled correctly and try again.", sep = ""))#
    # Add species to exclude to taxa to delete:#
    TaxaToDelete <- unique(c(TaxaToDelete, SpeciesToExclude))#
    # Remove species to exclude from Taxonomy MRP (as lomg as they are still there):#
    if(length(intersect(SpeciesToExclude, rownames(TaxonomyMRP))) > 0) TaxonomyMRP <- TaxonomyMRP[-match(intersect(SpeciesToExclude, rownames(TaxonomyMRP)), rownames(TaxonomyMRP)), , drop = FALSE]#
    # Find any columns to delete (duplicated, autapomorphic or constant):#
    ColumnsToDalete <- unique(c(which(duplicated(apply(TaxonomyMRP, 2, paste, collapse = ""))), unname(which(apply(TaxonomyMRP, 2, sum) < 2))))#
    # If columns are to be deleted then delete them:#
    if(length(ColumnsToDalete) > 0) TaxonomyMRP <- TaxonomyMRP[, -ColumnsToDalete]#
    # Update new valid OTUs:#
    NewValidOTUs <- sort(rownames(TaxonomyMRP))#
#
  }#
  # Delete taxa from every matrix they occur in:#
  MRPList[ActiveMRP(MRPList)] <- lapply(MRPList[ActiveMRP(MRPList)], function(x) {DeleteRows <- match(intersect(TaxaToDelete, rownames(x$Matrix)), rownames(x$Matrix)); if(length(DeleteRows) > 0) x$Matrix <- x$Matrix[-DeleteRows, , drop = FALSE]; x})#
  # Prune redundant characters from matrices following taxon deletion(s):#
  MRPList[ActiveMRP(MRPList)] <- lapply(MRPList[ActiveMRP(MRPList)], function(x) {y <- PisaniMRPPrune(Claddis::MakeMorphMatrix(x$Matrix, Weights = x$Weights, ignore.duplicate.taxa = TRUE)); x$Matrix <- y$Matrix_1$Matrix; x$Weights <- y$Matrix_1$Weights; x})#
  # Print current processing status:#
  cat("Done\nProducing taxonomy tree...")#
  # Duplicated Taxonomy MRP to create a collapsable version for generating taxonomy Newick string:#
  TaxonomyMRPNewick <- TaxonomyMRP#
  # Get order of columns to collapse to form MRP#
  columncollapseorder <- order(apply(TaxonomyMRPNewick, 2, sum))#
  # For each column ("clade") in order from smallest to largest:#
  for(i in columncollapseorder) {#
    # Get taxa present in current clade:#
    taxonrows <- which(TaxonomyMRPNewick[, i] == 1)#
    # Create new partial Newick string for current clade (node):#
    newNewickstring <- paste("(", paste(names(taxonrows), collapse = ","), ")", colnames(TaxonomyMRPNewick)[i], sep = "")#
    # Replace row name with new Newick string:#
    rownames(TaxonomyMRPNewick)[taxonrows[1]] <- newNewickstring#
    # Remove now redundant taxa from Newick matrix:#
    TaxonomyMRPNewick <- TaxonomyMRPNewick[-taxonrows[2:length(taxonrows)], , drop = FALSE]#
  }#
  # Complete Newick string and over write Taxonomy Newick matrix:#
  TaxonomyMRPNewick <- paste("(", paste(rownames(TaxonomyMRPNewick), collapse = ","), ")", TargetClade, ";", sep = "")#
  # Ladderize taxonomy tree for neatness!:#
  TaxonomyMRPTree <- ladderize(read.tree(text = TaxonomyMRPNewick))#
#####
  # If there are higher taxa to collapse:#
  if(length(HigherTaxaToCollapse) > 0) {#
    # Print current processing status:#
    cat("Done\nCollapsing higher taxa...")#
    # Find any higher taxa actually present in target clade:#
    HigherTaxaInTargetClade <- colnames(TaxonomyMRP)#
    # Find any missing names (in collapse list but not in taxonomy):#
    MissingHigherTaxa <- setdiff(HigherTaxaToCollapse, HigherTaxaInTargetClade)#
    # If any are found stop and warn user:#
    if(length(MissingHigherTaxa) > 0) stop(paste("The following HigherTaxaToCollapse were not actually found in the data: ", paste(MissingHigherTaxa, collapse = ", "), ". Check they are spelled correctly and are valid (according to the Paleobiology Database) and try again.", sep = ""))#
    # Check the clades are all unique (not internested) and if not then stop and warn user:#
    if(any(duplicated(unlist(lapply(as.list(HigherTaxaToCollapse), function(x) rownames(TaxonomyMRP[TaxonomyMRP[, colnames(TaxonomyMRP) == x] == 1, ])))))) stop("HigherTaxaToCollapse contains clades that are internested. Remove the internested clades and try again.")#
    # Build taxa to rename matrix:#
    TaxaToRenameMatrix <- do.call(rbind, lapply(as.list(HigherTaxaToCollapse), function(x) unname(cbind(x, rownames(TaxonomyMRP[TaxonomyMRP[, colnames(TaxonomyMRP) == x] == 1, ])))))#
    # Build list of each clade's species compliment:#
    CladeContentsList <- lapply(as.list(TaxonomyMRPTree$node.label), function(x) {NodeNumber <- which(TaxonomyMRPTree$node.label == x) + Ntip(TaxonomyMRPTree); TaxonomyMRPTree$tip.label[FindDescendants(n = NodeNumber, tree = TaxonomyMRPTree)]})#
    # Add names of clades:#
    names(CladeContentsList) <- TaxonomyMRPTree$node.label#
    # Find any subsumed clades (to be removed from taxonomy MRP):#
    SubsumedClades <- unlist(lapply(as.list(HigherTaxaToCollapse), function(x) {CurrentClade <- which(names(CladeContentsList) == x); TempCladeContents <- CladeContentsList[-CurrentClade]; names(which(unlist(lapply(TempCladeContents, function(x) length(setdiff(x, CladeContentsList[[CurrentClade]])))) == 0))}))#
    # Build block to add to taxonomy MRP out of first taxon inside each clade to collapse:#
    BlockToAddToTaxonomyMRP <- do.call(rbind, lapply(as.list(HigherTaxaToCollapse), function(x) TaxonomyMRP[TaxaToRenameMatrix[which(TaxaToRenameMatrix[, 1] == x)[1], 2], ]))#
    # Add uppercase rownames to new block:#
    rownames(BlockToAddToTaxonomyMRP) <- toupper(HigherTaxaToCollapse)#
    # Add to taxonomy MRP:#
    TaxonomyMRP <- rbind(TaxonomyMRP, BlockToAddToTaxonomyMRP)#
    # Collapse taxonomy MRP down by removing clades and the species from the collapsed clades:#
    TaxonomyMRP <- TaxonomyMRP[-unlist(lapply(as.list(TaxaToRenameMatrix[, 2]), function(x) which(rownames(TaxonomyMRP) == x))), -unlist(lapply(as.list(c(HigherTaxaToCollapse, SubsumedClades)), function(x) which(colnames(TaxonomyMRP) == x))), drop = FALSE]#
    # Remove all but one collapsed taxa from each clade from the tree:#
    TaxonomyMRPTree <- drop.tip(TaxonomyMRPTree, TaxaToRenameMatrix[-unlist(lapply(as.list(HigherTaxaToCollapse), function(x) which(TaxaToRenameMatrix[, 1] == x)[1])), 2])#
    # Ladderize taxonomy tree for neatness!:#
    TaxonomyMRPTree <- ladderize(TaxonomyMRPTree)#
    # Build tips to replace matrix:#
    TipsToReplaceMatrix <- do.call(rbind, lapply(as.list(HigherTaxaToCollapse), function(x) TaxaToRenameMatrix[which(TaxaToRenameMatrix[, 1] == x)[1], ]))#
    # Replace tip names in tree:#
    TaxonomyMRPTree$tip.label[unlist(lapply(apply(TipsToReplaceMatrix, 1, as.list), function(x) {x <- unlist(x); which(TaxonomyMRPTree$tip.label == x[2])}))] <- toupper(TipsToReplaceMatrix[, 1])#
    # Replace names in MRP matrices:#
    MRPList[ActiveMRP(MRPList)] <- lapply(MRPList[ActiveMRP(MRPList)], function(x) {CurrentRownames <- rownames(x$Matrix); NamesToReplace <- intersect(CurrentRownames, TaxaToRenameMatrix[, 2]); if(length(NamesToReplace) > 0) rownames(x$Matrix)[match(NamesToReplace, rownames(x$Matrix))] <- toupper(TaxaToRenameMatrix[match(NamesToReplace, TaxaToRenameMatrix[, 2]), 1]); x})#
    # Collapse any duplicate taxa created by this substitution (very likely!):#
    MRPList[ActiveMRP(MRPList)] <- lapply(MRPList[ActiveMRP(MRPList)], function(x) {y <- Claddis::MakeMorphMatrix(x$Matrix, Weights = x$Weights, ignore.duplicate.taxa = TRUE); if(any(duplicated(rownames(y$Matrix_1$Matrix)))) {DuplicateNames <- rownames(y$Matrix_1$Matrix)[duplicated(rownames(y$Matrix_1$Matrix))]; y <- CollapseDuplicateTaxonMRP(y)}; x$Matrix <- y$Matrix_1$Matrix; x$Weights <- y$Matrix_1$Weights; x})#
    # Prune constant characters and collapse duplicated characters:#
    MRPList[ActiveMRP(MRPList)] <- lapply(MRPList[ActiveMRP(MRPList)], function(x) {y <- PisaniMRPPrune(Claddis::MakeMorphMatrix(x$Matrix, Weights = x$Weights, ignore.duplicate.taxa = TRUE)); x$Matrix <- y$Matrix_1$Matrix; x$Weights <- y$Matrix_1$Weights; x})#
    # Update new valid OTUs:#
    NewValidOTUs <- sort(rownames(TaxonomyMRP))#
  }#
  # If specimen-level OTUs are included:#
  if(IncludeSpecimenLevelOTUs) {#
    # Print current processing status:#
    cat("Done\nAdding NAs for indet. and sp. subclades to taxonomy MRP...")#
    # Find indeterminates and sps:#
    indetsandsps <- NewValidOTUs[which((unlist(lapply(lapply(strsplit(NewValidOTUs, "_"), '==', "indet"), sum)) + unlist(lapply(lapply(strsplit(NewValidOTUs, "_"), '==', "sp"), sum))) > 0)]#
    # If there are indeterminates and/or sps:#
    if(length(indetsandsps) > 0) {#
      # For each such taxon:#
      for(i in indetsandsps) {#
        # Find higher taxon to which it belongs:#
        highertaxon <- colnames(TaxonomyMRP)[which(unlist(lapply(lapply(strsplit(colnames(TaxonomyMRP), "_et_"), '==', strsplit(i, "_")[[1]][1]), sum)) == 1)]#
        # Find any sub (suprapseicifc taxa) for that higher taxon:#
        subtaxa <- colnames(TaxonomyMRP)[which(unlist(lapply(lapply(lapply(split(TaxonomyMRP[names(which(TaxonomyMRP[, highertaxon] == 1)), , drop = FALSE], rep(1:ncol(TaxonomyMRP[names(which(TaxonomyMRP[, highertaxon] == 1)), , drop = FALSE]), each = nrow(TaxonomyMRP[names(which(TaxonomyMRP[, highertaxon] == 1)), , drop = FALSE]))), sort), unique), length)) == 2)]#
        # If these exist then set ith taxon as being NA with respect to belonging to the subtax(a):#
        if(length(subtaxa) > 1) TaxonomyMRP[i, subtaxa] <- NA#
      }#
    }#
  }#
  # For empty data sets make sure matrix is zero-by-zero and weights have no lengths:#
  MRPList <- lapply(MRPList, function(x) {MatrixSize <- nrow(x$Matrix) * ncol(x$Matrix); if(MatrixSize == 0) {x$Matrix <- matrix(nrow = 0, ncol = 0); x$Weights <- vector(mode = "numeric")}; x})#
  # Print current processing status:#
  cat("Done\nGetting weighting data (publication year and dependencies)...")#
  # Set current year (used multiple times later):#
  CurrentYear <- strsplit(as.character(Sys.Date()), "-")[[1]][1]#
  # Add publication year to each data set (in presses are ascribed the current year):#
  MRPList <- lapply(MRPList, function(x) {x$PublicationYear <- gsub("[:A-Z:a-z:]|_|-", "", gsub("inpress", CurrentYear, x$FileName)); x})#
  # Find any missing parents:#
  MissingParents <- setdiff(unique(unname(unlist(lapply(MRPList, function(x) x$Parent[nchar(x$Parent) > 0])))), names(MRPList))#
  # Find all parent data set names:#
  ParentDataSets <- sort(unique(unname(unlist(lapply(MRPList, function(x) x$Parent[nchar(x$Parent) > 0])))))#
  # Get child data sets for each parent:#
  ChildDataSets <- lapply(as.list(ParentDataSets), function(x) unname(unlist(mapply(function(x, y) y$FileName[y$Parent == x], x = x, y = MRPList))))#
  # Add names to child data sets:#
  names(ChildDataSets) <- ParentDataSets#
  # Now include any grandchildren, greatgrandchildren etc.:#
  ChildDataSets <- lapply(ChildDataSets, function(x) sort(unique(c(x, unname(unlist(ChildDataSets[intersect(x, names(ChildDataSets))]))))))#
  # Add sibling relationships to data sets with shared parents and update parents field with grandparents, greatgrandparents etc.:#
  MRPList <- lapply(MRPList, function(x) {SiblingVector <- c(x$Sibling, setdiff(ChildDataSets[[match(x$Parent, ParentDataSets)]], x$FileName)); if(any(nchar(SiblingVector)) > 0) SiblingVector <- SiblingVector[nchar(SiblingVector) > 0]; x$Sibling <- unique(SiblingVector); if(!is.null(MRPList[[x$Parent[1]]]$Parent)) while(nchar(MRPList[[x$Parent[1]]]$Parent) > 0) x$Parent <- c(MRPList[[x$Parent[1]]]$Parent, x$Parent); x})#
  # OLD LINE FOR ABOVE THAT I AM PRETTY SURE IS BROKEN BUT AM LEAVING HERE FOR NOW IN CASE IT AIN'T#
  # Add sibling relationships to data sets with shared parents and update parents field with grandparents, greatgrandparents etc.:#
  #MRPList <- lapply(MRPList, function(x) {SiblingVector <- c(x$Sibling, setdiff(ChildDataSets[[match(x$Parent, ParentDataSets)]], x$FileName)); if(any(nchar(SiblingVector)) > 0) SiblingVector <- SiblingVector[nchar(SiblingVector) > 0]; x$Sibling <- unique(SiblingVector); x$Parent <- names(which(unlist(lapply(ChildDataSets, function(y) length(intersect(y, x$FileName)))) > 0)); x})#
  # Build an empty redundant parent list for later use if no parents exist:#
  RedundantParents <- vector(mode = "character")#
  # If parents exist build a vector of those that are redundant (at least one child data set contains their full taxonomic complement):#
  if(length(unlist(lapply(MRPList[ActiveMRP(MRPList)], function(x) x$Parent[nchar(x$Parent) > 0]))) > 0) RedundantParents <- unlist(lapply(as.list(unique(unlist(lapply(MRPList[ActiveMRP(MRPList)], function(x) x$Parent[nchar(x$Parent) > 0])))), function(x) {Children <- unname(unlist(lapply(MRPList[ActiveMRP(MRPList)], function(y) if(any(y$Parent == x)) y$FileName))); if(any(unlist(lapply(as.list(Children), function(y) length(setdiff(rownames(MRPList[[x]]$Matrix), rownames(MRPList[[y]]$Matrix))))) == 0)) x}))#
  # If redundant parents were found then collapse these data sets back to empty matrix and weights::#
  if(length(RedundantParents) > 0) MRPList[RedundantParents] <- lapply(MRPList[RedundantParents], function(x) {x$Matrix <- matrix(ncol = 0, nrow = 0); x$Weights <- vector(mode = "numeric"); x})#
  # Find any remaining active parent data sets:#
  ActiveParents <- names(which(unlist(lapply(MRPList[setdiff(ParentDataSets, MissingParents)], function(x) nrow(x$Matrix) * ncol(x$Matrix))) > 0))#
  # If active parents remain:#
  if(length(ActiveParents) > 0) {#
    # Add children of active parent to siblings:#
    MRPList[ActiveParents] <- lapply(MRPList[ActiveParents], function(x) {SiblingVector <- unique(c(ChildDataSets[[x$FileName]], x$Sibling)); x$Sibling <- unique(SiblingVector[nchar(SiblingVector) > 0]); x})#
    # Add parent as sibling of offspring:#
    MRPList <- lapply(MRPList, function(x) {SiblingVector <- c(x$Sibling, intersect(x$Parent, ActiveParents)); if(any(nchar(SiblingVector) > 0)) SiblingVector <- SiblingVector[nchar(SiblingVector) > 0]; x$Sibling <- sort(unique(SiblingVector)); x})#
  }#
  # Find any empty data sets to remove:#
  RemovedSourceData <- sort(names(which(unlist(lapply(MRPList, function(x) nrow(x$Matrix) * ncol(x$Matrix))) == 0)))#
  # Remove data sets from MRPList:#
  MRPList[RemovedSourceData] <- NULL#
  # Remove any dead siblings:#
  MRPList <- lapply(MRPList, function(x) {x$Sibling <- intersect(x$Sibling, names(MRPList)); x})#
  # If usinga  veil line:#
  if(VeilLine) {#
    # Print current processing status:#
    cat("Done\nApplying veil line...")#
    # Start with current year as veil year:#
    CurrentVeilYear <- as.numeric(CurrentYear)#
    # Set current taxa included as being from current veil year (to present):#
    CurrentTaxaIncluded <- unique(unlist(lapply(MRPList[as.numeric(unlist(lapply(MRPList, function(x) x$PublicationYear))) >= CurrentVeilYear], function(x) rownames(x$Matrix))))#
    # Make a stop point (where all taxa are sampled):#
    StopPoint <- length(unique(unlist(lapply(MRPList, function(x) rownames(x$Matrix)))))#
    # While not all taxa are included in current sample:#
    while(length(CurrentTaxaIncluded) < StopPoint) {#
      # Increment one year back in time:#
      CurrentVeilYear <- CurrentVeilYear - 1#
#
      # Update current taxa included:#
      CurrentTaxaIncluded <- unique(unlist(lapply(MRPList[as.numeric(unlist(lapply(MRPList, function(x) x$PublicationYear))) >= CurrentVeilYear], function(x) rownames(x$Matrix))))#
    }#
    # Find any data sets to remove (older than veil year):#
    DataSetsToRemove <- which(as.numeric(unlist(lapply(MRPList, function(x) x$PublicationYear))) < CurrentVeilYear)#
    # If data sets to remove:#
    if(length(DataSetsToRemove) > 0) {#
      # Add to removed source data vector:#
      RemovedSourceData <- sort(c(RemovedSourceData, names(MRPList)[DataSetsToRemove]))#
      # Remove from MRP list:#
      MRPList <- MRPList[-DataSetsToRemove]#
      # Remove any new dead siblings:#
      MRPList <- lapply(MRPList, function(x) {x$Sibling <- intersect(x$Sibling, names(MRPList)); x})#
    }#
#
  # If not using veil line:#
  } else {#
    # Set current veil year as oldest data set:#
    CurrentVeilYear <- min(as.numeric(unlist(lapply(MRPList, function(x) x$PublicationYear))))#
  }#
  # Print current processing status:#
  cat("Done\nCalculating weights...")#
  # Update current year to youngest data set (in case this is not the actual current year) as will screw uo weights otherwise:#
  CurrentYear <- as.character(max(as.numeric(unlist(lapply(MRPList, function(x) x$PublicationYear)))))#
  # Reformat weights to be input weights, publication year weights (equation 1 in Supplementary Information of Lloyd et al. 2016),#
  # data set dependence weights (1 / (N siblings + 1)), and clade contradiction weights (1 / frequency of contradictory clades).#
  # All weights are set on a zero to one scale initially and then multiplied by RelativeWeights:#
  MRPList <- lapply(MRPList, function(x) {InputWeights <- x$Weights; x$Weights <- NULL; x$InputWeights <- RelativeWeights[1] * InputWeights; x$PublicationYearWeights <- RelativeWeights[2] * (rep(((2 ^ (0.5 * (as.numeric(x$PublicationYear) - CurrentVeilYear + 1))) - 1) / ((2 ^ (0.5 * (as.numeric(CurrentYear) - CurrentVeilYear + 1))) - 1), length(InputWeights))); x$DataSetDependenceWeights <- RelativeWeights[3] * rep(1 / (length(x$Sibling) + 1), length(InputWeights)); x$CladeContradictionWeights <- RelativeWeights[4] * MRPIntraMatrixWeights(x$Matrix); x})#
  # If using sum to combine weights collapse weights to just their sum:#
  if(WeightCombination == "sum") MRPList <- lapply(MRPList, function(x) {x$Weights <- apply(rbind(x$InputWeights, x$PublicationYearWeights, x$DataSetDependenceWeights, x$CladeContradictionWeights), 2, sum); x$InputWeights <- NULL; x$PublicationYearWeights <- NULL; x$DataSetDependenceWeights <- NULL; x$CladeContradictionWeights <- NULL; x})#
  # If using product to combine weights collapse weights to just their product (excluding zeroes) and remove other weights from list:#
  if(WeightCombination == "product") MRPList <- lapply(MRPList, function(x) {x$Weights <- apply(rbind(x$InputWeights, x$PublicationYearWeights, x$DataSetDependenceWeights, x$CladeContradictionWeights), 2, function(y) {z <- as.character(y); z[z == "0"] <- NA; prod(as.numeric(z), na.rm = TRUE)}); x$InputWeights <- NULL; x$PublicationYearWeights <- NULL; x$DataSetDependenceWeights <- NULL; x$CladeContradictionWeights <- NULL; x})#
  # Get current maximum weight:#
  MaximumWeight <- max(unlist(lapply(MRPList, function(x) x$Weights)))#
  # Get current minimum weight:#
  MinimumWeight <- min(unlist(lapply(MRPList, function(x) x$Weights)))#
  # Calculate the multiplication factor for weight rescaling (10 to 1000), but use minimum weight if there is no variance:#
  MultiplicationFactor <- ifelse(1 / ((MaximumWeight - MinimumWeight) / 990) == Inf, MinimumWeight, 1 / ((MaximumWeight - MinimumWeight) / 990))#
  # Calculate the addition factor for weight rescaling (10 to 1000):#
  AdditionFactor <- 10 - (MinimumWeight * MultiplicationFactor)#
  # Rescale weights (10 to 1000) and round results to two decimal places (best TNT can cope with):#
  MRPList <- lapply(MRPList, function(x) {x$Weights <- round((x$Weights * MultiplicationFactor) + AdditionFactor, 2); x})#
  # Print current processing status:#
  cat("Done\nChecking for phylogeny-taxonomy contradictions...")#
  # Do first pass to find any contradictions between taxonomy MRP and the fully reconciled source matrix:#
  MRPList <- lapply(MRPList, function(x) {TaxonomyMRPStrings <- TaxonomyMRP[rownames(x$Matrix), ]; TaxonomyMRPStrings[is.na(TaxonomyMRPStrings)] <- "0"; TaxonomyMRPStrings <- TaxonomyMRPStrings[, apply(TaxonomyMRPStrings, 2, function(y) length(unique(y))) == 2, drop = FALSE]; x$TaxonomyContradictions <- names(which(unlist(lapply(apply(TaxonomyMRPStrings, 2, list), function(z) length(MRPCharacterContradiction(unlist(z), x$Matrix))) > 0))); x$TaxonomyContradictionProportion <- length(x$TaxonomyContradictions) / ncol(TaxonomyMRPStrings); x})#
  # Store monophyletic taxa (those not contradicted by any phylogenetic characters - useful for chunking larger data if found):#
  MonophyleticTaxa <- setdiff(colnames(TaxonomyMRP), unique(unlist(lapply(MRPList, function(x) x$TaxonomyContradictions))))#
  # If reporting contradiction issues to the screen:#
  if(ReportContradictionsToScreen) {#
    # Find any data sets with taxonomy-phylogeny contradictions:#
    ContradictionIssueDataSets <- names(unlist(lapply(MRPList, function(x) length(x$TaxonomyContradictions))) > 0)#
    # If there are data sets with contradictions:#
    if(length(ContradictionIssueDataSets) > 0) {#
      # Build vector of contradiction warnings:#
      ContradictionWarnings <- unname(unlist(lapply(MRPList[ContradictionIssueDataSets], function(x) {TaxonomyMRPSubset <- TaxonomyMRP[rownames(x$Matrix), x$TaxonomyContradictions, drop = FALSE]; if(any(is.na(TaxonomyMRPSubset))) TaxonomyMRPSubset[is.na(TaxonomyMRPSubset)] <- "0"; ListContradictions(TaxonomyMRP = TaxonomyMRPSubset, MRPMatrix = x$Matrix, ContradictionTaxa = x$TaxonomyContradictions, DataSetName = x$FileName)})))#
      # Print warnings to screen:#
      cat(ContradictionWarnings)#
      # NEED TO BREAK THIS DOWN FURTHER AS CLEARLY SOME REDUNDANCY! (E.G. GROUPING HIGHER TAXA WITH SAME ISSUE, OR DATA SETS WITH SAME ISSUE)#
    }#
  }#
  # If using a constraint:#
  if(ConstraintInUse) {#
    # Print current processing status:#
    cat("Done\nApplying constraint tree...")#
    # If a monophyly constraint add all other taxa outside the constraint (makes NAs zeroes):#
    if(ConstraintType == "monophyly") MRPList[[grep(ConstraintDataSet, names(MRPList))]]$Matrix <- rbind(MRPList[[grep(ConstraintDataSet, names(MRPList))]]$Matrix, matrix("0", ncol = ncol(MRPList[[grep("Constraint", names(MRPList))]]$Matrix), nrow = length(setdiff(NewValidOTUs, rownames(MRPList[[grep(ConstraintDataSet, names(MRPList))]]$Matrix))), dimnames = list(setdiff(NewValidOTUs, rownames(MRPList[[grep(ConstraintDataSet, names(MRPList))]]$Matrix)), c())))#
    # Build vector of atxa in constraint:#
    TaxaInConstraint <- rownames(MRPList[[grep(ConstraintDataSet, names(MRPList))]]$Matrix)#
    # Get combined weight of all non-constraint that contradicts constraint (need to know to correctly weight the constraint data):#
    NonConstraintWeightsTotal <- sum(unlist(lapply(MRPList[-grep(ConstraintDataSet, names(MRPList))], function(x) {TaxaInBoth <- intersect(rownames(x$Matrix), TaxaInConstraint); if(length(TaxaInBoth) > 2) {ConstraintMRPStrings <- x$Matrix[TaxaInBoth, ]; ConstraintMatrix <- MRPList[[grep(ConstraintDataSet, names(MRPList))]]$Matrix[TaxaInBoth, ]; ConstraintMatrix[is.na(ConstraintMatrix)] <- "0"; ConstraintMatrix <- ConstraintMatrix[, apply(ConstraintMatrix, 2, function(y) length(unique(y))) == 2, drop = FALSE]; if(length(unique(as.vector(ConstraintMRPStrings))) > 1) {x$ConstraintContradictions <- x$Weights[unique(unlist(lapply(apply(ConstraintMatrix, 2, list), function(z) {MRPCharacterContradiction(unlist(z), ConstraintMRPStrings)})))]} else {x$ConstraintContradictions <- integer(0)}} else {x$ConstraintContradictions <- integer(0)}; x$ConstraintContradictions})))#
    # If NonConstraintWeightsTotal is less than 10000 then set it at 10000 to ensure it is upweighted:#
    if(NonConstraintWeightsTotal < 10000) NonConstraintWeightsTotal <- 10000#
    # Update weights of constraint tree to maximum (allowing for weights to fall in the 999-1000 range if they represent conflicting clades):#
    MRPList[[ConstraintDataSet]]$Weights <- round(MRPIntraMatrixWeights(MRPList[[ConstraintDataSet]]$Matrix) + 999, 2)#
    # Get order of magnitude of current character count of constraint tree (need to check this won't be too big):#
    OrderOfMagnitudeOfCurrentCharacterCountOfConstraint <- nchar(as.character(ceiling(NonConstraintWeightsTotal / 1000) * ncol(MRPList[[ConstraintDataSet]]$Matrix)))#
    # If this order exceeds 10^6 (too big for memory):#
    if(OrderOfMagnitudeOfCurrentCharacterCountOfConstraint > 6) {#
      # Get order of magnitude to reduce weights by:#
      OrderOfMagnitudeToReduceWeightsBy <- (OrderOfMagnitudeOfCurrentCharacterCountOfConstraint - 6) * 10#
      # Calculate the multiplication factor for weight rescaling (10 to 1000):#
      MultiplicationFactor <- 1 / (990 / ((1000 / OrderOfMagnitudeToReduceWeightsBy) - 10))#
      # Calculate the addition factor for weight rescaling (10 to 1000):#
      AdditionFactor <- 10 - (10 * MultiplicationFactor)#
      # Rescale weights (10 to 1000) and round results to two decimal places (best TNT can cope with):#
      MRPList[-grep(ConstraintDataSet, names(MRPList))] <- lapply(MRPList[-grep(ConstraintDataSet, names(MRPList))], function(x) {x$Weights <- round((x$Weights * MultiplicationFactor) + AdditionFactor, 2); x})#
      # Update NonConstraintWeightsTotal:#
      NonConstraintWeightsTotal <- sum(unname(unlist(lapply(MRPList[-grep(ConstraintDataSet, names(MRPList))], function(x) x$Weights))))#
    }#
    # Embiggen MRP matrix so that weights are high enough to ensure constraint gets implemented:#
    MRPList[[ConstraintDataSet]]$Matrix <- metatree::EmbiggenMatrix(Claddis::MakeMorphMatrix(MRPList[[ConstraintDataSet]]$Matrix, Weights = MRPList[[ConstraintDataSet]]$Weights), N = ceiling(NonConstraintWeightsTotal / 1000))$Matrix_1$Matrix#
    # Update weights by replicating N times as with matrix embiggining:#
    MRPList[[ConstraintDataSet]]$Weights <- rep(MRPList[[ConstraintDataSet]]$Weights, ceiling(NonConstraintWeightsTotal / 1000))#
  }#
#
  # Print current processing status:#
  cat("Done\nBuilding MRP matrix...")#
  # Add in missing taxa as NAs to every taxon:#
  MRPList <- lapply(MRPList, function(x) {MissingTaxa <- setdiff(rownames(TaxonomyMRP), rownames(x$Matrix)); if(length(MissingTaxa) > 0) x$Matrix <- rbind(x$Matrix, matrix(nrow = length(MissingTaxa), ncol = ncol(x$Matrix), dimnames = list(MissingTaxa, c()))); x$Matrix <- x$Matrix[rownames(TaxonomyMRP), , drop = FALSE]; x})#
  # Build full MRP matrix (with taxonomy MRP):#
  if(!ExcludeTaxonomyMRP) FullMRPMatrix <- MakeMorphMatrix(CharacterTaxonMatrix = cbind(do.call(cbind, lapply(MRPList, function(x) x$Matrix)), TaxonomyMRP), Weights = c(unname(unlist(lapply(MRPList, function(x) x$Weights))), rep(1, ncol(TaxonomyMRP))))#
  # Build full MRP matrix (without taxonomy MRP):#
  if(ExcludeTaxonomyMRP) FullMRPMatrix <- MakeMorphMatrix(CharacterTaxonMatrix = do.call(cbind, lapply(MRPList, function(x) x$Matrix)), Weights = unname(unlist(lapply(MRPList, function(x) x$Weights))))#
  # Add all zero outgroup to matrix:#
  FullMRPMatrix$Matrix_1$Matrix <- rbind(matrix("0", nrow = 1, ncol = ncol(FullMRPMatrix$Matrix_1$Matrix), dimnames = list("allzero", c())), FullMRPMatrix$Matrix_1$Matrix)#
#
  # Print current processing status:#
  cat("Done\nPerforming Safe Taxonomic Reduction...")#
  # Perform STR on full matrix:#
  STRData <- SafeTaxonomicReduction(FullMRPMatrix)#
  # Create additional STR matrix from full matrix:#
  STRMRPMatrix <- STRData$reduced.matrix#
  # Print current processing status:#
  cat("Done\nCompiling and returning output...")#
  # Compile output:#
  Output <- list(FullMRPMatrix = FullMRPMatrix, STRMRPMatrix = STRMRPMatrix, TaxonomyTree = TaxonomyMRPTree, MonophyleticTaxa = MonophyleticTaxa, SafelyRemovedTaxa = STRData$str.list, RemovedSourceData = RemovedSourceData, VeilYear = CurrentVeilYear)
MRPDirectory = "~/Dropbox/Mammal_Supertree/ProjectPlanetOfTheApes/InputData/MRP"#
  XMLDirectory = "~/Dropbox/Mammal_Supertree/ProjectPlanetOfTheApes/InputData/XML"#
  InclusiveDataList = c()#
  ExclusiveDataList = c("Andrews_1988a", "Beard_et_MacPhee_1994a", "Begun_et_Kordos_1997a", "Burger_2010aa", "Gebo_etal_2001a", "Kimbel_etal_2004a", "Pattinson_etal_2015a", "Maiolino_etal_2012a", "Seiffert_etal_2015a", "Rose_1997a", "Marivaux_etal_2001a", "Boyer_etal_2017ab", "Boyer_etal_2017ac"),#
  TargetClade = "Primates"#
  HigherTaxaToCollapse = c()#
  MissingSpecies = "exclude"#
  Interval = NULL#
  VeilLine = TRUE,#
  IncludeSpecimenLevelOTUs = TRUE#
  RelativeWeights = c(0, 100, 10, 1),#
  WeightCombination = "sum"#
  ReportContradictionsToScreen = FALSE,#
  BackboneConstraint = "Springer_etal_2012a"#
  MonophylyConstraint = NULL#
  ExcludeTaxonomyMRP = FALSE#
  # Subfunction that gives just MRPs where matrix is still intact (has rows and columns):#
  ActiveMRP <- function(MRPList) unname(which(unlist(lapply(MRPList, function(x) prod(dim(x$Matrix)))) > 0))#
  # Subfunction to make multi-taxon reconciliations unique OTUs:#
  SeparateMultiTaxonReconciliations <- function(ListBlock) {#
    # Find comma rows (multiple taxa in initial reconciliation):#
    commarows <- grep(",", rownames(ListBlock$Matrix))#
    # If there is at least one multiple-taxon reconciliation:#
    if(length(commarows) > 0) {#
      # For each multiple-taxon reconciliation in reverse order (to avoid later rows not matching):#
      for(j in rev(commarows)) {#
        # Get multiple names of reconciliation:#
        multiplenames <- strsplit(rownames(ListBlock$Matrix)[j], "%%%%")[[1]]#
        # Get multiple-taxon numbers:#
        multitaxonnumbers <- strsplit(multiplenames[1], ";")[[1]]#
        # Get multiple-taxon names:#
        multitaxonnames <- strsplit(multiplenames[2], ",")[[1]]#
        # Check data integrity with respect to multiple-taxon values:#
        if(length(multitaxonnumbers) != length(multitaxonnames)) stop(paste("Problem with multiple-taxon reconciliation(s) in ", ListBlock$FileName, " (check commas and semi-colons are correct; i.e., of same length).", sep = ""))#
        # Add new rows at base of matrix:#
        ListBlock$Matrix <- rbind(ListBlock$Matrix, matrix(rep(ListBlock$Matrix[j, ], length(multitaxonnumbers)), nrow = length(multitaxonnumbers), byrow = TRUE, dimnames = list(paste(multitaxonnumbers, multitaxonnames, sep = "%%%%"), c())))#
        # Remove now redundant row from matrix:#
        ListBlock$Matrix <- ListBlock$Matrix[-j, , drop = FALSE]#
      }#
    }#
    # Return updated list block:#
    return(ListBlock)#
  }#
  # Subfunction to find contradicting MRP characters between a string (single character) and a matrix (multiple characters):#
  MRPCharacterContradiction <- function(MRPCharacterString, MRPCharacterMatrix) {#
    # Check MRP string has names and stop and warn user if not:#
    if(is.null(names(MRPCharacterString))) stop("MRPCharacterString must have names. Add and try again.")#
    # Check MRP matrix has names and stop and warn user if not:#
    if(is.null(rownames(MRPCharacterMatrix))) stop("MRPCharacterMatrix must have row names. Add and try again.")#
    # Check MRP string and matrix match in size and stop and warn user if not:#
    if(length(MRPCharacterString) != nrow(MRPCharacterMatrix)) stop("MRPCharacterString must have the same length as the number of rows of MRPCharacterMatrix. Check data and try again.")#
    # Check names of MRP string and matrix match and stop and warn user if not:#
    if(!all(sort(names(MRPCharacterString)) == sort(rownames(MRPCharacterMatrix)))) stop("MRPCharacterString names must match row names of MRPCharacterMatrix. Check names and try again.")#
    # Check only zeroes and ones are coded and stop and warn user if not:#
    if(length(setdiff(unique(c(MRPCharacterString, MRPCharacterMatrix)), c("0", "1"))) > 0) stop("Both MRPCharacterString and MRPCharacterMatrix must consist exclusively of the characters \"0\" and \"1\". Check data and try again.")#
    # Check MRP string contains both zeroe and ones and stop and warn user if not:#
    if(length(unique(MRPCharacterString)) < 2) stop("MRPCharacterString must contain both zeroes and ones.")#
    # Check every MRP matrix column contains both zeroe and ones and stop and warn user if not:#
    if(length(unique(as.vector(MRPCharacterMatrix))) < 2) stop("MRPCharacterMatrix must contain both zeroes and ones.")#
    # Find names corresponding to scores of "0" in the MRP string:#
    StringZeroNames <- names(which(MRPCharacterString == "0"))#
    # Find names corresponding to scores of "1" in the MRP string:#
    StringOneNames <- names(which(MRPCharacterString == "1"))#
    # Find any matrix columns that contradict the string character (both "0" and "1" coded for zero and one matches in MRP string):#
    ContradictionColumns <- which(apply(MRPCharacterMatrix, 2, function(x) length(unique(x[StringZeroNames])) == 2 && length(unique(x[StringOneNames])) == 2))#
    # Return contradicting columns:#
    return(ContradictionColumns)#
  }#
  # Subfunction to produce intra matrix weights:#
  MRPIntraMatrixWeights <- function(MRPMatrix) {#
    # Get a list of characters that contradict with each character in turn:#
    ContradictionList <- lapply(apply(MRPMatrix, 2, as.list), function(x) MRPCharacterContradiction(unlist(x), MRPMatrix))#
    # Add every character to its' own list:#
    ContradictionList <- mapply(function(x, y) c(x, y), x = as.list(1:ncol(MRPMatrix)), y = ContradictionList)#
    # Build vector of intra matrix weights:#
    IntraMatrixWeights <- 1 / unlist(lapply(ContradictionList, function(x) length(unique(unlist(ContradictionList[x])))))#
    # Return intra matrix weights:#
    return(IntraMatrixWeights)#
  }#
  # Subfunction to collapse vector of string to single formatted string:#
  WriteListAsString <- function(ListOfItems, OxfordComma = TRUE) {#
    # If not using Oxford comma set final bridge as not having one:#
    if(!OxfordComma) FinalBridge <- " and "#
    # If using Oxford comma set final bridge as having one:#
    if(OxfordComma) FinalBridge <- ", and "#
    # If list is a single item make that the output:#
    if(length(ListOfItems) == 1) Output <- ListOfItems#
    # If list is two items join with a simple and:#
    if(length(ListOfItems) == 2) Output <- paste(ListOfItems, collapse = " and ")#
    # If three or more items format as list with Oxford Comma option included:#
    if(length(ListOfItems) > 2) Output <- paste(paste(ListOfItems[1:(length(ListOfItems) - 2)], collapse = ", "), paste(ListOfItems[(length(ListOfItems) - 1):length(ListOfItems)], collapse = FinalBridge), sep = ", ")#
    # Return output:#
    return(Output)#
  }#
  # Subfunction to find taxonomy-phylogeny contradictions and turn them into warning messages:#
  ListContradictions <- function(TaxonomyMRP, MRPMatrix, ContradictionTaxa, DataSetName) {#
    # Subfunction to build warning messages:#
    BuildWarningMessages <- function(BoundMatrix, ContradictionTaxon, DataSetName) {#
      # Create four blocks for matching:#
      ZeroZero <- ZeroOne <- OneZero <- OneOne <- BoundMatrix#
      # Fill blocks with zeroes:#
      ZeroOne[, 1] <- OneZero[, 2] <- ZeroZero[1:length(ZeroZero)] <- "0"#
      # Fill blocks with ones:#
      ZeroOne[, 2] <- OneZero[, 1] <- OneOne[1:length(OneOne)] <- "1"#
      # Build empty list of names:#
      NamesList <- list()#
      # Store names where scores are zero and zero:#
      NamesList[["ZeroZeroNames"]] <- names(which(apply(BoundMatrix == ZeroZero, 1, all)))#
      # Store names where scores are zero and one:#
      NamesList[["ZeroOneNames"]] <- names(which(apply(BoundMatrix == ZeroOne, 1, all)))#
      # Store names where scores are one and zero:#
      NamesList[["OneZeroNames"]] <- names(which(apply(BoundMatrix == OneZero, 1, all)))#
      # Store names where scores are one and one:#
      NamesList[["OneOneNames"]] <- names(which(apply(BoundMatrix == OneOne, 1, all)))#
      # Prune down to just the minimum list lengths (the likley problem candidate(s)):#
      NamesList <- NamesList[unlist(lapply(NamesList, length)) == min(unlist(lapply(NamesList, length)))]#
      # Collapse each item of the list to a singel string:#
      NamesList <- lapply(NamesList, WriteListAsString)#
      # Find datasets with second case (apparent taxa outside clade that should be inside):#
      CaseOne <- match(c("ZeroZeroNames", "OneZeroNames"), names(NamesList))#
      # Find datasets with second case (apparent taxa inside clade that should be outside):#
      CaseTwo <- match(c("ZeroOneNames", "OneOneNames"), names(NamesList))#
      # Remove NAs from first case matches:#
      CaseOne <- CaseOne[!is.na(CaseOne)]#
      # Remove NAs from second case matches:#
      CaseTwo <- CaseTwo[!is.na(CaseTwo)]#
      # If first case exists then reformat string with message to user:#
      if(length(CaseOne) > 0) NamesList[CaseOne] <- lapply(NamesList[CaseOne], function(x) paste("In ", DataSetName, " the following taxa were found outside ", ContradictionTaxon, " when taxonomy suggests they should be inside: ", x, ". Check data set and/or taxonomy that this is correct.\n", sep = ""))#
      # If second case exists then reformat string with message to user:#
      if(length(CaseTwo) > 0) NamesList[CaseTwo] <- lapply(NamesList[CaseTwo], function(x) paste("In ", DataSetName, " the following taxa were found inside ", ContradictionTaxon, " when taxonomy suggests they should be outside: ", x, ". Check data set and/or taxonomy that this is correct.\n", sep = ""))#
      # Reformat names list as a vector for output:#
      Output <- unname(unlist(NamesList))#
      # If multiple values then reformat into a single value:#
      if(length(Output) > 1) Output <- paste("In ", DataSetName, " one of the following is true:\n", paste(paste(paste(1:length(Output), ". T", sep = ""), gsub(paste("In ", DataSetName, " t| Check data set and/or taxonomy that this is correct.\n", sep = ""), "", Output), rep("\n", length(Output)), sep = ""), collapse = ""), "Check data set and/or taxonomy that this is correct.\n", sep = "")#
      # Return output:#
      return(Output)#
    }#
    # Build output into unique values (as can get duplicates):#
    Output <- unique(unlist(lapply(as.list(ContradictionTaxa), function(x) lapply(as.list(MRPCharacterContradiction(TaxonomyMRP[, x], MRPMatrix)), function(y) {BoundMatrix <- cbind(TaxonomyMRP[rownames(MRPMatrix), x], MRPMatrix[, y]); BuildWarningMessages(BoundMatrix, x, DataSetName)}))))#
    # Return output:#
    return(Output)#
  }#
  # Check MRPDirectory is formatted correctly adn stop and warn user if not:#
  if(!all(is.character(MRPDirectory)) || length(MRPDirectory) != 1) stop("MRPDirectory must be a single character string indicating the path to the folder containing the MRP files.")#
  # Check XMLDirectory is formatted correctly adn stop and warn user if not:#
  if(!all(is.character(XMLDirectory)) || length(XMLDirectory) != 1) stop("XMLDirectory must be a single character string indicating the path to the folder containing the XML files.")#
  # Check TargetClade is formatted correctly adn stop and warn user if not:#
  if(!all(is.character(TargetClade)) || length(TargetClade) != 1) stop("TargetClade must be a single character string indicating the desired clade the metatree will represent.")#
  # Check MissingSpecies respresents a valid option:#
  if(length(setdiff(MissingSpecies, c("all", "exclude", "genus"))) > 0) stop("MissingSpecies must be one of \"all\", \"exclude\", or \"genus\".")#
  # Check VeilLine is a logical and stop and warn user if not:#
  if(!is.logical(VeilLine)) stop("VeilLine must be a logical (TRUE or FALSE).")#
  # Check IncludeSpecimenLevelOTUs is a logical and stop and warn user if not:#
  if(!is.logical(IncludeSpecimenLevelOTUs)) stop("IncludeSpecimenLevelOTUs must be a logical (TRUE or FALSE).")#
  # Set defualt of constraint in use to FALSE:#
  ConstraintInUse <- FALSE#
  # Check that there is a maximum of one constraint tree being used and stop and warn user if so.#
  # Technically it ought to be possible to do this, but it leaves open some potentially horrendous disasters best avoided for now:#
  if(!is.null(BackboneConstraint) && !is.null(MonophylyConstraint)) stop("Cannot currently apply a backbone constraint and a monophyly constraint simultaneously.")#
  # If backbone constraint is set:#
  if(!is.null(BackboneConstraint)) {#
    # Set constraint in use to TRUE:#
    ConstraintInUse <- TRUE#
    # Check is only a single value and stop and warn user if not:#
    if(length(BackboneConstraint) > 1) stop("BackboneConstraint must be a single value. (Cannot apply two backbone constraints simultaneously.)")#
    # Check is a string and stop and warn user if not:#
    if(!is.character(BackboneConstraint)) stop("BackboneConstraint must be a text string. Reformat and try again.")#
    # Set constraint data set to backbone constraint:#
    ConstraintDataSet <- BackboneConstraint#
    # Set constraint type to backbone:#
    ConstraintType <- "backbone"#
#
  }#
  # If monophyly onstraint is set:#
  if(!is.null(MonophylyConstraint)) {#
    # Set constraint in use to TRUE:#
    ConstraintInUse <- TRUE#
#
    # Check is only a single value and stop and warn user if not:#
    if(length(MonophylyConstraint) > 1) stop("MonophylyConstraint must be a single value. (Cannot apply two monophyly constraints simultaneously.)")#
    # Check is a string and stop and warn user if not:#
    if(!is.character(MonophylyConstraint)) stop("MonophylyConstraint must be a text string. Reformat and try again.")#
    # Set constraint data set to monophyly constraint:#
    ConstraintDataSet <- MonophylyConstraint#
    # Set constraint type to monophyly:#
    ConstraintType <- "monophyly"#
  }#
  # Check VeilLine is a logical and stop and warn user if not:#
  if(!is.logical(ReportContradictionsToScreen)) stop("ReportContradictionsToScreen must be a logical (TRUE or FALSE).")#
  # List of types of resolution that require finding a senior synonym:#
  synonyms <- c("corrected to", "misspelling of", "objective synonym of", "obsolete variant of", "recombined as", "replaced by", "subjective synonym of")#
  # List of types of resolution that require changing reconciliation to DELETE:#
  DeletionCategories <- c("nomen dubium", "nomen vanum", "nomen nudum", "nomen oblitum", "invalid subgroup of")#
  # Print current processing status:#
  cat("Reading MRP data...")#
  # Set working directory as MRP directory:#
  setwd(MRPDirectory)#
  # List MRP files (or just use inclusivedatalist if set):#
  MRPFileList <- strsplit(ifelse(length(InclusiveDataList) > 0, paste(setdiff(sort(unique(InclusiveDataList)), sort(unique(ExclusiveDataList))), "mrp.nex", sep = "", collapse = "%%"), paste(setdiff(gsub("mrp\\.nex", "", list.files()), sort(unique(ExclusiveDataList))), "mrp.nex", sep = "", collapse = "%%")), "%%")[[1]]#
  # If a backbone constraint is used and is a file check it is present in the source data and stop and warn user if not:#
  if(!is.null(BackboneConstraint)) if(is.na(match(paste(BackboneConstraint, "mrp.nex", sep = ""), MRPFileList))) stop("Backbone constraint file not found in data. Check name and try again.")#
  # If a monophyly constraint is used and is a file check it is present in the source data and stop and warn user if not:#
  if(!is.null(MonophylyConstraint)) if(is.na(match(paste(MonophylyConstraint, "mrp.nex", sep = ""), MRPFileList))) stop("Monophyly constraint file not found in data. Check name and try again.")#
  # Check there are four relative weights values and stop and warn user if not:#
  if(length(RelativeWeights) != 4) stop("RelativeWeights must consist of exactly four values. Fix and try again.")#
  # Check relative weights are numeric and stop and warn user if not:#
  if(!is.numeric(RelativeWeights)) stop("RelativeWeights must consist of numeric values. Fix and try again.")#
  # Check there are no negative weights and at least one positive weight is being used and stop and wanr user if not:#
  if(sum(RelativeWeights) <= 0 || any(RelativeWeights < 0)) stop("RelativeWeights must include at least one positive value and negative values are not allowed. Fix and try again.")#
  # Check only a single weight combination value is being used and stop and warn user if not:#
  if(length(WeightCombination) != 1) stop("WeightCombination must consist of a single value.")#
  # Check weight combintion is a valid option and stop and warn if not:#
  if(length(setdiff(WeightCombination, c("product", "sum"))) > 0) stop("WeightCombination must be one of \"product\" or \"sum\" only. Check spelling and try again.")#
  # Read in all MRP files and store in a list (include duplicate headers to store parent sibling info later):#
  MRPList <- lapply(lapply(as.list(MRPFileList), Claddis::ReadMorphNexus), function(x) {y <- list(x$Matrix_1$Matrix, x$Matrix_1$Weights, "", "", ""); names(y) <- c("Matrix", "Weights", "FileName", "Parent", "Sibling"); y})#
  # Set names of MRP files:#
  names(MRPList) <- gsub("mrp.nex", "", MRPFileList)#
  # Find maximum input weight:#
  MaximumInputWeight <- max(unlist(lapply(MRPList, function(x) x$Weights)))#
  # Resacle all input weights zero to one by dividing through by maximum input weight:#
  MRPList <- lapply(MRPList, function(x) {x$Weights <- x$Weights / MaximumInputWeight; x})#
  # Print current processing status:#
  cat("Done\nReading XML data...")#
  # Set working directory as XML (i.e., metadata) directory:#
  setwd(XMLDirectory)#
  # List MRP files (or just use inslusivedatalist if set):#
  XMLFileList <- strsplit(ifelse(length(InclusiveDataList) > 0, paste(setdiff(sort(unique(InclusiveDataList)), sort(unique(ExclusiveDataList))), ".xml", sep = "", collapse = "%%"), paste(setdiff(gsub("\\.xml", "", list.files()), sort(unique(ExclusiveDataList))), ".xml", sep = "", collapse = "%%")), "%%")[[1]]#
  # Check there are no MRPs not listed as XMLs and vice versa (should return empty vector):#
  MRPXMLunion <- c(setdiff(gsub("\\.xml", "", XMLFileList), gsub("mrp\\.nex", "", MRPFileList)), setdiff(gsub("mrp\\.nex", "", MRPFileList), gsub("\\.xml", "", XMLFileList)))#
  # Stop if MRP datasets not listed as XMLs and vice versa:#
  if(length(MRPXMLunion) > 0) stop(paste("Datasets do not match (MRP and XML)!:", MRPXMLunion, collapse = " "))#
  # Read in all XML files and store in a list (reformatting subgenera as GenusSubgenus along the way):#
  XMLList <- lapply(as.list(XMLFileList), function(x) {y <- ReadMetatreeXML(x); y$SourceTree$Taxa$TagContents[, "recon_name"] <- gsub("_\\(|\\)", "", y$SourceTree$Taxa$TagContents[, "recon_name"]); y})#
  # Add names to XML list:#
  names(XMLList) <- gsub(".xml", "", XMLFileList)#
  # Collapse to just pertinent information:#
  XMLList <- lapply(XMLList, function(x) {y <- list(); y[["TaxonMatrix"]] <- x$SourceTree$Taxa$TagContents; y[["FileName"]] <- unname(unlist(x$SourceTree$Filename)); y[["Parent"]] <- unname(unlist(x$SourceTree$Parent)); y[["Sibling"]] <- unname(unlist(x$SourceTree$Sibling)); y})#
  # Find any files that contain duplicated taxon names:#
  FilesWithDuplicatedTaxonNames <- names(XMLList)[which(unlist(lapply(XMLList, function(x) any(duplicated(x$TaxonMatrix[, "ListValue"])))))]#
  # If duplicate names were found stop and warn user:#
  if(length(FilesWithDuplicatedTaxonNames) > 0) stop(paste("The following files contain duplicate taxon names: ", paste(FilesWithDuplicatedTaxonNames, collapse = ", "), ". Ensure all taxon names are unique and try again.", sep = ""))#
  # Find any taxon names that do not match between MRP and XML:#
  TaxonMismatches <- mapply(function(x, y) {MRPNames <- rownames(x$Matrix); XMLNames <- y$TaxonMatrix[, "ListValue"]; c(setdiff(MRPNames, XMLNames), setdiff(XMLNames, MRPNames))}, x = MRPList[names(MRPList)], y = XMLList[names(MRPList)])#
  # Find any files with mismatching taxon names between MRP and XML:#
  FilesWithTaxonMismatches <- names(TaxonMismatches)[which(unlist(lapply(TaxonMismatches, function(x) length(x))) > 0)]#
  # If such files are found then stop and warn user:#
  if(length(FilesWithTaxonMismatches) > 0) stop(paste("The following files contain mismatching taxon names between the MRP and XML versions: ", paste(FilesWithTaxonMismatches, collapse = ", "), ". Ensure all taxon names match and try again.", sep = ""))#
  # Compile any name issues:#
  NameIssues <- lapply(XMLList, function(x) {TaxonMatrix <- x$TaxonMatrix; SpacesFound <- c(grep(" ", TaxonMatrix[, "recon_name"]), grep(" ", TaxonMatrix[, "recon_no"]), grep(" ", TaxonMatrix[, "ListValue"])); EmptyValuesFound <- c(which(TaxonMatrix[, "recon_name"] == ""), which(TaxonMatrix[, "recon_no"] == ""), which(TaxonMatrix[, "ListValue"] == "")); RogueNumberCharacters <- setdiff(unique(unlist(strsplit(TaxonMatrix[, "recon_no"], ""))), c(0:9, ";", "-")); RogueNameCharacters <- setdiff(unique(c(unlist(strsplit(TaxonMatrix[, "recon_name"], "")), unlist(strsplit(TaxonMatrix[, "ListValue"], "")))), c(LETTERS, letters, 0:9, "_", ",")); y <- list(SpacesFound, EmptyValuesFound, RogueNumberCharacters, RogueNameCharacters); names(y) <- c("SpacesFound", "EmptyValuesFound", "RogueNumberCharacters", "RogueNameCharacters"); y})#
  # Find any files with spaces in taxon names:#
  FilesWithSpaces <- names(NameIssues)[unlist(lapply(NameIssues, function(x) length(x$SpacesFound))) > 0]#
  # Find any values with empty values for taxon names:#
  FilesWithEmptyValues <- names(NameIssues)[unlist(lapply(NameIssues, function(x) length(x$EmptyValuesFound))) > 0]#
  # Files with rogue values in the recon number field:#
  FilesWithRogueTaxonNumbers <- names(NameIssues)[unlist(lapply(NameIssues, function(x) length(x$RogueNumberCharacters))) > 0]#
  # Files with rogue values in the name fields:#
  FilesWithRogueTaxonNames <- names(NameIssues)[unlist(lapply(NameIssues, function(x) length(x$RogueNameCharacters))) > 0]#
  # If issues with spaces in names stop and warn user:#
  if(length(FilesWithSpaces) > 0) stop(paste("The following files contain spaces in the taxonomic reconciliation (names or numbers): ", paste(FilesWithSpaces, collapse = ", "), ". Remove spaces and try again.", sep = ""))#
  # If issues with empty names stop and warn user:#
  if(length(FilesWithEmptyValues) > 0) stop(paste("The following files contain empty values in the taxonomic reconciliation (names or numbers): ", paste(FilesWithEmptyValues, collapse = ", "), ". Ensure all values are filled and try again.", sep = ""))#
  # If issues with rogue characters in number field stop and warn user:#
  if(length(FilesWithRogueTaxonNumbers) > 0) stop(paste("The following files contain rogue values in the taxonomic reconciliation (numbers): ", paste(FilesWithRogueTaxonNumbers, collapse = ", "), ". Ensure all taxon numbers only include semicolon(s) (the separating character) or dashes (for negative values) and try again.", sep = ""))#
  # If issues with rogue characters in name field stop and warn user:#
  if(length(FilesWithRogueTaxonNames) > 0) stop(paste("The following files contain rogue values in the taxonomic reconciliation (names): ", paste(FilesWithRogueTaxonNames, collapse = ", "), ". Ensure all taxon names are formed from alphanumerics, commas (the separating character) or underscores and try again.", sep = ""))#
  # Reconcile OTU names with XML version:#
  MRPList <- mapply(function(x, y) {rownames(x$Matrix)[unlist(lapply(as.list(y$TaxonMatrix[, "ListValue"]), function(z) which(rownames(x$Matrix) == z)))] <- paste(y$TaxonMatrix[, "recon_no"], y$TaxonMatrix[, "recon_name"], sep = "%%%%"); x$FileName <- y$FileName; if(!is.null(y$Parent)) x$Parent <- y$Parent; if(!is.null(y$Sibling)) x$Sibling <- y$Sibling; x}, x = MRPList[names(MRPList)], y = XMLList[names(MRPList)], SIMPLIFY = FALSE)#
#
  # Print current processing status:#
  cat("Done\nChecking for unsampled parents and siblings...")#
  # Extract parent and sibling names:#
  ParentAndSiblingNames <- sort(unlist(lapply(as.list(unique(unname(unlist(lapply(MRPList, '[', c("Parent", "Sibling")))))), function(x) x[nchar(x) > 0])))#
  # Warn user about any unsampled parents and/or siblings:#
  if(length(setdiff(ParentAndSiblingNames, names(MRPList))) > 0) print(paste("The following parents and siblings are not in the sample (check they are correct or add them into the sample): ", paste(setdiff(ParentAndSiblingNames, names(MRPList)), collapse = ", "), sep = ""))#
  # Print current processing status:#
  cat("Done\nFinding initial multiple-taxon reconciliations...")#
  # Separate out multi-taxon reconcilations:#
  MRPList <- lapply(MRPList, SeparateMultiTaxonReconciliations)#
  # If excluding specimen-level OTUs:#
  if(!IncludeSpecimenLevelOTUs) {#
    # Print current processing status:#
    cat("Done\nRemoving specimen-level OTUs...")#
    # Convert specimen-level OTUs to taxa to DELETE:#
    MRPList <- lapply(MRPList, function(x) {RowNamesToDelete <- which(unlist(lapply(strsplit(rownames(x$Matrix), split = ""), function(y) sum(y == "_") > 2))); if(length(RowNamesToDelete) > 0) rownames(x$Matrix)[RowNamesToDelete] <- "0%%%%DELETE"; x})#
  }#
  # Print current processing status:#
  cat("Done\nRemoving taxa with initial reconciliations of \"DELETE\"...")#
  # Remove any taxa reconciled as DELETE:#
  MRPList <- lapply(MRPList, function(x) {DeleteRows <- which(unlist(lapply(strsplit(rownames(x$Matrix), split = "%%%%"), function(y) y[2])) == "DELETE"); if(length(DeleteRows) > 0) x$Matrix <- x$Matrix[-DeleteRows, , drop = FALSE]; x})#
  # Prune matrices following deletion:#
  MRPList[ActiveMRP(MRPList)] <- lapply(MRPList[ActiveMRP(MRPList)], function(x) {y <- PisaniMRPPrune(Claddis::MakeMorphMatrix(x$Matrix, Weights = x$Weights, ignore.duplicate.taxa = TRUE)); x$Matrix <- y$Matrix_1$Matrix; x$Weights <- y$Matrix_1$Weights; x})#
#
  # Print current processing status:#
  cat("Done\nSearching for and collapsing pre-reconciliation duplicated taxa...")#
  # Collapse any duplicate taxon names:#
  MRPList[ActiveMRP(MRPList)] <- lapply(MRPList[ActiveMRP(MRPList)], function(x) {y <- Claddis::MakeMorphMatrix(x$Matrix, Weights = x$Weights, ignore.duplicate.taxa = TRUE); if(any(duplicated(rownames(y$Matrix_1$Matrix)))) {DuplicateNames <- setdiff(unlist(lapply(strsplit(rownames(y$Matrix_1$Matrix)[duplicated(rownames(y$Matrix_1$Matrix))], split = "%%%%"), '[', 2)), "DELETE"); if(length(DuplicateNames) > 0) cat(paste("\nDuplicate resolved OTU name(s) found in ", x$FileName, ": ", paste(DuplicateNames, collapse = ", "), ". Check this is correct.", sep = "")); y <- CollapseDuplicateTaxonMRP(y)}; x$Matrix <- y$Matrix_1$Matrix; x$Weights <- y$Matrix_1$Weights; x})#
  # Print current processing status:#
  cat("Done\nBuilding initial taxonomy matrix...")#
  # Create taxonomy matrix to store all taxon resolution data:#
  TaxonomyMatrix <- do.call(rbind, strsplit(unique(unname(unlist(lapply(MRPList[ActiveMRP(MRPList)], function(x) rownames(x$Matrix))))), split ="%%%%"))#
  # Add column names:#
  colnames(TaxonomyMatrix) <- c("TaxonNo", "TaxonName")#
  # Print current processing status:#
  cat("Done\nChecking for missing taxon numbers...")#
  # If any "-1" taxa found stop and tell user:#
  if(any(TaxonomyMatrix[, "TaxonNo"] == "-1")) stop(paste("The following taxa have the reconciliation number \"-1\": ", paste(TaxonomyMatrix[TaxonomyMatrix[, "TaxonNo"] == "-1", "TaxonName"], collapse = ", "), sep = ""))#
  # Print current processing status:#
  cat("Done\nBuilding initial Paleobiology Database reconciliation list...")#
  # Create resolved taxon numbers matrix:#
  ResolvedTaxonNumbers <- cbind(unique(TaxonomyMatrix[, "TaxonNo"]), PaleobiologyDBTaxaQuerier(taxon_nos = unique(TaxonomyMatrix[, "TaxonNo"]), interval = NULL))#
  # Deal with subgenera:#
  ResolvedTaxonNumbers[, "TaxonName"] <- gsub(" \\(|\\)", "", ResolvedTaxonNumbers[, "TaxonName"])#
  # Add column names to first value (input number):#
  colnames(ResolvedTaxonNumbers)[1] <- "InputNo"#
  # If specifying an Interval:#
  if(!all(is.null(Interval))) {#
    # Do same query for just taxa in Interval:#
    ResolvedTaxonNumbersInterval <- cbind(unique(TaxonomyMatrix[, "TaxonNo"]), PaleobiologyDBTaxaQuerier(taxon_nos = unique(TaxonomyMatrix[, "TaxonNo"]), interval = Interval))#
    # Deal with subgenera:#
    ResolvedTaxonNumbersInterval[, "TaxonName"] <- gsub(" \\(|\\)", "", ResolvedTaxonNumbersInterval[, "TaxonName"])#
    # Invert variable so only includes taxa outside Interval:#
    ResolvedTaxonNumbersInterval <- ResolvedTaxonNumbers[is.na(ResolvedTaxonNumbersInterval[, "TaxonName"]), ]#
    # Find any nomen dubia etc. to delete:#
    DeleteRows <- which(unlist(lapply(lapply(lapply(as.list(ResolvedTaxonNumbersInterval[, "TaxonValidity"]), match, x = DeletionCategories), sort), length)) > 0)#
    # If there are deletes then remove them from the matrix:#
    if(length(DeleteRows) > 0) ResolvedTaxonNumbersInterval <- ResolvedTaxonNumbersInterval[-DeleteRows, , drop = FALSE]#
  }#
  # Print current processing status:#
  cat("Done\nChecking taxon names match with database version...")#
  # Vector to store any failed matches:#
  failedmatches <- vector(mode = "character")#
  # For each initially reconciled name:#
  for(i in 1:nrow(TaxonomyMatrix)) {#
    # Get resolved name:#
    resolvedname <- gsub(" ", "_", ResolvedTaxonNumbers[which(ResolvedTaxonNumbers[, "InputNo"] == TaxonomyMatrix[i, "TaxonNo"]), "TaxonName"])#
    # Get input name:#
    inputname <- TaxonomyMatrix[i, "TaxonName"]#
    # Check names truly match (i.e., deals with case of indets where direct match not possible) and store if not:#
    if(resolvedname != inputname && any(is.na(match(strsplit(resolvedname, "_")[[1]], strsplit(inputname, "_")[[1]])))) failedmatches <- c(failedmatches, paste("Input name ", inputname, " does not match database name for corresponding number (", resolvedname, ").", sep = ""))#
  }#
  # If there are failed matches:#
  if(length(failedmatches) > 0) {#
    # Provide list to user:#
    cat(paste(failedmatches, collapse = "\n"))#
    # Stop function (will break later otherwise):#
    stop("")#
  }#
  # Print current processing status:#
  cat("Done\nChecking taxon validities...")#
  # Check for any new kind of resolution (should be empty vector):#
  newresolutions <- setdiff(sort(unique(ResolvedTaxonNumbers[, "TaxonValidity"])), c(DeletionCategories, synonyms))#
  # Stop if new resolutiosn found (need to add these to the resolution types above):#
  if(length(newresolutions) > 0) stop(paste("New resolution type found!: ", newresolutions, sep = ""))#
  # Print current processing status:#
  cat("Done\nBuilding synonymy tables...")#
  # Empty vector to store rows that correspond to some form of junior synonym:#
  synonymrows <- c()#
  # Find all junior synonym rows:#
  for(i in synonyms) synonymrows <- sort(c(synonymrows, which(ResolvedTaxonNumbers[, "TaxonValidity"] == i)))#
  # Set junior synonym matrix:#
  JuniorSynonyms <- ResolvedTaxonNumbers[synonymrows, , drop = FALSE]#
  # Create empty matrix to store senior synoyms:#
  SeniorSynonyms <- matrix(nrow = 0, ncol = 8, dimnames = list(c(), c("OriginalTaxonNo", "ResolvedTaxonNo", "TaxonName", "TaxonRank", "ParentTaxonNo", "TaxonValidity", "AcceptedNumber", "AcceptedName")))#
  # Reconcile senior synonym with database:#
  currenttaxa <- PaleobiologyDBTaxaQuerier(gsub("txn:", "", ResolvedTaxonNumbers[synonymrows, "AcceptedNumber"]))#
  # Deal with subgenera:#
  currenttaxa[, "TaxonName"] <- gsub(" \\(|\\)", "", currenttaxa[, "TaxonName"])#
  # While there are taxa with validity issues:#
  while(any(!is.na(currenttaxa[, "TaxonValidity"]))) {#
    # Isolate rows to check (i.e., just rows where validity isn't NA (i.e., resolved):#
    rowstocheck <- which(!is.na(currenttaxa[, "TaxonValidity"]))#
    # Check just those taxa:#
    currenttaxa[rowstocheck, ] <- PaleobiologyDBTaxaQuerier(taxon_nos = gsub("txn:", "", currenttaxa[rowstocheck, "AcceptedNumber"]), taxon_names = currenttaxa[rowstocheck, "AcceptedName"])#
    # Deal with subgenera:#
    currenttaxa[rowstocheck, "TaxonName"] <- gsub(" \\(|\\)", "", currenttaxa[rowstocheck, "TaxonName"])#
  }#
  # Make current taxa into senior synonyms list:#
  SeniorSynonyms <- currenttaxa#
  # If using an Interval:#
  if(!all(is.null(Interval))) {#
    # Update resolved taxon numbers to valid taxa only:#
    ResolvedTaxonNumbersInterval[which(!is.na(match(ResolvedTaxonNumbersInterval[, "InputNo"], JuniorSynonyms[, "InputNo"]))), c("OriginalTaxonNo", "ResolvedTaxonNo", "TaxonName", "TaxonRank", "ParentTaxonNo", "TaxonValidity", "AcceptedNumber", "AcceptedName")] <- SeniorSynonyms[match(ResolvedTaxonNumbersInterval[, "InputNo"], JuniorSynonyms[, "InputNo"])[!is.na(match(ResolvedTaxonNumbersInterval[, "InputNo"], JuniorSynonyms[, "InputNo"]))], c("OriginalTaxonNo", "ResolvedTaxonNo", "TaxonName", "TaxonRank", "ParentTaxonNo", "TaxonValidity", "AcceptedNumber", "AcceptedName")]#
  }#
  # Only complete this step if including specimen-level OTUs (there will not be any at this stage anyway if set as FALSE):#
  if(IncludeSpecimenLevelOTUs) {#
    # Print current processing status:#
    cat("Done\nChecking validity of indeterminate taxon reconciliations...")#
    # Get list of indeterminates:#
    indeterminates <- TaxonomyMatrix[which((unlist(lapply(lapply(strsplit(TaxonomyMatrix[, "TaxonName"], "_"), '==', "aff"), sum)) + unlist(lapply(lapply(strsplit(TaxonomyMatrix[, "TaxonName"], "_"), '==', "cf"), sum)) + unlist(lapply(lapply(strsplit(TaxonomyMatrix[, "TaxonName"], "_"), '==', "indet"), sum)) + unlist(lapply(lapply(strsplit(TaxonomyMatrix[, "TaxonName"], "_"), '==', "sp"), sum))) > 0), "TaxonName"]#
    # For each indeterminate:#
    for(i in indeterminates) {#
      # Get resolved row number:#
      resolvedrownumber <- which(ResolvedTaxonNumbers[, "InputNo"] == TaxonomyMatrix[which(TaxonomyMatrix[, "TaxonName"] == i), "TaxonNo"])#
      # If a possible invalid taxon (validity is not blank):#
      if(!is.na(ResolvedTaxonNumbers[resolvedrownumber, "TaxonValidity"])) {#
        # Get accepted number of taxon (may be NA):#
        AcceptedNumber <- gsub("txn:", "", ResolvedTaxonNumbers[resolvedrownumber, "AcceptedNumber"])#
        # If accepted number is blank (NA) stop adn warn user taxon is invalid:#
        if(is.na(AcceptedNumber)) stop(paste(i, " assigned to a taxon that is invalid, consider renaming.", sep = ""))#
        # If accepted numebr is different to input number stop and warn user taxon is synonymised:#
        if(AcceptedNumber != ResolvedTaxonNumbers[resolvedrownumber, "InputNo"]) stop(paste(i, " assigned to a taxon that is invalid, consider renaming.", sep = ""))#
      }#
    }#
  }#
#
  # Print current processing status:#
  cat("Done\nDeleting taxa resolved as nomen dubium and the like...")#
  # Get input numbers that should be deleted:#
  NumbersToDelete <- ResolvedTaxonNumbers[unlist(lapply(as.list(DeletionCategories), function(x) which(ResolvedTaxonNumbers[, "TaxonValidity"] == x))), "InputNo"]#
  # As long as there are numbers to delete:#
  if(length(NumbersToDelete) > 0) {#
    # Remove any taxa to delete:#
    MRPList[ActiveMRP(MRPList)] <- lapply(MRPList[ActiveMRP(MRPList)], function(x) {TaxonNumbers <- do.call(rbind, strsplit(rownames(x$Matrix), split = "%%%%"))[, 1]; DeleteRows <- sort(match(NumbersToDelete, TaxonNumbers)); if(length(DeleteRows) > 0) x$Matrix <- x$Matrix[-DeleteRows, , drop = FALSE]; x})#
    # Prune matrices following deletion:#
    MRPList[ActiveMRP(MRPList)] <- lapply(MRPList[ActiveMRP(MRPList)], function(x) {y <- PisaniMRPPrune(Claddis::MakeMorphMatrix(x$Matrix, Weights = x$Weights, ignore.duplicate.taxa = TRUE)); x$Matrix <- y$Matrix_1$Matrix; x$Weights <- y$Matrix_1$Weights; x})#
  }#
  # Print current processing status:#
  cat("Done\nReplacing junior synonyms with senior synonyms...")#
  # Rebuild junior synonyms into a vector of names:#
  JuniorSynonymsVector <- paste(JuniorSynonyms[, "InputNo"], gsub(" ", "_", JuniorSynonyms[, "TaxonName"]), sep = "%%%%")#
  # Rebuild senior synonyms into a vector of names:#
  SeniorSynonymsVector <- paste(unlist(lapply(apply(SeniorSynonyms[, c("OriginalTaxonNo", "ResolvedTaxonNo"), drop = FALSE], 1, as.list), function(x) unname(gsub("txn:|var:", "", unlist(x)[!is.na(unlist(x))][1])))), gsub(" ", "_", SeniorSynonyms[, "TaxonName"]), sep = "%%%%")#
  # Build synonym matrix:#
  SynonymyMatrix <- cbind(JuniorSynonymsVector, SeniorSynonymsVector)#
  # Replace junior synonyms with senior synonyms:#
  MRPList[ActiveMRP(MRPList)] <- lapply(MRPList[ActiveMRP(MRPList)], function(x) {SynonymyRows <- sort(match(SynonymyMatrix[, 1], rownames(x$Matrix))); if(length(SynonymyRows) > 0) rownames(x$Matrix)[SynonymyRows] <- SynonymyMatrix[match(rownames(x$Matrix)[SynonymyRows], SynonymyMatrix[, 1]), 2]; x})#
#
  # Collapse any duplicate taxa created by this substitution:#
  MRPList[ActiveMRP(MRPList)] <- lapply(MRPList[ActiveMRP(MRPList)], function(x) {y <- Claddis::MakeMorphMatrix(x$Matrix, Weights = x$Weights, ignore.duplicate.taxa = TRUE); if(any(duplicated(rownames(y$Matrix_1$Matrix)))) {DuplicateNames <- rownames(y$Matrix_1$Matrix)[duplicated(rownames(y$Matrix_1$Matrix))]; y <- CollapseDuplicateTaxonMRP(y)}; x$Matrix <- y$Matrix_1$Matrix; x$Weights <- y$Matrix_1$Weights; x})#
  # Prune characters made redundant by these collapses:#
  MRPList[ActiveMRP(MRPList)] <- lapply(MRPList[ActiveMRP(MRPList)], function(x) {y <- PisaniMRPPrune(Claddis::MakeMorphMatrix(x$Matrix, Weights = x$Weights, ignore.duplicate.taxa = TRUE)); x$Matrix <- y$Matrix_1$Matrix; x$Weights <- y$Matrix_1$Weights; x})#
  # GOT TO HERE WITH REFACTOR (BUT HAVE JUMPED AROUND A BUNCH, SO...)#
#
  # Print current processing status:#
  cat("Done\nBuilding taxonomy...")#
  # Get a list of the valid OTU names (may be pruned down later to just those in target clade):#
  ValidOTUNames <- unique(unlist(lapply(lapply(MRPList, '[[', "Matrix"), rownames)))[grep("_", unique(unlist(lapply(lapply(MRPList, '[[', "Matrix"), rownames))))]#
  # Replace junior with senior synonyms in resolved names matrix:#
  ResolvedTaxonNumbers[synonymrows, c("OriginalTaxonNo", "ResolvedTaxonNo", "TaxonName", "TaxonRank", "ParentTaxonNo", "TaxonValidity", "AcceptedNumber", "AcceptedName")] <- SeniorSynonyms#
  # Overwrite resolved number with resolved taxon number:#
  ResolvedTaxonNumbers[, "ResolvedTaxonNo"] <- gsub("txn:|var:", "", unlist(lapply(lapply(apply(ResolvedTaxonNumbers[, c("OriginalTaxonNo", "ResolvedTaxonNo")], 1, sort), rev), '[', 1)))#
  # Remove original taxon number column:#
  ResolvedTaxonNumbers <- ResolvedTaxonNumbers[, -which(colnames(ResolvedTaxonNumbers) == "OriginalTaxonNo")]#
  # Remove deleted taxa from resolved names matrix (if there are any):#
  if(length(which(!is.na(ResolvedTaxonNumbers[, "TaxonValidity"]))) > 0) ResolvedTaxonNumbers <- ResolvedTaxonNumbers[-which(!is.na(ResolvedTaxonNumbers[, "TaxonValidity"])), , drop = FALSE]#
  # Reformat parent taxon numbers into just numbers:#
  ResolvedTaxonNumbers[, "ParentTaxonNo"] <- gsub("txn:", "", ResolvedTaxonNumbers[, "ParentTaxonNo"])#
  # Collapse resolved matrix to just field with values (i.e., drop valid and senior synonym columns):#
  ResolvedTaxonNumbers <- ResolvedTaxonNumbers[, c("ResolvedTaxonNo", "TaxonName", "TaxonRank", "ParentTaxonNo")]#
  # If doing something with missing species (i.e., those not currently included as OTUs, but existing in target clade):#
  if(MissingSpecies != "exclude") {#
    # Find all descendants of target clade:#
    AllChildren <- PaleobiologyDBDescendantFinder(taxon_nos = "1", taxon_names = TargetClade, validonly = TRUE, returnrank = "3", interval = Interval)#
    # Deal with subgenera:#
    AllChildren[, "TaxonName"] <- gsub(" \\(|\\)", "", AllChildren[, "TaxonName"])#
    # If inserting all missing species get all possible species parent numbers:#
    if(MissingSpecies == "all") CurrentSpeciesParentNumbers <- unique(c(gsub("txn:", "", AllChildren[, "ParentTaxonNo"]), ResolvedTaxonNumbers[which(ResolvedTaxonNumbers[, "TaxonRank"] == 3), "ParentTaxonNo"]))#
    # If only inserting missing species at genus-level find parent numbers of all current species (i.e., potential genera to add):#
    if(MissingSpecies == "genus") CurrentSpeciesParentNumbers <- unique(ResolvedTaxonNumbers[which(ResolvedTaxonNumbers[, "TaxonRank"] == 3), "ParentTaxonNo"])#
    # Find any parents not already present in resolved numbers matrix:#
    AsYetUnsampledSpeciesParents <- setdiff(CurrentSpeciesParentNumbers, ResolvedTaxonNumbers[, "ResolvedTaxonNo"])#
    # If such parents exist:#
    if(length(AsYetUnsampledSpeciesParents) > 0) {#
      # Find unsampled species parents:#
      CurrentSpeciesParents <- PaleobiologyDBTaxaQuerier(taxon_nos = AsYetUnsampledSpeciesParents)#
      # Deal with subgenera:#
      CurrentSpeciesParents[, "TaxonName"] <- gsub(" \\(|\\)", "", CurrentSpeciesParents[, "TaxonName"])#
      # Find rows corresponding to valid genera:#
      ValidGenusRows <- intersect(which(is.na(CurrentSpeciesParents[, "TaxonValidity"])), which(CurrentSpeciesParents[, "TaxonRank"] == "5"))#
      # If there are valid genera then add these to resolved taxon numbers:#
      if(length(ValidGenusRows) > 0) ResolvedTaxonNumbers <- rbind(ResolvedTaxonNumbers, cbind(unname(gsub("txn:|var:", "", unlist(lapply(lapply(lapply(apply(CurrentSpeciesParents[ValidGenusRows, c("OriginalTaxonNo", "ResolvedTaxonNo"), drop = FALSE], 1, list), unlist), sort, decreasing = TRUE), '[', 1)))), CurrentSpeciesParents[ValidGenusRows, c("TaxonName", "TaxonRank")] , gsub("txn:", "", CurrentSpeciesParents[ValidGenusRows, "ParentTaxonNo"])))#
    }#
    # If including all species:#
    if(MissingSpecies == "all") {#
      # Update Valid OTUs accordingly#
      ValidOTUNames <- unique(c(ValidOTUNames, gsub(" ", "_", paste(unlist(lapply(strsplit(gsub("NA", "", paste(AllChildren[, "OriginalTaxonNo"], AllChildren[, "ResolvedTaxonNo"], sep = "")), split = "var:|txn:"), '[[', 2)), AllChildren[, "TaxonName"], sep = "%%%%"))))#
      # Set new children to add to resolved taxon numbers later:#
      NewChildren <- matrix(c(gsub("txn:|var:", "", unlist(lapply(apply(AllChildren[, c("OriginalTaxonNo", "ResolvedTaxonNo")], 1, sort, decreasing = TRUE), '[', 1))), AllChildren[, c("TaxonName", "TaxonRank")], gsub("txn:", "", AllChildren[, "ParentTaxonNo"])), ncol = 4)#
    }#
    # If including only species assigned to genus-level OTUs:#
    if(MissingSpecies == "genus") {#
      # Get current genus numbers (to check what has already been included):#
      CurrentGenusNumbers <- ResolvedTaxonNumbers[which(ResolvedTaxonNumbers[, "TaxonRank"] == 5), "ResolvedTaxonNo"]#
      # Get children of sampled genera:#
      GeneraChildren <- PaleobiologyDBDescendantFinder(taxon_nos = CurrentGenusNumbers, validonly = TRUE, returnrank = "3")#
      # Deal with subgenera:#
      GeneraChildren[, "TaxonName"] <- gsub(" \\(|\\)", "", GeneraChildren[, "TaxonName"])#
      # Update valid OTUs with children of all sampled genera:#
      ValidOTUNames <- unique(c(ValidOTUNames, gsub(" ", "_", paste(unlist(lapply(strsplit(gsub("NA", "", paste(GeneraChildren[, "OriginalTaxonNo"], GeneraChildren[, "ResolvedTaxonNo"], sep = "")), split = "var:|txn:"), '[[', 2)), GeneraChildren[, "TaxonName"], sep = "%%%%"))))#
      # Set new children to add to resolved taxon numbers later:#
      NewChildren <- matrix(c(gsub("txn:|var:", "", unlist(lapply(apply(GeneraChildren[, c("OriginalTaxonNo", "ResolvedTaxonNo")], 1, sort, decreasing = TRUE), '[', 1))), GeneraChildren[, c("TaxonName", "TaxonRank")], gsub("txn:", "", GeneraChildren[, "ParentTaxonNo"])), ncol = 4)#
    }#
    # Find any new children not already included in resolved taxon numbers list:#
    ChildrenToAdd <- setdiff(NewChildren[, 1], ResolvedTaxonNumbers[, "ResolvedTaxonNo"])#
    # If there are children to add then add them to resolved taxon numbers:#
    if(length(ChildrenToAdd) > 0) ResolvedTaxonNumbers <- rbind(ResolvedTaxonNumbers, NewChildren[match(ChildrenToAdd, NewChildren[, 1]), ])#
  }#
  # Find parents of all resolved taxon numbers (need to make sure these are valid or will propogate errors):#
  ParentMatrix <- PaleobiologyDBTaxaQuerier(ResolvedTaxonNumbers[, "ParentTaxonNo"], original = TRUE)#
  # If any are invalid then update to valid version:#
  if(any(!is.na(ParentMatrix[, "AcceptedNumber"]))) ParentMatrix[!is.na(ParentMatrix[, "AcceptedNumber"]), ] <- do.call(rbind, lapply(as.list(gsub("txn:", "", ParentMatrix[!is.na(ParentMatrix[, "AcceptedNumber"]), "AcceptedNumber"])), function(x) PaleobiologyDBTaxaQuerier(x, original = FALSE)))#
  # Update parent numbers to valid versions only:#
  ResolvedTaxonNumbers[, "ParentTaxonNo"] <- unname(unlist(lapply(apply(ParentMatrix[, c("OriginalTaxonNo", "ResolvedTaxonNo")], 1, list), function(x) {x <- unlist(x); gsub("txn:|var:", "", x[!is.na(x)][1])})))#
  # Get initial parent child relationships based on OTUs:#
  ParentChildRelationships <- paste(unlist(lapply(strsplit(ValidOTUNames, "%%%%"), '[', 1)), ResolvedTaxonNumbers[match(unlist(lapply(strsplit(ValidOTUNames, "%%%%"), '[', 1)), ResolvedTaxonNumbers[, "ResolvedTaxonNo"]), "ParentTaxonNo"], sep = " belongs to ")#
  # If including specimen level OTUs:#
  if(IncludeSpecimenLevelOTUs) {#
    # Find which rows correspond to indeterminate and sp taxa (i.e., those where parent should be initial reconciliation):#
    indetsandsps <- sort(c(which(unlist(lapply(lapply(lapply(lapply(lapply(strsplit(ValidOTUNames, "%%%%"), '[', 2), strsplit, split = "_"), unlist), '==', "indet"), any))), which(unlist(lapply(lapply(lapply(lapply(lapply(strsplit(ValidOTUNames, "%%%%"), '[', 2), strsplit, split = "_"), unlist), '==', "sp"), any)))))#
    # If such taxa exist then update parent child relationships accordingly:#
    if(length(indetsandsps) > 0) ParentChildRelationships[indetsandsps] <- paste(unlist(lapply(strsplit(ValidOTUNames[indetsandsps], "%%%%"), '[', 1)), unlist(lapply(strsplit(ValidOTUNames[indetsandsps], "%%%%"), '[', 1)), sep = " belongs to ")#
  }#
  # Get list of new children (for which parents are needed) - excludes "Life" which has no parent:#
  newchildren <- setdiff(unlist(lapply(strsplit(ParentChildRelationships, " belongs to "), '[', 2)), "28595")#
  # As long as there are still children in need of parents:#
  while(length(newchildren) > 0) {#
    # Find any numbers missing for the taxonomy name resolution matrix:#
    missingfromresolutions <- newchildren[which(is.na(match(newchildren, ResolvedTaxonNumbers[, "ResolvedTaxonNo"])))]#
    # If there are such numbers:#
    if(length(missingfromresolutions) > 0) {#
      # Get raw query data for new names#
      rawquery <- PaleobiologyDBTaxaQuerier(taxon_nos = missingfromresolutions)#
      # Look for synonymy rows (taxon validity is a synonym type):#
      NewSynonymRows <- sort(unique(unname(unlist(lapply(as.list(synonyms), function(x) which(rawquery[, "TaxonValidity"] == x))))))#
      # If synonyms were found:#
      if(length(NewSynonymRows) > 0) {#
        # Fix any synonyms (replace junior with senior):#
        rawquery[NewSynonymRows, c("ResolvedTaxonNo", "TaxonName")] <- rawquery[NewSynonymRows, c("AcceptedNumber", "AcceptedName"), drop = FALSE]#
        # Remove now obsolete validity data:#
        rawquery[NewSynonymRows, c("TaxonValidity", "AcceptedNumber", "AcceptedName")] <- NA#
      }#
      # Deal with subgenera:#
      rawquery[, "TaxonName"] <- gsub(" \\(|\\)", "", rawquery[, "TaxonName"])#
      # Add formatted results of query to resolved names matrix:#
      ResolvedTaxonNumbers <- rbind(ResolvedTaxonNumbers, unname(cbind(gsub("txn:|var:", "", unname(unlist(lapply(lapply(lapply(apply(rawquery[, c("OriginalTaxonNo", "ResolvedTaxonNo"), drop = FALSE], 1, list), unlist), sort, decreasing = TRUE), '[', 1)))), rawquery[, c("TaxonName", "TaxonRank"), drop = FALSE], gsub("txn:", "", rawquery[, "ParentTaxonNo"]))))#
    }#
    # Add new parent child relationships to list:#
    ParentChildRelationships <- c(ParentChildRelationships, paste(ResolvedTaxonNumbers[match(newchildren, ResolvedTaxonNumbers[, "ResolvedTaxonNo"]), "ResolvedTaxonNo"], ResolvedTaxonNumbers[match(newchildren, ResolvedTaxonNumbers[, "ResolvedTaxonNo"]), "ParentTaxonNo"], sep = " belongs to "))#
    # Update new children:#
    newchildren <- setdiff(ResolvedTaxonNumbers[match(newchildren, ResolvedTaxonNumbers[, "ResolvedTaxonNo"]), "ParentTaxonNo"], "28595")#
  }#
  # If Life is missing then add it at bottom:#
  if(all(!ResolvedTaxonNumbers[, "ResolvedTaxonNo"] == "28595")) ResolvedTaxonNumbers <- rbind(ResolvedTaxonNumbers, c("28595", "Life", "25", NA))#
  # Convert parent-child relationships into a matrix (columns for child and parent):#
  parentchildmatrix <- matrix(unlist(strsplit(ParentChildRelationships, split = " belongs to ")), ncol = 2, byrow = TRUE, dimnames = list(c(), c("Child", "Parent")))#
  # Update parent-child matrix with child names:#
  parentchildmatrix[, "Child"] <- ResolvedTaxonNumbers[match(parentchildmatrix[, "Child"], ResolvedTaxonNumbers[, "ResolvedTaxonNo"]), "TaxonName"]#
  # Update parent-child matrix with parent names:#
  parentchildmatrix[, "Parent"] <- ResolvedTaxonNumbers[match(parentchildmatrix[, "Parent"], ResolvedTaxonNumbers[, "ResolvedTaxonNo"]), "TaxonName"]#
  # Add valid OTU names into parent-child matrix:#
  parentchildmatrix[c(1:length(ValidOTUNames)), "Child"] <- unlist(lapply(strsplit(ValidOTUNames, "%%%%"), '[', 2))#
  # Add missing taxon ("Life") to parent-child matrix:#
  parentchildmatrix[which(is.na(parentchildmatrix[, "Parent"])), "Parent"] <- "Life"#
  # Create empty taxonomy MRP matrix:#
  TaxonomyMRP <- matrix(0, nrow = length(ValidOTUNames), ncol = length(sort(unique(parentchildmatrix[, "Parent"]))), dimnames = list(sort(unlist(lapply(strsplit(ValidOTUNames, "%%%%"), '[', 2))), sort(unique(parentchildmatrix[, "Parent"]))))#
  # Remove duplicates:#
  parentchildmatrix <- matrix(unlist(strsplit(unique(paste(parentchildmatrix[, "Child"], parentchildmatrix[, "Parent"], sep = "%%%%")), "%%%%")), ncol = 2, byrow = TRUE, dimnames = list(c(), c("Child", "Parent")))#
  # Check for duplicate names:#
  if(any(duplicated(sort(unlist(lapply(strsplit(ValidOTUNames, "%%%%"), '[[', 2)))))) stop(paste("The following OTU names are duplicated in the database (check and correct): ", paste(sort(unlist(lapply(strsplit(ValidOTUNames, "%%%%"), '[[', 2)))[duplicated(sort(unlist(lapply(strsplit(ValidOTUNames, "%%%%"), '[[', 2))))], sep = ", "), sep = ""))#
  # For each OTU (traces up through hierarchy until its presence in every higher taxon to which it belongs is assigned)::#
  for(i in 1:length(ValidOTUNames)) {#
    # Set starting current child taxon:#
    currentchild <- parentchildmatrix[i, "Child"]#
    # Set starting current parent taxon:#
    currentparent <- setdiff(parentchildmatrix[which(parentchildmatrix[, "Child"] == currentchild), "Parent"], currentchild)#
    # Record presence of child in parent in taxonomy matrix:#
    TaxonomyMRP[parentchildmatrix[i, "Child"], currentparent] <- 1#
    # As long as the parent is not "Life" (top of taxonomic hierarchy not reached):#
    while(currentparent != "Life") {#
      # Check there is not a duplicate taxon issue and stop and warn user if there is:#
      if(length(currentparent) > 1) stop(paste(currentchild, " is duplicated in the Paleobiology Database! Fix and try again.", sep = ""))#
      # Update child with previous parent:#
      currentchild <- currentparent#
      # Update parent with new parent:#
      currentparent <- setdiff(parentchildmatrix[which(parentchildmatrix[, "Child"] == currentchild), "Parent"], currentchild)#
      # Record presence of child in parent:#
      TaxonomyMRP[parentchildmatrix[i, "Child"], currentparent] <- 1#
    }#
  }#
  # Print current processing status:#
  cat("Done\nDealing with subgenera...")#
  # Find any subgenera names (as supraspecific column names only):#
  subgenerarows <- grep("\\(", colnames(TaxonomyMRP))#
  # If subgenera found make these single names (i.e., removes parentheses that will screw up Newick trees later):#
  if(length(subgenerarows) > 0) colnames(TaxonomyMRP)[subgenerarows] <- gsub("\\(|\\)| ", "", colnames(TaxonomyMRP)[subgenerarows])#
  # Correct subgenera in MRP list too:#
  MRPList <- lapply(MRPList, function(x) {NamesToCheck <- rownames(x$Matrix); NamesToCheck <- gsub("_\\(|\\)", "", NamesToCheck); rownames(x$Matrix) <- NamesToCheck; x})#
  # Print current processing status:#
  cat("Done\nTidying up taxonomy...")#
  # Check target clade is actually found:#
  if(length(which(colnames(TaxonomyMRP) == TargetClade)) == 0) stop("Target clade not found in taxonomy. Check spelling/Paleobiology database validity.")#
  # Work out which taxa are actually valid OTUs (belong to target clade):#
  NewValidOTUs <- names(which(TaxonomyMRP[, TargetClade] == 1))#
  # Find any subspecies names:#
  SubspeciesNames <- NewValidOTUs[unlist(lapply(strsplit(NewValidOTUs, split = ""), function(x) all(c(sum(x == "_") == 2, length(grep("[:A-Z:]", x)) == 1))))]#
  # Only continue if subspecies were found:#
  if(length(SubspeciesNames) > 0) {#
    # Find any subspecues where species is not in sample:#
    SubspeciesWhereSpeciesIsNotFound <- SubspeciesNames[!unlist(lapply(as.list(SubspeciesNames), function(x) any(NewValidOTUs == paste(strsplit(x, split = "_")[[1]][1:2], collapse = "_"))))]#
    # If subspecies without sampled species :#
    if(length(SubspeciesWhereSpeciesIsNotFound) > 0) {#
      # Rename these with species names:#
      NewValidOTUs[match(SubspeciesWhereSpeciesIsNotFound, NewValidOTUs)] <- unlist(lapply(strsplit(SubspeciesWhereSpeciesIsNotFound, split = "_"), function(x) paste(x[1:2], collapse = "_")))#
      # Rename taxonomy MRP rownames with species names too:#
      rownames(TaxonomyMRP)[match(SubspeciesWhereSpeciesIsNotFound, rownames(TaxonomyMRP))] <- unlist(lapply(strsplit(SubspeciesWhereSpeciesIsNotFound, split = "_"), function(x) paste(x[1:2], collapse = "_")))#
    }#
    # Collapse subspecies back to just the names where the species is already sampled:#
    SubspeciesNames <- setdiff(SubspeciesNames, SubspeciesWhereSpeciesIsNotFound)#
    # If there are subspecies where species already exists then prune these from the taxonomy MRP:#
    if(length(SubspeciesNames) > 0) NewValidOTUs <- NewValidOTUs[-match(SubspeciesNames, NewValidOTUs)]#
  }#
  # Modify this if using intervals:#
  if(!all(is.null(Interval))) NewValidOTUs <- setdiff(NewValidOTUs, gsub(" ", "_", ResolvedTaxonNumbersInterval[, "TaxonName"]))#
  # Can now strip out numbers from taxon names:#
  for(i in 1:length(MRPList)) if(!is.null(rownames(MRPList[[i]]$Matrix))) rownames(MRPList[[i]]$Matrix) <- unlist(lapply(strsplit(rownames(MRPList[[i]]$Matrix), "%%%%"), '[', 2))#
  # Collapse taxonomy MRP to just new valid taxa:#
  TaxonomyMRP <- TaxonomyMRP[NewValidOTUs, ]#
  # Make taxonomy MRP into list:#
  TaxonomyMRPlist <- split(TaxonomyMRP, rep(1:ncol(TaxonomyMRP), each = nrow(TaxonomyMRP)))#
  # Add column names to list:#
  names(TaxonomyMRPlist) <- colnames(TaxonomyMRP)#
  # Find higher taxa for which every taxon is present:#
  redundanthighertaxa <- colnames(TaxonomyMRP)[intersect(which(unlist(lapply(lapply(TaxonomyMRPlist, unique), length)) == 1), which(unlist(lapply(lapply(TaxonomyMRPlist, unique), '[', 1)) == 1))]#
  # Empty higher taxa:#
  emptyhighertaxa <- colnames(TaxonomyMRP)[intersect(which(unlist(lapply(lapply(TaxonomyMRPlist, unique), length)) == 1), which(unlist(lapply(lapply(TaxonomyMRPlist, unique), '[', 1)) == 0))]#
  # Find taxonomic autapomorphies (those with just one OTU and hence redundant):#
  taxonomicautapomorphies <- names(which(unlist(lapply(TaxonomyMRPlist, sum)) == 1))#
  # Collapse taxonomy MRP by removing constant characters (i.e., most of the subgroups just established - not autapomorphies as they can be substitutes later!):#
  TaxonomyMRP <- TaxonomyMRP[, -match(c(redundanthighertaxa, emptyhighertaxa), colnames(TaxonomyMRP)), drop = FALSE]#
  # Print current processing status:#
  cat("Done\nSubstituting valid OTUs for supraspecific taxa...")#
  # Find datasets with (valid) surpaspecific OTUs:#
  datasetswithsupraspecificOTUs <- which(unlist(lapply(lapply(lapply(lapply(MRPList, '[[', "Matrix"), rownames), intersect, y = colnames(TaxonomyMRP)), length)) > 0)#
  # If such data sets exist:#
  if(length(datasetswithsupraspecificOTUs) > 0) {#
    # For each such data set:#
    for(i in datasetswithsupraspecificOTUs) {#
      # Find higher taxa that will need to be replaced:#
      highertaxatoreplace <- intersect(rownames(MRPList[[i]]$Matrix), colnames(TaxonomyMRP))#
      # For each higher taxon to replace:#
      for(j in highertaxatoreplace) {#
        # Find substitue names from taxonomy:#
        substitutenames <- names(which(TaxonomyMRP[, j] == 1))#
        # Add these to end of matrix using coding for higher taxon:#
        MRPList[[i]]$Matrix <- rbind(MRPList[[i]]$Matrix, matrix(rep(MRPList[[i]]$Matrix[j, ], length(substitutenames)), nrow = length(substitutenames), byrow = TRUE, dimnames = list(substitutenames, c())))#
        # Remove now replaced higher taxon from matrix:#
        MRPList[[i]]$Matrix <- MRPList[[i]]$Matrix[-which(rownames(MRPList[[i]]$Matrix) == j), , drop = FALSE]#
      }#
    }#
  }#
  # Print current processing status:#
  cat("Done\nRetracting subspecies into species...")#
  # Replace all subspecies with their species name:#
  MRPList[ActiveMRP(MRPList)] <- lapply(MRPList[ActiveMRP(MRPList)], function(x) {UnderscoreAndCapitalCounts <- matrix(unlist(lapply(strsplit(rownames(x$Matrix), split = ""), function(y) c(sum(y == "_"), length(grep("[:A-Z:]", y))))), ncol = 2, byrow = TRUE, dimnames = list(c(), c("Underscores", "Capitals"))); SubspeciesRows <- intersect(which(UnderscoreAndCapitalCounts[, "Underscores"] == 2), which(UnderscoreAndCapitalCounts[, "Capitals"] == 1)); if(length(SubspeciesRows) > 0) rownames(x$Matrix)[SubspeciesRows] <- unlist(lapply(strsplit(rownames(x$Matrix)[SubspeciesRows], split = "_"), function(z) paste(z[1:2], collapse = "_"))); x})#
  # Collapse any duplicate taxon names:#
  MRPList[ActiveMRP(MRPList)] <- lapply(MRPList[ActiveMRP(MRPList)], function(x) {y <- Claddis::MakeMorphMatrix(x$Matrix, Weights = x$Weights, ignore.duplicate.taxa = TRUE); if(any(duplicated(rownames(y$Matrix_1$Matrix)))) {DuplicateNames <- rownames(y$Matrix_1$Matrix)[duplicated(rownames(y$Matrix_1$Matrix))]; if(length(DuplicateNames) > 0) cat(paste("\nDuplicate resolved OTU name(s) found post higher-taxon substitution in ", x$FileName, ": ", paste(DuplicateNames, collapse = ", "), ". Check this is correct.", sep = "")); y <- CollapseDuplicateTaxonMRP(y)}; x$Matrix <- y$Matrix_1$Matrix; x$Weights <- y$Matrix_1$Weights; x})#
  # Print current processing status:#
  cat("Done\nFurther tidying of taxonomy...")#
  # If applying an Interval:#
  if(!all(is.null(Interval))) {#
    # Find any rows to delete (because they represent taxa outside the Interval):#
    RowsToDelete <- sort(match(gsub(" ", "_", ResolvedTaxonNumbersInterval[ResolvedTaxonNumbersInterval[, "TaxonRank"] == "3", "TaxonName"]), rownames(TaxonomyMRP)))#
    # If found then remove these from the taxonomy MRP:#
    if(length(RowsToDelete) > 0) TaxonomyMRP <- TaxonomyMRP[-RowsToDelete, , drop = FALSE]#
  }#
  # Collapse taxonomy MRP by removing autapomorphic characters (if any):#
  if(length(taxonomicautapomorphies) > 0) TaxonomyMRP <- TaxonomyMRP[, -match(taxonomicautapomorphies, colnames(TaxonomyMRP)), drop = FALSE]#
  # Overwrite taxonomy MRP list with strings for each column:#
  TaxonomyMRPlist <- apply(TaxonomyMRP, 2, paste, collapse = "")#
  # Find any duplicated MRP strings:#
  duplicatedMRPstrings <- rle(sort(TaxonomyMRPlist))$values[which(rle(sort(TaxonomyMRPlist))$lengths > 1)]#
  # If there are duplicated columns (i.e., redundant MRP characters in the taxonomy):#
  if(length(duplicatedMRPstrings) > 0) {#
    # For each duplicated character:#
    for(i in duplicatedMRPstrings) {#
      # Get duplicated columns for current MRP string:#
      duplicatedcolumns <- which(TaxonomyMRPlist == i)#
      # Form new column name by collapsing higher taxa that are duplicated to a single string:#
      newcolumnname <- paste(names(duplicatedcolumns), collapse = "_et_")#
      # Overwrite first duplicated column name with new collapsed name:#
      colnames(TaxonomyMRP)[duplicatedcolumns[1]] <- newcolumnname#
      # Remove redundant columns from matrix:#
      TaxonomyMRP <- TaxonomyMRP[, -duplicatedcolumns[2:length(duplicatedcolumns)], drop = FALSE]#
      # Remove redundant columns from list:#
      TaxonomyMRPlist <- TaxonomyMRPlist[-duplicatedcolumns[2:length(duplicatedcolumns)]]#
    }#
  }#
  # Print current processing status:#
  cat("Done\nRemoving outgroups, empty supraspecific taxa and those outside the sampling interval...")#
  # Find any remaining taxa that now need to be deleted (outgroups to target clade and empty higher taxa):#
  TaxaToDelete <- setdiff(unlist(lapply(lapply(MRPList, '[[', "Matrix"), rownames)), NewValidOTUs)#
  # If applying an Interval then add taxa outside of it to the deletes list:#
  if(!all(is.null(Interval))) TaxaToDelete <- unique(c(TaxaToDelete, gsub(" ", "_", ResolvedTaxonNumbersInterval[ResolvedTaxonNumbersInterval[, "TaxonRank"] == "3", "TaxonName"])))#
  # If there are species to exclude:#
  if(length(SpeciesToExclude) > 0) {#
    # Build vector of all current OTU names:#
    OTUNames <- unique(unlist(lapply(MRPList, function(x) rownames(x$Matrix))))#
    # Find any missing names (in exclude list but not in tree):#
    MissingNames <- setdiff(SpeciesToExclude, OTUNames)#
    # If any are found stop and warn user:#
    if(length(MissingNames) > 0) stop(paste("The following SpeciesToExclude were not actually found in the data: ", paste(MissingNames, collapse = ", "), ". Check they are spelled correctly and try again.", sep = ""))#
    # Add species to exclude to taxa to delete:#
    TaxaToDelete <- unique(c(TaxaToDelete, SpeciesToExclude))#
    # Remove species to exclude from Taxonomy MRP (as lomg as they are still there):#
    if(length(intersect(SpeciesToExclude, rownames(TaxonomyMRP))) > 0) TaxonomyMRP <- TaxonomyMRP[-match(intersect(SpeciesToExclude, rownames(TaxonomyMRP)), rownames(TaxonomyMRP)), , drop = FALSE]#
    # Find any columns to delete (duplicated, autapomorphic or constant):#
    ColumnsToDalete <- unique(c(which(duplicated(apply(TaxonomyMRP, 2, paste, collapse = ""))), unname(which(apply(TaxonomyMRP, 2, sum) < 2))))#
    # If columns are to be deleted then delete them:#
    if(length(ColumnsToDalete) > 0) TaxonomyMRP <- TaxonomyMRP[, -ColumnsToDalete]#
    # Update new valid OTUs:#
    NewValidOTUs <- sort(rownames(TaxonomyMRP))#
#
  }#
  # Delete taxa from every matrix they occur in:#
  MRPList[ActiveMRP(MRPList)] <- lapply(MRPList[ActiveMRP(MRPList)], function(x) {DeleteRows <- match(intersect(TaxaToDelete, rownames(x$Matrix)), rownames(x$Matrix)); if(length(DeleteRows) > 0) x$Matrix <- x$Matrix[-DeleteRows, , drop = FALSE]; x})#
  # Prune redundant characters from matrices following taxon deletion(s):#
  MRPList[ActiveMRP(MRPList)] <- lapply(MRPList[ActiveMRP(MRPList)], function(x) {y <- PisaniMRPPrune(Claddis::MakeMorphMatrix(x$Matrix, Weights = x$Weights, ignore.duplicate.taxa = TRUE)); x$Matrix <- y$Matrix_1$Matrix; x$Weights <- y$Matrix_1$Weights; x})#
  # Print current processing status:#
  cat("Done\nProducing taxonomy tree...")#
  # Duplicated Taxonomy MRP to create a collapsable version for generating taxonomy Newick string:#
  TaxonomyMRPNewick <- TaxonomyMRP#
  # Get order of columns to collapse to form MRP#
  columncollapseorder <- order(apply(TaxonomyMRPNewick, 2, sum))#
  # For each column ("clade") in order from smallest to largest:#
  for(i in columncollapseorder) {#
    # Get taxa present in current clade:#
    taxonrows <- which(TaxonomyMRPNewick[, i] == 1)#
    # Create new partial Newick string for current clade (node):#
    newNewickstring <- paste("(", paste(names(taxonrows), collapse = ","), ")", colnames(TaxonomyMRPNewick)[i], sep = "")#
    # Replace row name with new Newick string:#
    rownames(TaxonomyMRPNewick)[taxonrows[1]] <- newNewickstring#
    # Remove now redundant taxa from Newick matrix:#
    TaxonomyMRPNewick <- TaxonomyMRPNewick[-taxonrows[2:length(taxonrows)], , drop = FALSE]#
  }#
  # Complete Newick string and over write Taxonomy Newick matrix:#
  TaxonomyMRPNewick <- paste("(", paste(rownames(TaxonomyMRPNewick), collapse = ","), ")", TargetClade, ";", sep = "")#
  # Ladderize taxonomy tree for neatness!:#
  TaxonomyMRPTree <- ladderize(read.tree(text = TaxonomyMRPNewick))#
#####
  # If there are higher taxa to collapse:#
  if(length(HigherTaxaToCollapse) > 0) {#
    # Print current processing status:#
    cat("Done\nCollapsing higher taxa...")#
    # Find any higher taxa actually present in target clade:#
    HigherTaxaInTargetClade <- colnames(TaxonomyMRP)#
    # Find any missing names (in collapse list but not in taxonomy):#
    MissingHigherTaxa <- setdiff(HigherTaxaToCollapse, HigherTaxaInTargetClade)#
    # If any are found stop and warn user:#
    if(length(MissingHigherTaxa) > 0) stop(paste("The following HigherTaxaToCollapse were not actually found in the data: ", paste(MissingHigherTaxa, collapse = ", "), ". Check they are spelled correctly and are valid (according to the Paleobiology Database) and try again.", sep = ""))#
    # Check the clades are all unique (not internested) and if not then stop and warn user:#
    if(any(duplicated(unlist(lapply(as.list(HigherTaxaToCollapse), function(x) rownames(TaxonomyMRP[TaxonomyMRP[, colnames(TaxonomyMRP) == x] == 1, ])))))) stop("HigherTaxaToCollapse contains clades that are internested. Remove the internested clades and try again.")#
    # Build taxa to rename matrix:#
    TaxaToRenameMatrix <- do.call(rbind, lapply(as.list(HigherTaxaToCollapse), function(x) unname(cbind(x, rownames(TaxonomyMRP[TaxonomyMRP[, colnames(TaxonomyMRP) == x] == 1, ])))))#
    # Build list of each clade's species compliment:#
    CladeContentsList <- lapply(as.list(TaxonomyMRPTree$node.label), function(x) {NodeNumber <- which(TaxonomyMRPTree$node.label == x) + Ntip(TaxonomyMRPTree); TaxonomyMRPTree$tip.label[FindDescendants(n = NodeNumber, tree = TaxonomyMRPTree)]})#
    # Add names of clades:#
    names(CladeContentsList) <- TaxonomyMRPTree$node.label#
    # Find any subsumed clades (to be removed from taxonomy MRP):#
    SubsumedClades <- unlist(lapply(as.list(HigherTaxaToCollapse), function(x) {CurrentClade <- which(names(CladeContentsList) == x); TempCladeContents <- CladeContentsList[-CurrentClade]; names(which(unlist(lapply(TempCladeContents, function(x) length(setdiff(x, CladeContentsList[[CurrentClade]])))) == 0))}))#
    # Build block to add to taxonomy MRP out of first taxon inside each clade to collapse:#
    BlockToAddToTaxonomyMRP <- do.call(rbind, lapply(as.list(HigherTaxaToCollapse), function(x) TaxonomyMRP[TaxaToRenameMatrix[which(TaxaToRenameMatrix[, 1] == x)[1], 2], ]))#
    # Add uppercase rownames to new block:#
    rownames(BlockToAddToTaxonomyMRP) <- toupper(HigherTaxaToCollapse)#
    # Add to taxonomy MRP:#
    TaxonomyMRP <- rbind(TaxonomyMRP, BlockToAddToTaxonomyMRP)#
    # Collapse taxonomy MRP down by removing clades and the species from the collapsed clades:#
    TaxonomyMRP <- TaxonomyMRP[-unlist(lapply(as.list(TaxaToRenameMatrix[, 2]), function(x) which(rownames(TaxonomyMRP) == x))), -unlist(lapply(as.list(c(HigherTaxaToCollapse, SubsumedClades)), function(x) which(colnames(TaxonomyMRP) == x))), drop = FALSE]#
    # Remove all but one collapsed taxa from each clade from the tree:#
    TaxonomyMRPTree <- drop.tip(TaxonomyMRPTree, TaxaToRenameMatrix[-unlist(lapply(as.list(HigherTaxaToCollapse), function(x) which(TaxaToRenameMatrix[, 1] == x)[1])), 2])#
    # Ladderize taxonomy tree for neatness!:#
    TaxonomyMRPTree <- ladderize(TaxonomyMRPTree)#
    # Build tips to replace matrix:#
    TipsToReplaceMatrix <- do.call(rbind, lapply(as.list(HigherTaxaToCollapse), function(x) TaxaToRenameMatrix[which(TaxaToRenameMatrix[, 1] == x)[1], ]))#
    # Replace tip names in tree:#
    TaxonomyMRPTree$tip.label[unlist(lapply(apply(TipsToReplaceMatrix, 1, as.list), function(x) {x <- unlist(x); which(TaxonomyMRPTree$tip.label == x[2])}))] <- toupper(TipsToReplaceMatrix[, 1])#
    # Replace names in MRP matrices:#
    MRPList[ActiveMRP(MRPList)] <- lapply(MRPList[ActiveMRP(MRPList)], function(x) {CurrentRownames <- rownames(x$Matrix); NamesToReplace <- intersect(CurrentRownames, TaxaToRenameMatrix[, 2]); if(length(NamesToReplace) > 0) rownames(x$Matrix)[match(NamesToReplace, rownames(x$Matrix))] <- toupper(TaxaToRenameMatrix[match(NamesToReplace, TaxaToRenameMatrix[, 2]), 1]); x})#
    # Collapse any duplicate taxa created by this substitution (very likely!):#
    MRPList[ActiveMRP(MRPList)] <- lapply(MRPList[ActiveMRP(MRPList)], function(x) {y <- Claddis::MakeMorphMatrix(x$Matrix, Weights = x$Weights, ignore.duplicate.taxa = TRUE); if(any(duplicated(rownames(y$Matrix_1$Matrix)))) {DuplicateNames <- rownames(y$Matrix_1$Matrix)[duplicated(rownames(y$Matrix_1$Matrix))]; y <- CollapseDuplicateTaxonMRP(y)}; x$Matrix <- y$Matrix_1$Matrix; x$Weights <- y$Matrix_1$Weights; x})#
    # Prune constant characters and collapse duplicated characters:#
    MRPList[ActiveMRP(MRPList)] <- lapply(MRPList[ActiveMRP(MRPList)], function(x) {y <- PisaniMRPPrune(Claddis::MakeMorphMatrix(x$Matrix, Weights = x$Weights, ignore.duplicate.taxa = TRUE)); x$Matrix <- y$Matrix_1$Matrix; x$Weights <- y$Matrix_1$Weights; x})#
    # Update new valid OTUs:#
    NewValidOTUs <- sort(rownames(TaxonomyMRP))#
  }#
  # If specimen-level OTUs are included:#
  if(IncludeSpecimenLevelOTUs) {#
    # Print current processing status:#
    cat("Done\nAdding NAs for indet. and sp. subclades to taxonomy MRP...")#
    # Find indeterminates and sps:#
    indetsandsps <- NewValidOTUs[which((unlist(lapply(lapply(strsplit(NewValidOTUs, "_"), '==', "indet"), sum)) + unlist(lapply(lapply(strsplit(NewValidOTUs, "_"), '==', "sp"), sum))) > 0)]#
    # If there are indeterminates and/or sps:#
    if(length(indetsandsps) > 0) {#
      # For each such taxon:#
      for(i in indetsandsps) {#
        # Find higher taxon to which it belongs:#
        highertaxon <- colnames(TaxonomyMRP)[which(unlist(lapply(lapply(strsplit(colnames(TaxonomyMRP), "_et_"), '==', strsplit(i, "_")[[1]][1]), sum)) == 1)]#
        # Find any sub (suprapseicifc taxa) for that higher taxon:#
        subtaxa <- colnames(TaxonomyMRP)[which(unlist(lapply(lapply(lapply(split(TaxonomyMRP[names(which(TaxonomyMRP[, highertaxon] == 1)), , drop = FALSE], rep(1:ncol(TaxonomyMRP[names(which(TaxonomyMRP[, highertaxon] == 1)), , drop = FALSE]), each = nrow(TaxonomyMRP[names(which(TaxonomyMRP[, highertaxon] == 1)), , drop = FALSE]))), sort), unique), length)) == 2)]#
        # If these exist then set ith taxon as being NA with respect to belonging to the subtax(a):#
        if(length(subtaxa) > 1) TaxonomyMRP[i, subtaxa] <- NA#
      }#
    }#
  }#
  # For empty data sets make sure matrix is zero-by-zero and weights have no lengths:#
  MRPList <- lapply(MRPList, function(x) {MatrixSize <- nrow(x$Matrix) * ncol(x$Matrix); if(MatrixSize == 0) {x$Matrix <- matrix(nrow = 0, ncol = 0); x$Weights <- vector(mode = "numeric")}; x})#
  # Print current processing status:#
  cat("Done\nGetting weighting data (publication year and dependencies)...")#
  # Set current year (used multiple times later):#
  CurrentYear <- strsplit(as.character(Sys.Date()), "-")[[1]][1]#
  # Add publication year to each data set (in presses are ascribed the current year):#
  MRPList <- lapply(MRPList, function(x) {x$PublicationYear <- gsub("[:A-Z:a-z:]|_|-", "", gsub("inpress", CurrentYear, x$FileName)); x})#
  # Find any missing parents:#
  MissingParents <- setdiff(unique(unname(unlist(lapply(MRPList, function(x) x$Parent[nchar(x$Parent) > 0])))), names(MRPList))#
  # Find all parent data set names:#
  ParentDataSets <- sort(unique(unname(unlist(lapply(MRPList, function(x) x$Parent[nchar(x$Parent) > 0])))))#
  # Get child data sets for each parent:#
  ChildDataSets <- lapply(as.list(ParentDataSets), function(x) unname(unlist(mapply(function(x, y) y$FileName[y$Parent == x], x = x, y = MRPList))))#
  # Add names to child data sets:#
  names(ChildDataSets) <- ParentDataSets#
  # Now include any grandchildren, greatgrandchildren etc.:#
  ChildDataSets <- lapply(ChildDataSets, function(x) sort(unique(c(x, unname(unlist(ChildDataSets[intersect(x, names(ChildDataSets))]))))))#
  # Add sibling relationships to data sets with shared parents and update parents field with grandparents, greatgrandparents etc.:#
  MRPList <- lapply(MRPList, function(x) {SiblingVector <- c(x$Sibling, setdiff(ChildDataSets[[match(x$Parent, ParentDataSets)]], x$FileName)); if(any(nchar(SiblingVector)) > 0) SiblingVector <- SiblingVector[nchar(SiblingVector) > 0]; x$Sibling <- unique(SiblingVector); if(!is.null(MRPList[[x$Parent[1]]]$Parent)) while(nchar(MRPList[[x$Parent[1]]]$Parent) > 0) x$Parent <- c(MRPList[[x$Parent[1]]]$Parent, x$Parent); x})#
  # OLD LINE FOR ABOVE THAT I AM PRETTY SURE IS BROKEN BUT AM LEAVING HERE FOR NOW IN CASE IT AIN'T#
  # Add sibling relationships to data sets with shared parents and update parents field with grandparents, greatgrandparents etc.:#
  #MRPList <- lapply(MRPList, function(x) {SiblingVector <- c(x$Sibling, setdiff(ChildDataSets[[match(x$Parent, ParentDataSets)]], x$FileName)); if(any(nchar(SiblingVector)) > 0) SiblingVector <- SiblingVector[nchar(SiblingVector) > 0]; x$Sibling <- unique(SiblingVector); x$Parent <- names(which(unlist(lapply(ChildDataSets, function(y) length(intersect(y, x$FileName)))) > 0)); x})#
  # Build an empty redundant parent list for later use if no parents exist:#
  RedundantParents <- vector(mode = "character")#
  # If parents exist build a vector of those that are redundant (at least one child data set contains their full taxonomic complement):#
  if(length(unlist(lapply(MRPList[ActiveMRP(MRPList)], function(x) x$Parent[nchar(x$Parent) > 0]))) > 0) RedundantParents <- unlist(lapply(as.list(unique(unlist(lapply(MRPList[ActiveMRP(MRPList)], function(x) x$Parent[nchar(x$Parent) > 0])))), function(x) {Children <- unname(unlist(lapply(MRPList[ActiveMRP(MRPList)], function(y) if(any(y$Parent == x)) y$FileName))); if(any(unlist(lapply(as.list(Children), function(y) length(setdiff(rownames(MRPList[[x]]$Matrix), rownames(MRPList[[y]]$Matrix))))) == 0)) x}))#
  # If redundant parents were found then collapse these data sets back to empty matrix and weights::#
  if(length(RedundantParents) > 0) MRPList[RedundantParents] <- lapply(MRPList[RedundantParents], function(x) {x$Matrix <- matrix(ncol = 0, nrow = 0); x$Weights <- vector(mode = "numeric"); x})#
  # Find any remaining active parent data sets:#
  ActiveParents <- names(which(unlist(lapply(MRPList[setdiff(ParentDataSets, MissingParents)], function(x) nrow(x$Matrix) * ncol(x$Matrix))) > 0))#
  # If active parents remain:#
  if(length(ActiveParents) > 0) {#
    # Add children of active parent to siblings:#
    MRPList[ActiveParents] <- lapply(MRPList[ActiveParents], function(x) {SiblingVector <- unique(c(ChildDataSets[[x$FileName]], x$Sibling)); x$Sibling <- unique(SiblingVector[nchar(SiblingVector) > 0]); x})#
    # Add parent as sibling of offspring:#
    MRPList <- lapply(MRPList, function(x) {SiblingVector <- c(x$Sibling, intersect(x$Parent, ActiveParents)); if(any(nchar(SiblingVector) > 0)) SiblingVector <- SiblingVector[nchar(SiblingVector) > 0]; x$Sibling <- sort(unique(SiblingVector)); x})#
  }#
  # Find any empty data sets to remove:#
  RemovedSourceData <- sort(names(which(unlist(lapply(MRPList, function(x) nrow(x$Matrix) * ncol(x$Matrix))) == 0)))#
  # Remove data sets from MRPList:#
  MRPList[RemovedSourceData] <- NULL#
  # Remove any dead siblings:#
  MRPList <- lapply(MRPList, function(x) {x$Sibling <- intersect(x$Sibling, names(MRPList)); x})#
  # If usinga  veil line:#
  if(VeilLine) {#
    # Print current processing status:#
    cat("Done\nApplying veil line...")#
    # Start with current year as veil year:#
    CurrentVeilYear <- as.numeric(CurrentYear)#
    # Set current taxa included as being from current veil year (to present):#
    CurrentTaxaIncluded <- unique(unlist(lapply(MRPList[as.numeric(unlist(lapply(MRPList, function(x) x$PublicationYear))) >= CurrentVeilYear], function(x) rownames(x$Matrix))))#
    # Make a stop point (where all taxa are sampled):#
    StopPoint <- length(unique(unlist(lapply(MRPList, function(x) rownames(x$Matrix)))))#
    # While not all taxa are included in current sample:#
    while(length(CurrentTaxaIncluded) < StopPoint) {#
      # Increment one year back in time:#
      CurrentVeilYear <- CurrentVeilYear - 1#
#
      # Update current taxa included:#
      CurrentTaxaIncluded <- unique(unlist(lapply(MRPList[as.numeric(unlist(lapply(MRPList, function(x) x$PublicationYear))) >= CurrentVeilYear], function(x) rownames(x$Matrix))))#
    }#
    # Find any data sets to remove (older than veil year):#
    DataSetsToRemove <- which(as.numeric(unlist(lapply(MRPList, function(x) x$PublicationYear))) < CurrentVeilYear)#
    # If data sets to remove:#
    if(length(DataSetsToRemove) > 0) {#
      # Add to removed source data vector:#
      RemovedSourceData <- sort(c(RemovedSourceData, names(MRPList)[DataSetsToRemove]))#
      # Remove from MRP list:#
      MRPList <- MRPList[-DataSetsToRemove]#
      # Remove any new dead siblings:#
      MRPList <- lapply(MRPList, function(x) {x$Sibling <- intersect(x$Sibling, names(MRPList)); x})#
    }#
#
  # If not using veil line:#
  } else {#
    # Set current veil year as oldest data set:#
    CurrentVeilYear <- min(as.numeric(unlist(lapply(MRPList, function(x) x$PublicationYear))))#
  }#
  # Print current processing status:#
  cat("Done\nCalculating weights...")#
  # Update current year to youngest data set (in case this is not the actual current year) as will screw uo weights otherwise:#
  CurrentYear <- as.character(max(as.numeric(unlist(lapply(MRPList, function(x) x$PublicationYear)))))#
  # Reformat weights to be input weights, publication year weights (equation 1 in Supplementary Information of Lloyd et al. 2016),#
  # data set dependence weights (1 / (N siblings + 1)), and clade contradiction weights (1 / frequency of contradictory clades).#
  # All weights are set on a zero to one scale initially and then multiplied by RelativeWeights:#
  MRPList <- lapply(MRPList, function(x) {InputWeights <- x$Weights; x$Weights <- NULL; x$InputWeights <- RelativeWeights[1] * InputWeights; x$PublicationYearWeights <- RelativeWeights[2] * (rep(((2 ^ (0.5 * (as.numeric(x$PublicationYear) - CurrentVeilYear + 1))) - 1) / ((2 ^ (0.5 * (as.numeric(CurrentYear) - CurrentVeilYear + 1))) - 1), length(InputWeights))); x$DataSetDependenceWeights <- RelativeWeights[3] * rep(1 / (length(x$Sibling) + 1), length(InputWeights)); x$CladeContradictionWeights <- RelativeWeights[4] * MRPIntraMatrixWeights(x$Matrix); x})#
  # If using sum to combine weights collapse weights to just their sum:#
  if(WeightCombination == "sum") MRPList <- lapply(MRPList, function(x) {x$Weights <- apply(rbind(x$InputWeights, x$PublicationYearWeights, x$DataSetDependenceWeights, x$CladeContradictionWeights), 2, sum); x$InputWeights <- NULL; x$PublicationYearWeights <- NULL; x$DataSetDependenceWeights <- NULL; x$CladeContradictionWeights <- NULL; x})#
  # If using product to combine weights collapse weights to just their product (excluding zeroes) and remove other weights from list:#
  if(WeightCombination == "product") MRPList <- lapply(MRPList, function(x) {x$Weights <- apply(rbind(x$InputWeights, x$PublicationYearWeights, x$DataSetDependenceWeights, x$CladeContradictionWeights), 2, function(y) {z <- as.character(y); z[z == "0"] <- NA; prod(as.numeric(z), na.rm = TRUE)}); x$InputWeights <- NULL; x$PublicationYearWeights <- NULL; x$DataSetDependenceWeights <- NULL; x$CladeContradictionWeights <- NULL; x})#
  # Get current maximum weight:#
  MaximumWeight <- max(unlist(lapply(MRPList, function(x) x$Weights)))#
  # Get current minimum weight:#
  MinimumWeight <- min(unlist(lapply(MRPList, function(x) x$Weights)))#
  # Calculate the multiplication factor for weight rescaling (10 to 1000), but use minimum weight if there is no variance:#
  MultiplicationFactor <- ifelse(1 / ((MaximumWeight - MinimumWeight) / 990) == Inf, MinimumWeight, 1 / ((MaximumWeight - MinimumWeight) / 990))#
  # Calculate the addition factor for weight rescaling (10 to 1000):#
  AdditionFactor <- 10 - (MinimumWeight * MultiplicationFactor)#
  # Rescale weights (10 to 1000) and round results to two decimal places (best TNT can cope with):#
  MRPList <- lapply(MRPList, function(x) {x$Weights <- round((x$Weights * MultiplicationFactor) + AdditionFactor, 2); x})#
  # Print current processing status:#
  cat("Done\nChecking for phylogeny-taxonomy contradictions...")#
  # Do first pass to find any contradictions between taxonomy MRP and the fully reconciled source matrix:#
  MRPList <- lapply(MRPList, function(x) {TaxonomyMRPStrings <- TaxonomyMRP[rownames(x$Matrix), ]; TaxonomyMRPStrings[is.na(TaxonomyMRPStrings)] <- "0"; TaxonomyMRPStrings <- TaxonomyMRPStrings[, apply(TaxonomyMRPStrings, 2, function(y) length(unique(y))) == 2, drop = FALSE]; x$TaxonomyContradictions <- names(which(unlist(lapply(apply(TaxonomyMRPStrings, 2, list), function(z) length(MRPCharacterContradiction(unlist(z), x$Matrix))) > 0))); x$TaxonomyContradictionProportion <- length(x$TaxonomyContradictions) / ncol(TaxonomyMRPStrings); x})#
  # Store monophyletic taxa (those not contradicted by any phylogenetic characters - useful for chunking larger data if found):#
  MonophyleticTaxa <- setdiff(colnames(TaxonomyMRP), unique(unlist(lapply(MRPList, function(x) x$TaxonomyContradictions))))#
  # If reporting contradiction issues to the screen:#
  if(ReportContradictionsToScreen) {#
    # Find any data sets with taxonomy-phylogeny contradictions:#
    ContradictionIssueDataSets <- names(unlist(lapply(MRPList, function(x) length(x$TaxonomyContradictions))) > 0)#
    # If there are data sets with contradictions:#
    if(length(ContradictionIssueDataSets) > 0) {#
      # Build vector of contradiction warnings:#
      ContradictionWarnings <- unname(unlist(lapply(MRPList[ContradictionIssueDataSets], function(x) {TaxonomyMRPSubset <- TaxonomyMRP[rownames(x$Matrix), x$TaxonomyContradictions, drop = FALSE]; if(any(is.na(TaxonomyMRPSubset))) TaxonomyMRPSubset[is.na(TaxonomyMRPSubset)] <- "0"; ListContradictions(TaxonomyMRP = TaxonomyMRPSubset, MRPMatrix = x$Matrix, ContradictionTaxa = x$TaxonomyContradictions, DataSetName = x$FileName)})))#
      # Print warnings to screen:#
      cat(ContradictionWarnings)#
      # NEED TO BREAK THIS DOWN FURTHER AS CLEARLY SOME REDUNDANCY! (E.G. GROUPING HIGHER TAXA WITH SAME ISSUE, OR DATA SETS WITH SAME ISSUE)#
    }#
  }#
  # If using a constraint:#
  if(ConstraintInUse) {#
    # Print current processing status:#
    cat("Done\nApplying constraint tree...")#
    # If a monophyly constraint add all other taxa outside the constraint (makes NAs zeroes):#
    if(ConstraintType == "monophyly") MRPList[[grep(ConstraintDataSet, names(MRPList))]]$Matrix <- rbind(MRPList[[grep(ConstraintDataSet, names(MRPList))]]$Matrix, matrix("0", ncol = ncol(MRPList[[grep("Constraint", names(MRPList))]]$Matrix), nrow = length(setdiff(NewValidOTUs, rownames(MRPList[[grep(ConstraintDataSet, names(MRPList))]]$Matrix))), dimnames = list(setdiff(NewValidOTUs, rownames(MRPList[[grep(ConstraintDataSet, names(MRPList))]]$Matrix)), c())))#
    # Build vector of atxa in constraint:#
    TaxaInConstraint <- rownames(MRPList[[grep(ConstraintDataSet, names(MRPList))]]$Matrix)#
    # Get combined weight of all non-constraint that contradicts constraint (need to know to correctly weight the constraint data):#
    NonConstraintWeightsTotal <- sum(unlist(lapply(MRPList[-grep(ConstraintDataSet, names(MRPList))], function(x) {TaxaInBoth <- intersect(rownames(x$Matrix), TaxaInConstraint); if(length(TaxaInBoth) > 2) {ConstraintMRPStrings <- x$Matrix[TaxaInBoth, ]; ConstraintMatrix <- MRPList[[grep(ConstraintDataSet, names(MRPList))]]$Matrix[TaxaInBoth, ]; ConstraintMatrix[is.na(ConstraintMatrix)] <- "0"; ConstraintMatrix <- ConstraintMatrix[, apply(ConstraintMatrix, 2, function(y) length(unique(y))) == 2, drop = FALSE]; if(length(unique(as.vector(ConstraintMRPStrings))) > 1) {x$ConstraintContradictions <- x$Weights[unique(unlist(lapply(apply(ConstraintMatrix, 2, list), function(z) {MRPCharacterContradiction(unlist(z), ConstraintMRPStrings)})))]} else {x$ConstraintContradictions <- integer(0)}} else {x$ConstraintContradictions <- integer(0)}; x$ConstraintContradictions})))#
    # If NonConstraintWeightsTotal is less than 10000 then set it at 10000 to ensure it is upweighted:#
    if(NonConstraintWeightsTotal < 10000) NonConstraintWeightsTotal <- 10000#
    # Update weights of constraint tree to maximum (allowing for weights to fall in the 999-1000 range if they represent conflicting clades):#
    MRPList[[ConstraintDataSet]]$Weights <- round(MRPIntraMatrixWeights(MRPList[[ConstraintDataSet]]$Matrix) + 999, 2)#
    # Get order of magnitude of current character count of constraint tree (need to check this won't be too big):#
    OrderOfMagnitudeOfCurrentCharacterCountOfConstraint <- nchar(as.character(ceiling(NonConstraintWeightsTotal / 1000) * ncol(MRPList[[ConstraintDataSet]]$Matrix)))#
    # If this order exceeds 10^6 (too big for memory):#
    if(OrderOfMagnitudeOfCurrentCharacterCountOfConstraint > 6) {#
      # Get order of magnitude to reduce weights by:#
      OrderOfMagnitudeToReduceWeightsBy <- (OrderOfMagnitudeOfCurrentCharacterCountOfConstraint - 6) * 10#
      # Calculate the multiplication factor for weight rescaling (10 to 1000):#
      MultiplicationFactor <- 1 / (990 / ((1000 / OrderOfMagnitudeToReduceWeightsBy) - 10))#
      # Calculate the addition factor for weight rescaling (10 to 1000):#
      AdditionFactor <- 10 - (10 * MultiplicationFactor)#
      # Rescale weights (10 to 1000) and round results to two decimal places (best TNT can cope with):#
      MRPList[-grep(ConstraintDataSet, names(MRPList))] <- lapply(MRPList[-grep(ConstraintDataSet, names(MRPList))], function(x) {x$Weights <- round((x$Weights * MultiplicationFactor) + AdditionFactor, 2); x})#
      # Update NonConstraintWeightsTotal:#
      NonConstraintWeightsTotal <- sum(unname(unlist(lapply(MRPList[-grep(ConstraintDataSet, names(MRPList))], function(x) x$Weights))))#
    }#
    # Embiggen MRP matrix so that weights are high enough to ensure constraint gets implemented:#
    MRPList[[ConstraintDataSet]]$Matrix <- metatree::EmbiggenMatrix(Claddis::MakeMorphMatrix(MRPList[[ConstraintDataSet]]$Matrix, Weights = MRPList[[ConstraintDataSet]]$Weights), N = ceiling(NonConstraintWeightsTotal / 1000))$Matrix_1$Matrix#
    # Update weights by replicating N times as with matrix embiggining:#
    MRPList[[ConstraintDataSet]]$Weights <- rep(MRPList[[ConstraintDataSet]]$Weights, ceiling(NonConstraintWeightsTotal / 1000))#
  }#
#
  # Print current processing status:#
  cat("Done\nBuilding MRP matrix...")#
  # Add in missing taxa as NAs to every taxon:#
  MRPList <- lapply(MRPList, function(x) {MissingTaxa <- setdiff(rownames(TaxonomyMRP), rownames(x$Matrix)); if(length(MissingTaxa) > 0) x$Matrix <- rbind(x$Matrix, matrix(nrow = length(MissingTaxa), ncol = ncol(x$Matrix), dimnames = list(MissingTaxa, c()))); x$Matrix <- x$Matrix[rownames(TaxonomyMRP), , drop = FALSE]; x})#
  # Build full MRP matrix (with taxonomy MRP):#
  if(!ExcludeTaxonomyMRP) FullMRPMatrix <- MakeMorphMatrix(CharacterTaxonMatrix = cbind(do.call(cbind, lapply(MRPList, function(x) x$Matrix)), TaxonomyMRP), Weights = c(unname(unlist(lapply(MRPList, function(x) x$Weights))), rep(1, ncol(TaxonomyMRP))))#
  # Build full MRP matrix (without taxonomy MRP):#
  if(ExcludeTaxonomyMRP) FullMRPMatrix <- MakeMorphMatrix(CharacterTaxonMatrix = do.call(cbind, lapply(MRPList, function(x) x$Matrix)), Weights = unname(unlist(lapply(MRPList, function(x) x$Weights))))#
  # Add all zero outgroup to matrix:#
  FullMRPMatrix$Matrix_1$Matrix <- rbind(matrix("0", nrow = 1, ncol = ncol(FullMRPMatrix$Matrix_1$Matrix), dimnames = list("allzero", c())), FullMRPMatrix$Matrix_1$Matrix)#
#
  # Print current processing status:#
  cat("Done\nPerforming Safe Taxonomic Reduction...")#
  # Perform STR on full matrix:#
  STRData <- SafeTaxonomicReduction(FullMRPMatrix)#
  # Create additional STR matrix from full matrix:#
  STRMRPMatrix <- STRData$reduced.matrix#
  # Print current processing status:#
  cat("Done\nCompiling and returning output...")#
  # Compile output:#
  Output <- list(FullMRPMatrix = FullMRPMatrix, STRMRPMatrix = STRMRPMatrix, TaxonomyTree = TaxonomyMRPTree, MonophyleticTaxa = MonophyleticTaxa, SafelyRemovedTaxa = STRData$str.list, RemovedSourceData = RemovedSourceData, VeilYear = CurrentVeilYear)
